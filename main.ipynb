{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c297172",
   "metadata": {},
   "source": [
    "Multi-level Perturbed Unit Gradient Descent, MPUGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51d2b3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data  import Subset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from types import SimpleNamespace \n",
    "import matplotlib.pyplot  as plt\n",
    "import numpy as np \n",
    "\n",
    "from optimizers import *\n",
    "from upanets import UPANets\n",
    "from torchsummary import summary\n",
    "import time, copy,timm\n",
    "import json\n",
    "import random \n",
    "import os\n",
    "from train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaa60ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "args = SimpleNamespace(\n",
    "    datasets='cifar_10',\n",
    "    batch_size = 500,\n",
    "    seed = 42,\n",
    "    lr=0.1, \n",
    "    momentum=0.9,\n",
    "    wd = 0.0005,\n",
    "    blocks = 1,\n",
    "    filters = 16,\n",
    "    epochs = 400,\n",
    "    start_epochs = 8\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bdda934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_all_seeds(seed=42):\n",
    "    # Python原生随机 \n",
    "    random.seed(seed) \n",
    "    # NumPy随机 \n",
    "    np.random.seed(seed) \n",
    "    # PyTorch随机 \n",
    "    torch.manual_seed(seed) \n",
    "    # CUDA随机（GPU相关）\n",
    "    torch.cuda.manual_seed_all(seed) \n",
    "    # CUDNN确定性模式 \n",
    "    torch.backends.cudnn.deterministic  = True \n",
    "    torch.backends.cudnn.benchmark  = False \n",
    " \n",
    "set_all_seeds(args.seed)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca2f2d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "557e50ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 50000, 'valid': 10000}\n"
     ]
    }
   ],
   "source": [
    "img_size = 32 # default image size for Cifar-10\n",
    "im_dimention = 32\n",
    "cifar_10_mean = [0.4914, 0.4822, 0.4465] \n",
    "cifar_10_std = [0.2023, 0.1994, 0.2010]\n",
    "cifar_100_mean = [0.5071, 0.4867, 0.4408]\n",
    "cifar_100_std = [0.2673, 0.2564, 0.2762]\n",
    "\n",
    "if args.datasets == 'cifar_10':\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize((im_dimention,im_dimention)),\n",
    "            transforms.RandomRotation(15,),\n",
    "            transforms.RandomCrop(im_dimention),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=cifar_10_mean, std=cifar_10_std)\n",
    "            # transforms.Lambda(lambda x: x.to(torch.float16))    # 最终输出FP16\n",
    "        ]),\n",
    "        # 'valid': transforms.Compose([\n",
    "        #     transforms.Resize((im_dimention,im_dimention)),\n",
    "        #     transforms.ToTensor(),\n",
    "        #     transforms.Normalize(mean=cifar_10_mean, std=cifar_10_std)\n",
    "        # ]),\n",
    "        'test': transforms.Compose([\n",
    "            transforms.Resize((im_dimention,im_dimention)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=cifar_10_mean, std=cifar_10_std)\n",
    "        ]),\n",
    "    }\n",
    " \n",
    "    full_trainset = torchvision.datasets.CIFAR10(\n",
    "        root='./data/cifar_10', train=True, download=True, transform=data_transforms['train'])\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root='./data/cifar_10', train=False, download=True, transform=data_transforms['test'])\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=args.batch_size, shuffle=False, num_workers=0)\n",
    "    Num_class = 10\n",
    "\n",
    "if args.datasets == 'cifar_100':\n",
    "    data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((im_dimention,im_dimention)),\n",
    "        transforms.RandomRotation(15,),\n",
    "        transforms.RandomCrop(im_dimention),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=cifar_100_mean, std=cifar_100_std)\n",
    "    ]),\n",
    "    # 'valid': transforms.Compose([\n",
    "    #     transforms.Resize((im_dimention,im_dimention)),\n",
    "    #     transforms.ToTensor(),\n",
    "    #     transforms.Normalize(mean=cifar_100_mean, std=cifar_100_std)\n",
    "    # ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((im_dimention,im_dimention)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=cifar_100_mean, std=cifar_100_std)\n",
    "    ]),\n",
    "    }\n",
    "    full_trainset = torchvision.datasets.CIFAR100(\n",
    "        root='./data/cifar_100', train=True, download=True, transform=data_transforms['train'])\n",
    "    testset = torchvision.datasets.CIFAR100(\n",
    "        root='./data/cifar_100', train=False, download=True, transform=data_transforms['test'])\n",
    "    testloader = DataLoader(\n",
    "        testset, batch_size=args.batch_size, shuffle=False,sampler=torch.utils.data.SequentialSampler(testset),  num_workers=0)\n",
    "    Num_class = 100\n",
    "\n",
    "# # 获取所有样本的标签 \n",
    "# labels = [full_trainset[i][1] for i in range(len(full_trainset))]\n",
    "\n",
    "# # 分层划分（stratify参数确保比例）\n",
    "# train_idx, val_idx = train_test_split(\n",
    "#     range(len(full_trainset)),\n",
    "#     test_size=0.2,\n",
    "#     shuffle=True,\n",
    "#     stratify=labels,\n",
    "#     random_state=args.seed  \n",
    "# )\n",
    "\n",
    "# train_data = np.stack([full_trainset.data[i]  for i in train_idx]) \n",
    "# train_targets = [full_trainset.targets[i] for i in train_idx] \n",
    "# val_data = np.stack([full_trainset.data[i]  for i in val_idx]) \n",
    "# val_targets = [full_trainset.targets[i] for i in val_idx] \n",
    "\n",
    "# valset = full_trainset\n",
    "# valset.data = val_data\n",
    "# valset.targets = val_targets\n",
    "# valset.transform = data_transforms['valid']\n",
    "\n",
    "# trainset = copy.deepcopy(valset)\n",
    "# trainset.data = train_data\n",
    "# trainset.targets = train_targets\n",
    "# trainset.transform = data_transforms['train']\n",
    "\n",
    "# trainloader = {\n",
    "#     'train':DataLoader(\n",
    "#     trainset, batch_size=args.batch_size, shuffle=False, sampler=torch.utils.data.SequentialSampler(trainset), num_workers=0),\n",
    "#     'valid':DataLoader(\n",
    "#     valset, batch_size=args.batch_size, shuffle=False, sampler=torch.utils.data.SequentialSampler(valset), num_workers=0)}\n",
    "\n",
    "# dataset_sizes = {\n",
    "#     'train': len(trainset),\n",
    "#     'valid': len(valset),            \n",
    "                #  }\n",
    "\n",
    "trainloader = {\n",
    "    'train':DataLoader(\n",
    "    full_trainset, batch_size=args.batch_size, shuffle=False, sampler=torch.utils.data.SequentialSampler(full_trainset), num_workers=0),\n",
    "    'valid':testloader\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "    'train': len(full_trainset),\n",
    "    'valid': len(testset),      \n",
    "}\n",
    "print(dataset_sizes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "840b5037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vit_tiny_patch16_224']\n"
     ]
    }
   ],
   "source": [
    "print(timm.list_models('*vit_tiny_patch16_224*')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ab5b31b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from torchvision.transforms.functional  import to_pil_image \n",
    "# 反归一化转换（需与transform中的参数对应）\n",
    "inv_normalize = transforms.Normalize(\n",
    "    mean=[-0.4914/0.2023, -0.4822/0.1994, -0.4465/0.2010],\n",
    "    std=[1/0.2023, 1/0.1994, 1/0.2010]\n",
    ")\n",
    " \n",
    "def show_images(loader, num_images=4):\n",
    "    # 获取一个batch的数据 \n",
    "    # images, labels = next(iter(loader))\n",
    "    for batch_idx, (images, labels) in enumerate(loader):\n",
    "        if batch_idx == 0:  # 只取第一个batch \n",
    "            break \n",
    "\n",
    "    # 创建子图 \n",
    "    fig, axes = plt.subplots(1,  num_images, figsize=(15, 3))\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        # 反归一化+通道顺序调整 \n",
    "        img = inv_normalize(images[i]).permute(1, 2, 0).numpy()\n",
    "        img = np.clip(img,  0, 1)  # 处理浮点误差 \n",
    "        \n",
    "        # 显示图像及标签 \n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f\"Label: {full_trainset.classes[labels[i]]}\") \n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.show() \n",
    " \n",
    "show_images(trainloader['train'])\n",
    "show_images(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5aa47f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./model/\" + args.datasets + \"/benckmark.pth\"\n",
    "if os.path.exists(model_path):\n",
    "    net_benckmark_data = torch.load(model_path,  map_location='cpu')\n",
    "    benckmark_state_dict = net_benckmark_data['model_state_dict'] \n",
    "else:\n",
    "    net_benchmark = UPANets(args.filters, Num_class, args.blocks, img_size)\n",
    "    torch.save({\n",
    "        'model_state_dict': net_benchmark.state_dict()\n",
    "    }, model_path)\n",
    "    benckmark_state_dict = net_benchmark.state_dict()\n",
    "\n",
    "def tensor_to_serializable(obj):\n",
    "    if isinstance(obj, (np.float32,  np.float64)):   # 处理NumPy浮点数\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.integer):               # 处理NumPy整数 \n",
    "        return int(obj)\n",
    "    elif isinstance(obj, torch.Tensor):            # 处理PyTorch Tensor \n",
    "        return obj.item()  if obj.numel()  == 1 else obj.tolist() \n",
    "    elif isinstance(obj, (np.ndarray)):             # 处理NumPy数组 \n",
    "        return obj.tolist() \n",
    "    elif hasattr(obj, '__dict__'):                 # 处理自定义对象（可选）\n",
    "        return obj.__dict__\n",
    "    return obj \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3ec9786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pugdt_delta = UPANets(args.filters, Num_class, args.blocks, img_size)  \n",
    "# net_pugdt_delta.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net_pugdt_delta.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     net_pugdt_delta = torch.nn.DataParallel(net_pugdt_delta)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDXT(net_pugdt_delta.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=args.lr,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                 )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "\n",
    "# net_pugdt_delta, metricst_delta = train_model_timing_delta(net_pugdt_delta, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes, int(args.epochs/10), 0.01, 10) \n",
    "\n",
    "# model_path = \"./model/\"+args.datasets+\"/pugdt_delta_\" + str(args.epochs) + \"xi\" + str(args.epochs/10) + \"mu0.01_t10.pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net_pugdt_delta.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/pugdt_delta_\" + str(args.epochs) + \"xi\" + str(args.epochs/10) + \"mu0.01_t10.json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metricst_delta,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efb925b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pugdt_var = UPANets(args.filters, Num_class, args.blocks, img_size)  \n",
    "# net_pugdt_var.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net_pugdt_var.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     net_pugdt_var = torch.nn.DataParallel(net_pugdt_var)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDXT(net_pugdt_var.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=args.lr,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                 )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "\n",
    "# net_pugdt_var, metricst_var = train_model_timing_var(net_pugdt_var, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes, int(args.epochs/10), 0.015, 10) \n",
    "\n",
    "# model_path = \"./model/\"+args.datasets+\"/pugdt_var_\" + str(args.epochs) + \"init_t\" + str(args.epochs/10) + \"gamma0.015_k10.pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net_pugdt_var.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/pugdt_var_\" + str(args.epochs) + \"init_t\" + str(args.epochs/10) + \"gamma0.015_k10.json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metricst_var,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a42d18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = UPANets(args.filters, Num_class, args.blocks, img_size)\n",
    "# net.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     net = torch.nn.DataParallel(net)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# optimizer = optim.SGD(net.parameters(),\n",
    "#                 lr=args.lr,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                  )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "# # exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# net, metrics_org = train_model_org(net, criterion, optimizer, scheduler, args.epochs * 2, trainloader, device, dataset_sizes) \n",
    "\n",
    "# # 保存模型架构+参数+优化器状态（完整恢复训练）\n",
    "# model_path = \"./model/\"+args.datasets+\"/org\" + str(args.epochs) + \".pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/org_\" + str(args.epochs) + \".json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metrics_org, f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n",
    " \n",
    "# # 加载 \n",
    "\n",
    "# # checkpoint = torch.load('full_model_checkpoint.pth',  map_location='cpu')  # 先加载到CPU避免设备冲突 \n",
    "# # 模型结构需提前定义（需与保存时一致）\n",
    "# # model = YourModelClass()  \n",
    "# # model.load_state_dict(checkpoint['model_state_dict']) \n",
    " \n",
    "# # # 恢复优化器和训练状态 \n",
    "# # optimizer = torch.optim.Adam(model.parameters())  \n",
    "# # optimizer.load_state_dict(checkpoint['optimizer_state_dict']) \n",
    "# # with open('data.json',  'r', encoding='utf-8') as f:\n",
    "# #     loaded_dict = json.load(f) \n",
    "\n",
    "\n",
    "# # summary(net, (3, img_size, img_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0db0a205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pugdr_sin = UPANets(args.filters, Num_class, args.blocks, img_size)\n",
    "# net_pugdr_sin.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net_pugdr_sin.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     model_ft_org = torch.nn.DataParallel(net_pugdr_sin)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDXR(net_pugdr_sin.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=args.lr,\n",
    "#                 max_epochs= args.epochs,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 min_beta = 0.0, \n",
    "#                 max_beta = 2.0, \n",
    "#                 method = 'sin',\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                 )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "# # exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# net_pugdr_sin, metricsr_sin = train_model_alpha(net_pugdr_sin, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "# model_path = \"./model/\"+args.datasets+\"/pugdr_sin\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net_pugdr_sin.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/pugdr_sin_\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metricsr_sin,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c82cb0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pugdr_cos = UPANets(args.filters, Num_class, args.blocks, img_size)\n",
    "# net_pugdr_cos.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net_pugdr_cos.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     model_ft_org = torch.nn.DataParallel(net_pugdr_cos)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDXR(net_pugdr_cos.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=args.lr,\n",
    "#                 max_epochs= args.epochs,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 min_beta = 0.0, \n",
    "#                 max_beta = 1.0, \n",
    "#                 method = 'cos',\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                 )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "# # exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# net_pugdr_cos, metricsr_sin = train_model_alpha(net_pugdr_cos, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "# model_path = \"./model/\"+args.datasets+\"/pugdr_cos\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net_pugdr_cos.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/pugdr_cos_\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metricsr_sin,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be3e5d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pugds_cos = UPANets(args.filters, Num_class, args.blocks, img_size)  \n",
    "# net_pugds_cos.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net_pugds_cos.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     net_pugds_cos = torch.nn.DataParallel(net_pugds_cos)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDXS(net_pugds_cos.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=args.lr,\n",
    "#                 max_epochs= args.epochs,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 min_beta = 0.0, \n",
    "#                 max_beta = 1.5,\n",
    "#                 method = 'cos',\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                  )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "# # exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# net_pugds_cos, metricss_cos = train_model_alpha(net_pugds_cos, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "# model_path = \"./model/\"+args.datasets+\"/pugds_cos\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net_pugds_cos.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/pugds_cos_\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metricss_cos,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14e79fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pugds_sin = UPANets(args.filters, Num_class, args.blocks, img_size)  \n",
    "# net_pugds_sin.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net_pugds_sin.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     net_pugds_sin = torch.nn.DataParallel(net_pugds_sin)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDXS(net_pugds_sin.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=args.lr,\n",
    "#                 max_epochs= args.epochs,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 min_beta = 0.0, \n",
    "#                 max_beta = 2.0,\n",
    "#                 method = 'sin',\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                  )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "\n",
    "# net_pugds_sin, metricss_sin = train_model_alpha(net_pugds_sin, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "# model_path = \"./model/\"+args.datasets+\"/pugds_sin\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net_pugds_sin.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/pugds_sin_\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metricss_sin,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1d2ef1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pugd = UPANets(args.filters, Num_class, args.blocks, img_size)  \n",
    "# net_pugd.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net_pugd.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     model_ft_org = torch.nn.DataParallel(net_pugd)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDX(net_pugd.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=args.lr,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                  )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "# # exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# net_pugd, metrics0 = train_model(net_pugd, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "# model_path = \"./model/\"+args.datasets+\"/pugd\" + str(args.epochs) + \".pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net_pugd.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/pugd_\" + str(args.epochs) + \".json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metrics0,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c195537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pugdr_cos = UPANets(args.filters, Num_class, args.blocks, img_size)  \n",
    "# net_pugdr_cos.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net_pugdr_cos.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     model_ft_org = torch.nn.DataParallel(net_pugdr_cos)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDXR(net_pugdr_cos.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=args.lr,\n",
    "#                 max_epochs= args.epochs,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 min_beta = 0.1, \n",
    "#                 max_beta = 2, \n",
    "#                 method = 'icos',\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                 )\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "\n",
    "# net_pugdr_cos, metricsr_cos = train_model_alpha(net_pugdr_cos, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "# model_path = \"./model/\"+args.datasets+\"/pugdr_icos\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net_pugdr_cos.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/pugdr_icos_\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metricsr_cos,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10cf6955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pugdr_sin = UPANets(args.filters, Num_class, args.blocks, img_size)\n",
    "# net_pugdr_sin.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net_pugdr_sin.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     model_ft_org = torch.nn.DataParallel(net_pugdr_sin)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDXR(net_pugdr_sin.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=args.lr,\n",
    "#                 max_epochs= args.epochs,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 min_beta = 0.1, \n",
    "#                 max_beta = 2, \n",
    "#                 method = 'isin',\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                 )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "# # exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# net_pugdr_sin, metricsr_sin = train_model_alpha(net_pugdr_sin, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "# model_path = \"./model/\"+args.datasets+\"/pugdr_isin\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net_pugdr_sin.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/pugdr_isin_\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metricsr_sin,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6b645d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pugds_icos = UPANets(args.filters, Num_class, args.blocks, img_size)  \n",
    "# net_pugds_icos.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net_pugds_icos.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     net_pugds_icos = torch.nn.DataParallel(net_pugds_icos)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDXS(net_pugds_icos.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=args.lr,\n",
    "#                 max_epochs= args.epochs,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 min_beta = 1, \n",
    "#                 max_beta = 2, \n",
    "#                 method = 'icos',\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                  )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "\n",
    "# net_pugds_icos, metricss_icos = train_model_alpha(net_pugds_icos, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "# model_path = \"./model/\"+args.datasets+\"/pugds_icos\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net_pugds_icos.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/pugds_icos_\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metricss_icos,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "214741d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pugds_isin = UPANets(args.filters, Num_class, args.blocks, img_size)  \n",
    "# net_pugds_isin.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net_pugds_isin.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     net_pugds_isin = torch.nn.DataParallel(net_pugds_isin)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDXS(net_pugds_isin.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=args.lr,\n",
    "#                 max_epochs= args.epochs,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 min_beta = 0.8, \n",
    "#                 max_beta = 3, \n",
    "#                 method = 'isin',\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                  )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "# # exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# net_pugds_isin, metricss_isin = train_model_alpha(net_pugds_isin, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "# model_path = \"./model/\"+args.datasets+\"/pugds_isin\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net_pugds_isin.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/pugds_isin_\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metricss_isin,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "156b0bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/399\n",
      "42.78801202774048\n",
      "Epoch 1/399\n",
      "42.845568895339966\n",
      "Epoch 2/399\n",
      "42.790456771850586\n",
      "Epoch 3/399\n",
      "42.93376088142395\n",
      "Epoch 4/399\n",
      "42.939884185791016\n",
      "Epoch 5/399\n",
      "42.91262674331665\n",
      "Epoch 6/399\n",
      "42.966031551361084\n",
      "Epoch 7/399\n",
      "42.980263233184814\n",
      "Epoch 8/399\n",
      "43.03599953651428\n",
      "Epoch 9/399\n",
      "43.22315192222595\n",
      "Epoch 10/399\n",
      "43.03050684928894\n",
      "Epoch 11/399\n",
      "43.1363308429718\n",
      "Epoch 12/399\n",
      "43.10914969444275\n",
      "Epoch 13/399\n",
      "43.01090431213379\n",
      "Epoch 14/399\n",
      "43.2221622467041\n",
      "Epoch 15/399\n",
      "43.11964464187622\n",
      "Epoch 16/399\n",
      "43.07667803764343\n",
      "Epoch 17/399\n",
      "43.05146646499634\n",
      "Epoch 18/399\n",
      "43.09892463684082\n",
      "Epoch 19/399\n",
      "43.130958557128906\n",
      "Epoch 20/399\n",
      "43.25813961029053\n",
      "Epoch 21/399\n",
      "43.06433892250061\n",
      "Epoch 22/399\n",
      "43.06778693199158\n",
      "Epoch 23/399\n",
      "43.129621505737305\n",
      "Epoch 24/399\n",
      "43.09074282646179\n",
      "Epoch 25/399\n",
      "43.179210901260376\n",
      "Epoch 26/399\n",
      "43.19741177558899\n",
      "Epoch 27/399\n",
      "43.0576434135437\n",
      "Epoch 28/399\n",
      "43.09786891937256\n",
      "Epoch 29/399\n",
      "43.03360199928284\n",
      "Epoch 30/399\n",
      "43.00837969779968\n",
      "Epoch 31/399\n",
      "43.13457798957825\n",
      "Epoch 32/399\n",
      "43.11183166503906\n",
      "Epoch 33/399\n",
      "42.94856572151184\n",
      "Epoch 34/399\n",
      "42.999340772628784\n",
      "Epoch 35/399\n",
      "42.91092276573181\n",
      "Epoch 36/399\n",
      "43.03357744216919\n",
      "Epoch 37/399\n",
      "43.10532546043396\n",
      "Epoch 38/399\n",
      "42.9763400554657\n",
      "Epoch 39/399\n",
      "42.97860813140869\n",
      "Epoch 40/399\n",
      "42.88575029373169\n",
      "Epoch 41/399\n",
      "42.888620138168335\n",
      "Epoch 42/399\n",
      "42.87115240097046\n",
      "Epoch 43/399\n",
      "42.951963663101196\n",
      "Epoch 44/399\n",
      "42.886173248291016\n",
      "Epoch 45/399\n",
      "42.92416024208069\n",
      "Epoch 46/399\n",
      "42.79579496383667\n",
      "Epoch 47/399\n",
      "42.88116240501404\n",
      "Epoch 48/399\n",
      "43.210981130599976\n",
      "Epoch 49/399\n",
      "43.167601585388184\n",
      "Epoch 50/399\n",
      "43.22839617729187\n",
      "Epoch 51/399\n",
      "43.14102268218994\n",
      "Epoch 52/399\n",
      "43.10767316818237\n",
      "Epoch 53/399\n",
      "43.09463596343994\n",
      "Epoch 54/399\n",
      "43.261144161224365\n",
      "Epoch 55/399\n",
      "43.10535025596619\n",
      "Epoch 56/399\n",
      "43.05950117111206\n",
      "Epoch 57/399\n",
      "43.0534131526947\n",
      "Epoch 58/399\n",
      "43.05381989479065\n",
      "Epoch 59/399\n",
      "43.267435789108276\n",
      "Epoch 60/399\n",
      "43.078558921813965\n",
      "Epoch 61/399\n",
      "43.031811237335205\n",
      "Epoch 62/399\n",
      "43.086875200271606\n",
      "Epoch 63/399\n",
      "43.0713472366333\n",
      "Epoch 64/399\n",
      "43.051650285720825\n",
      "Epoch 65/399\n",
      "43.22271466255188\n",
      "Epoch 66/399\n",
      "43.086551666259766\n",
      "Epoch 67/399\n",
      "43.09986352920532\n",
      "Epoch 68/399\n",
      "43.11014485359192\n",
      "Epoch 69/399\n",
      "43.152310848236084\n",
      "Epoch 70/399\n",
      "43.18271541595459\n",
      "Epoch 71/399\n",
      "43.219770431518555\n",
      "Epoch 72/399\n",
      "43.18376183509827\n",
      "Epoch 73/399\n",
      "43.194910287857056\n",
      "Epoch 74/399\n",
      "43.15141296386719\n",
      "Epoch 75/399\n",
      "43.186254262924194\n",
      "Epoch 76/399\n",
      "43.23620080947876\n",
      "Epoch 77/399\n",
      "43.164692640304565\n",
      "Epoch 78/399\n",
      "43.18411707878113\n",
      "Epoch 79/399\n",
      "43.17927861213684\n",
      "Epoch 80/399\n",
      "43.181925773620605\n",
      "Epoch 81/399\n",
      "43.20076847076416\n",
      "Epoch 82/399\n",
      "43.25634574890137\n",
      "Epoch 83/399\n",
      "43.16554522514343\n",
      "Epoch 84/399\n",
      "43.12103748321533\n",
      "Epoch 85/399\n",
      "43.00938081741333\n",
      "Epoch 86/399\n",
      "43.087220907211304\n",
      "Epoch 87/399\n",
      "43.157565116882324\n",
      "Epoch 88/399\n",
      "43.22675013542175\n",
      "Epoch 89/399\n",
      "43.19055128097534\n",
      "Epoch 90/399\n",
      "43.15665674209595\n",
      "Epoch 91/399\n",
      "43.154812812805176\n",
      "Epoch 92/399\n",
      "43.162209272384644\n",
      "Epoch 93/399\n",
      "43.3393976688385\n",
      "Epoch 94/399\n",
      "43.17359161376953\n",
      "Epoch 95/399\n",
      "43.15881395339966\n",
      "Epoch 96/399\n",
      "43.09662365913391\n",
      "Epoch 97/399\n",
      "43.10504364967346\n",
      "Epoch 98/399\n",
      "43.03233194351196\n",
      "Epoch 99/399\n",
      "43.22090744972229\n",
      "Epoch 100/399\n",
      "43.111692667007446\n",
      "Epoch 101/399\n",
      "43.14322280883789\n",
      "Epoch 102/399\n",
      "43.03263854980469\n",
      "Epoch 103/399\n",
      "43.16421055793762\n",
      "Epoch 104/399\n",
      "43.06247687339783\n",
      "Epoch 105/399\n",
      "43.19995951652527\n",
      "Epoch 106/399\n",
      "43.136512994766235\n",
      "Epoch 107/399\n",
      "43.151214599609375\n",
      "Epoch 108/399\n",
      "43.074742794036865\n",
      "Epoch 109/399\n",
      "43.184359312057495\n",
      "Epoch 110/399\n",
      "43.22460722923279\n",
      "Epoch 111/399\n",
      "43.1404025554657\n",
      "Epoch 112/399\n",
      "42.9993257522583\n",
      "Epoch 113/399\n",
      "43.063202142715454\n",
      "Epoch 114/399\n",
      "43.17230534553528\n",
      "Epoch 115/399\n",
      "43.111098289489746\n",
      "Epoch 116/399\n",
      "43.28782272338867\n",
      "Epoch 117/399\n",
      "43.19510078430176\n",
      "Epoch 118/399\n",
      "43.06576180458069\n",
      "Epoch 119/399\n",
      "43.187623262405396\n",
      "Epoch 120/399\n",
      "43.163557291030884\n",
      "Epoch 121/399\n",
      "43.13351249694824\n",
      "Epoch 122/399\n",
      "43.2546968460083\n",
      "Epoch 123/399\n",
      "43.11078476905823\n",
      "Epoch 124/399\n",
      "43.09888458251953\n",
      "Epoch 125/399\n",
      "43.1536819934845\n",
      "Epoch 126/399\n",
      "43.171040534973145\n",
      "Epoch 127/399\n",
      "43.22513747215271\n",
      "Epoch 128/399\n",
      "43.066638469696045\n",
      "Epoch 129/399\n",
      "43.13161516189575\n",
      "Epoch 130/399\n",
      "43.09670639038086\n",
      "Epoch 131/399\n",
      "43.148916244506836\n",
      "Epoch 132/399\n",
      "43.120769023895264\n",
      "Epoch 133/399\n",
      "43.292418479919434\n",
      "Epoch 134/399\n",
      "43.088382720947266\n",
      "Epoch 135/399\n",
      "43.07838153839111\n",
      "Epoch 136/399\n",
      "43.00489139556885\n",
      "Epoch 137/399\n",
      "43.08174777030945\n",
      "Epoch 138/399\n",
      "43.17392301559448\n",
      "Epoch 139/399\n",
      "43.27885341644287\n",
      "Epoch 140/399\n",
      "43.146801233291626\n",
      "Epoch 141/399\n",
      "43.12000107765198\n",
      "Epoch 142/399\n",
      "43.14397692680359\n",
      "Epoch 143/399\n",
      "43.06391787528992\n",
      "Epoch 144/399\n",
      "43.244420528411865\n",
      "Epoch 145/399\n",
      "43.08247971534729\n",
      "Epoch 146/399\n",
      "43.07087779045105\n",
      "Epoch 147/399\n",
      "43.14835453033447\n",
      "Epoch 148/399\n",
      "43.126301288604736\n",
      "Epoch 149/399\n",
      "43.215739250183105\n",
      "Epoch 150/399\n",
      "43.24586057662964\n",
      "Epoch 151/399\n",
      "43.07224225997925\n",
      "Epoch 152/399\n",
      "43.03187823295593\n",
      "Epoch 153/399\n",
      "43.0727653503418\n",
      "Epoch 154/399\n",
      "43.05142331123352\n",
      "Epoch 155/399\n",
      "43.18021202087402\n",
      "Epoch 156/399\n",
      "43.067218542099\n",
      "Epoch 157/399\n",
      "43.11042881011963\n",
      "Epoch 158/399\n",
      "43.053993463516235\n",
      "Epoch 159/399\n",
      "43.10053539276123\n",
      "Epoch 160/399\n",
      "43.13425397872925\n",
      "Epoch 161/399\n",
      "43.347559213638306\n",
      "Epoch 162/399\n",
      "43.15288949012756\n",
      "Epoch 163/399\n",
      "43.19535255432129\n",
      "Epoch 164/399\n",
      "43.14689064025879\n",
      "Epoch 165/399\n",
      "43.11518383026123\n",
      "Epoch 166/399\n",
      "43.14274573326111\n",
      "Epoch 167/399\n",
      "43.30008339881897\n",
      "Epoch 168/399\n",
      "43.183480978012085\n",
      "Epoch 169/399\n",
      "43.17690706253052\n",
      "Epoch 170/399\n",
      "43.155126333236694\n",
      "Epoch 171/399\n",
      "43.189698696136475\n",
      "Epoch 172/399\n",
      "43.16234517097473\n",
      "Epoch 173/399\n",
      "43.21696639060974\n",
      "Epoch 174/399\n",
      "43.1421263217926\n",
      "Epoch 175/399\n",
      "43.10125517845154\n",
      "Epoch 176/399\n",
      "43.18395185470581\n",
      "Epoch 177/399\n",
      "43.06486225128174\n",
      "Epoch 178/399\n",
      "43.21257400512695\n",
      "Epoch 179/399\n",
      "43.071452617645264\n",
      "Epoch 180/399\n",
      "43.15875601768494\n",
      "Epoch 181/399\n",
      "43.046406745910645\n",
      "Epoch 182/399\n",
      "43.065646171569824\n",
      "Epoch 183/399\n",
      "43.182865142822266\n",
      "Epoch 184/399\n",
      "43.18505883216858\n",
      "Epoch 185/399\n",
      "43.05732035636902\n",
      "Epoch 186/399\n",
      "43.06770896911621\n",
      "Epoch 187/399\n",
      "43.10804200172424\n",
      "Epoch 188/399\n",
      "43.12416481971741\n",
      "Epoch 189/399\n",
      "43.114810943603516\n",
      "Epoch 190/399\n",
      "43.189451456069946\n",
      "Epoch 191/399\n",
      "43.072296380996704\n",
      "Epoch 192/399\n",
      "43.1405611038208\n",
      "Epoch 193/399\n",
      "43.08085560798645\n",
      "Epoch 194/399\n",
      "43.17532253265381\n",
      "Epoch 195/399\n",
      "43.261176347732544\n",
      "Epoch 196/399\n",
      "43.13740301132202\n",
      "Epoch 197/399\n",
      "43.10679340362549\n",
      "Epoch 198/399\n",
      "43.117355823516846\n",
      "Epoch 199/399\n",
      "43.15380525588989\n",
      "Epoch 200/399\n",
      "43.159231662750244\n",
      "Epoch 201/399\n",
      "43.2710907459259\n",
      "Epoch 202/399\n",
      "43.06869554519653\n",
      "Epoch 203/399\n",
      "43.07708263397217\n",
      "Epoch 204/399\n",
      "43.19707679748535\n",
      "Epoch 205/399\n",
      "43.181116580963135\n",
      "Epoch 206/399\n",
      "43.05426287651062\n",
      "Epoch 207/399\n",
      "43.27380061149597\n",
      "Epoch 208/399\n",
      "43.18922138214111\n",
      "Epoch 209/399\n",
      "43.19775104522705\n",
      "Epoch 210/399\n",
      "43.2047815322876\n",
      "Epoch 211/399\n",
      "43.17913222312927\n",
      "Epoch 212/399\n",
      "43.23646020889282\n",
      "Epoch 213/399\n",
      "43.209834814071655\n",
      "Epoch 214/399\n",
      "43.097596883773804\n",
      "Epoch 215/399\n",
      "43.11305475234985\n",
      "Epoch 216/399\n",
      "43.1318633556366\n",
      "Epoch 217/399\n",
      "43.15742492675781\n",
      "Epoch 218/399\n",
      "43.26544237136841\n",
      "Epoch 219/399\n",
      "43.117899656295776\n",
      "Epoch 220/399\n",
      "43.10090947151184\n",
      "Epoch 221/399\n",
      "43.09468102455139\n",
      "Epoch 222/399\n",
      "43.0562584400177\n",
      "Epoch 223/399\n",
      "43.14606809616089\n",
      "Epoch 224/399\n",
      "43.24182391166687\n",
      "Epoch 225/399\n",
      "43.05579495429993\n",
      "Epoch 226/399\n",
      "43.10442042350769\n",
      "Epoch 227/399\n",
      "43.126516580581665\n",
      "Epoch 228/399\n",
      "43.165199518203735\n",
      "Epoch 229/399\n",
      "43.226343393325806\n",
      "Epoch 230/399\n",
      "43.183183431625366\n",
      "Epoch 231/399\n",
      "43.08803606033325\n",
      "Epoch 232/399\n",
      "43.17272925376892\n",
      "Epoch 233/399\n",
      "43.0889995098114\n",
      "Epoch 234/399\n",
      "43.0636773109436\n",
      "Epoch 235/399\n",
      "43.230947732925415\n",
      "Epoch 236/399\n",
      "43.03506588935852\n",
      "Epoch 237/399\n",
      "43.024734020233154\n",
      "Epoch 238/399\n",
      "43.071364641189575\n",
      "Epoch 239/399\n",
      "43.10816979408264\n",
      "Epoch 240/399\n",
      "43.34360408782959\n",
      "Epoch 241/399\n",
      "43.05795407295227\n",
      "Epoch 242/399\n",
      "43.12063670158386\n",
      "Epoch 243/399\n",
      "43.053587436676025\n",
      "Epoch 244/399\n",
      "43.16701650619507\n",
      "Epoch 245/399\n",
      "43.18121886253357\n",
      "Epoch 246/399\n",
      "43.25876212120056\n",
      "Epoch 247/399\n",
      "43.14108920097351\n",
      "Epoch 248/399\n",
      "43.14107370376587\n",
      "Epoch 249/399\n",
      "43.15032911300659\n",
      "Epoch 250/399\n",
      "43.17102122306824\n",
      "Epoch 251/399\n",
      "43.139111280441284\n",
      "Epoch 252/399\n",
      "43.22597050666809\n",
      "Epoch 253/399\n",
      "43.185399293899536\n",
      "Epoch 254/399\n",
      "43.18193769454956\n",
      "Epoch 255/399\n",
      "43.186440229415894\n",
      "Epoch 256/399\n",
      "43.20632004737854\n",
      "Epoch 257/399\n",
      "43.25822567939758\n",
      "Epoch 258/399\n",
      "43.1226019859314\n",
      "Epoch 259/399\n",
      "43.149425983428955\n",
      "Epoch 260/399\n",
      "43.0852837562561\n",
      "Epoch 261/399\n",
      "43.16531467437744\n",
      "Epoch 262/399\n",
      "43.13616418838501\n",
      "Epoch 263/399\n",
      "43.309197664260864\n",
      "Epoch 264/399\n",
      "43.15686321258545\n",
      "Epoch 265/399\n",
      "43.177159786224365\n",
      "Epoch 266/399\n",
      "43.073127031326294\n",
      "Epoch 267/399\n",
      "43.13085651397705\n",
      "Epoch 268/399\n",
      "43.06353044509888\n",
      "Epoch 269/399\n",
      "43.289222240448\n",
      "Epoch 270/399\n",
      "43.12026906013489\n",
      "Epoch 271/399\n",
      "43.16799855232239\n",
      "Epoch 272/399\n",
      "43.153491735458374\n",
      "Epoch 273/399\n",
      "43.11669874191284\n",
      "Epoch 274/399\n",
      "43.29869866371155\n",
      "Epoch 275/399\n",
      "43.112590074539185\n",
      "Epoch 276/399\n",
      "43.16711497306824\n",
      "Epoch 277/399\n",
      "43.097991704940796\n",
      "Epoch 278/399\n",
      "43.1594398021698\n",
      "Epoch 279/399\n",
      "43.12111163139343\n",
      "Epoch 280/399\n",
      "43.30851411819458\n",
      "Epoch 281/399\n",
      "43.13733196258545\n",
      "Epoch 282/399\n",
      "43.181835412979126\n",
      "Epoch 283/399\n",
      "43.14393854141235\n",
      "Epoch 284/399\n",
      "43.206528425216675\n",
      "Epoch 285/399\n",
      "43.14048385620117\n",
      "Epoch 286/399\n",
      "43.348782539367676\n",
      "Epoch 287/399\n",
      "43.169459104537964\n",
      "Epoch 288/399\n",
      "43.13015699386597\n",
      "Epoch 289/399\n",
      "43.15935945510864\n",
      "Epoch 290/399\n",
      "43.18994760513306\n",
      "Epoch 291/399\n",
      "43.24566292762756\n",
      "Epoch 292/399\n",
      "43.23445653915405\n",
      "Epoch 293/399\n",
      "43.16767692565918\n",
      "Epoch 294/399\n",
      "42.97309064865112\n",
      "Epoch 295/399\n",
      "43.10375618934631\n",
      "Epoch 296/399\n",
      "43.18295335769653\n",
      "Epoch 297/399\n",
      "43.29554295539856\n",
      "Epoch 298/399\n",
      "43.11155080795288\n",
      "Epoch 299/399\n",
      "43.18066930770874\n",
      "Epoch 300/399\n",
      "43.12267732620239\n",
      "Epoch 301/399\n",
      "43.16383099555969\n",
      "Epoch 302/399\n",
      "43.082085609436035\n",
      "Epoch 303/399\n",
      "43.33788800239563\n",
      "Epoch 304/399\n",
      "43.16915965080261\n",
      "Epoch 305/399\n",
      "43.15094017982483\n",
      "Epoch 306/399\n",
      "43.12014961242676\n",
      "Epoch 307/399\n",
      "43.101900577545166\n",
      "Epoch 308/399\n",
      "43.232199907302856\n",
      "Epoch 309/399\n",
      "43.166561126708984\n",
      "Epoch 310/399\n",
      "43.16265034675598\n",
      "Epoch 311/399\n",
      "43.10598635673523\n",
      "Epoch 312/399\n",
      "43.141743898391724\n",
      "Epoch 313/399\n",
      "43.17235016822815\n",
      "Epoch 314/399\n",
      "43.268065214157104\n",
      "Epoch 315/399\n",
      "43.09592294692993\n",
      "Epoch 316/399\n",
      "43.14525294303894\n",
      "Epoch 317/399\n",
      "43.171608686447144\n",
      "Epoch 318/399\n",
      "43.14501094818115\n",
      "Epoch 319/399\n",
      "43.16077971458435\n",
      "Epoch 320/399\n",
      "43.308642864227295\n",
      "Epoch 321/399\n",
      "43.1622748374939\n",
      "Epoch 322/399\n",
      "43.125513553619385\n",
      "Epoch 323/399\n",
      "43.11388683319092\n",
      "Epoch 324/399\n",
      "43.14931535720825\n",
      "Epoch 325/399\n",
      "43.23541784286499\n",
      "Epoch 326/399\n",
      "43.15411925315857\n",
      "Epoch 327/399\n",
      "43.182013511657715\n",
      "Epoch 328/399\n",
      "43.13957953453064\n",
      "Epoch 329/399\n",
      "43.213906049728394\n",
      "Epoch 330/399\n",
      "43.152514934539795\n",
      "Epoch 331/399\n",
      "43.277040243148804\n",
      "Epoch 332/399\n",
      "43.17845940589905\n",
      "Epoch 333/399\n",
      "43.19312357902527\n",
      "Epoch 334/399\n",
      "43.19252800941467\n",
      "Epoch 335/399\n",
      "43.218097448349\n",
      "Epoch 336/399\n",
      "43.269654750823975\n",
      "Epoch 337/399\n",
      "43.20236015319824\n",
      "Epoch 338/399\n",
      "43.110032081604004\n",
      "Epoch 339/399\n",
      "43.201828718185425\n",
      "Epoch 340/399\n",
      "43.18340492248535\n",
      "Epoch 341/399\n",
      "43.131216049194336\n",
      "Epoch 342/399\n",
      "43.23556089401245\n",
      "Epoch 343/399\n",
      "43.13630723953247\n",
      "Epoch 344/399\n",
      "43.14573383331299\n",
      "Epoch 345/399\n",
      "43.18744611740112\n",
      "Epoch 346/399\n",
      "43.17619252204895\n",
      "Epoch 347/399\n",
      "43.15706491470337\n",
      "Epoch 348/399\n",
      "43.22986173629761\n",
      "Epoch 349/399\n",
      "43.11778545379639\n",
      "Epoch 350/399\n",
      "43.20300531387329\n",
      "Epoch 351/399\n",
      "43.10707926750183\n",
      "Epoch 352/399\n",
      "43.12626123428345\n",
      "Epoch 353/399\n",
      "43.259578704833984\n",
      "Epoch 354/399\n",
      "43.15796613693237\n",
      "Epoch 355/399\n",
      "43.103291034698486\n",
      "Epoch 356/399\n",
      "43.13205814361572\n",
      "Epoch 357/399\n",
      "43.05973505973816\n",
      "Epoch 358/399\n",
      "43.14703178405762\n",
      "Epoch 359/399\n",
      "43.33271932601929\n",
      "Epoch 360/399\n",
      "43.12891983985901\n",
      "Epoch 361/399\n",
      "43.101407051086426\n",
      "Epoch 362/399\n",
      "43.145872354507446\n",
      "Epoch 363/399\n",
      "43.10810685157776\n",
      "Epoch 364/399\n",
      "43.140313148498535\n",
      "Epoch 365/399\n",
      "43.29020833969116\n",
      "Epoch 366/399\n",
      "43.16204047203064\n",
      "Epoch 367/399\n",
      "43.20439147949219\n",
      "Epoch 368/399\n",
      "43.138930797576904\n",
      "Epoch 369/399\n",
      "43.21916079521179\n",
      "Epoch 370/399\n",
      "43.31456732749939\n",
      "Epoch 371/399\n",
      "43.15664625167847\n",
      "Epoch 372/399\n",
      "43.16102719306946\n",
      "Epoch 373/399\n",
      "43.11646127700806\n",
      "Epoch 374/399\n",
      "43.15762495994568\n",
      "Epoch 375/399\n",
      "43.14161729812622\n",
      "Epoch 376/399\n",
      "43.263442277908325\n",
      "Epoch 377/399\n",
      "43.13363838195801\n",
      "Epoch 378/399\n",
      "43.09402585029602\n",
      "Epoch 379/399\n",
      "43.1773567199707\n",
      "Epoch 380/399\n",
      "43.13974642753601\n",
      "Epoch 381/399\n",
      "43.11640119552612\n",
      "Epoch 382/399\n",
      "43.229827642440796\n",
      "Epoch 383/399\n",
      "43.13372540473938\n",
      "Epoch 384/399\n",
      "43.08588361740112\n",
      "Epoch 385/399\n",
      "43.09824514389038\n",
      "Epoch 386/399\n",
      "43.06127977371216\n",
      "Epoch 387/399\n",
      "43.25865650177002\n",
      "Epoch 388/399\n",
      "43.19154691696167\n",
      "Epoch 389/399\n",
      "43.13927412033081\n",
      "Epoch 390/399\n",
      "43.16927742958069\n",
      "Epoch 391/399\n",
      "43.0906777381897\n",
      "Epoch 392/399\n",
      "43.060627698898315\n",
      "Epoch 393/399\n",
      "43.20258283615112\n",
      "Epoch 394/399\n",
      "43.116864919662476\n",
      "Epoch 395/399\n",
      "43.06414556503296\n",
      "Epoch 396/399\n",
      "43.0761022567749\n",
      "Epoch 397/399\n",
      "43.02021932601929\n",
      "Epoch 398/399\n",
      "43.045090436935425\n",
      "Epoch 399/399\n",
      "43.26129508018494\n",
      "Training complete in 287m 35s\n",
      "Best val Acc: 0.937100\n"
     ]
    }
   ],
   "source": [
    "net_pugdrs = UPANets(args.filters, Num_class, args.blocks, img_size)  \n",
    "net_pugdrs.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "net_pugdrs.to(device)\n",
    "\n",
    "if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "    net_pugdrs = torch.nn.DataParallel(net_pugdrs)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "base_optimizer = optim.SGD\n",
    "optimizer = PUGDXRS(net_pugdrs.parameters(),\n",
    "                base_optimizer,\n",
    "                lr=args.lr,\n",
    "                max_epochs= args.epochs,\n",
    "                momentum=args.momentum,\n",
    "                weight_decay=args.wd,\n",
    "                min_beta_r = 0, \n",
    "                max_beta_r = 1, \n",
    "                method_r = 'sin',\n",
    "                min_beta_s = 0, \n",
    "                max_beta_s = 1,\n",
    "                method_s = 'cos',\n",
    "                dampening=0,   # 必须设置为0才能完全固定 \n",
    "                nesterov=False # 禁用Nesterov动量 \n",
    "                 )\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "\n",
    "net_pugdrs, metricsrs = train_model_alpha(net_pugdrs, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "model_path = \"./model/\"+args.datasets+\"/pugdrs_\" + str(optimizer.method_r) + str(optimizer.max_beta_r) + \"_\" + str(optimizer.min_beta_r) + \"_\" + str(optimizer.method_s) + str(optimizer.max_beta_s) + \"_\" + str(optimizer.min_beta_s) + \"_\" + str(args.epochs) + \".pth\"\n",
    "torch.save({\n",
    "    'model_state_dict': net_pugdrs.state_dict(), \n",
    "    'optimizer_state_dict': optimizer.state_dict()\n",
    "}, model_path) \n",
    "\n",
    "name = \"./results/\"+args.datasets+\"/pugdrs_\" + str(optimizer.method_r) + str(optimizer.max_beta_r) + \"_\" + str(optimizer.min_beta_r) + \"_\" + str(optimizer.method_s) + str(optimizer.max_beta_s) + \"_\" + str(optimizer.min_beta_s) + \"_\" + str(args.epochs) + \".json\"\n",
    "with open(name,  'w', encoding='utf-8') as f:\n",
    "    json.dump(metricsrs,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f20f6280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/399\n",
      "42.56034755706787\n",
      "Epoch 1/399\n",
      "42.66645383834839\n",
      "Epoch 2/399\n",
      "42.78577470779419\n",
      "Epoch 3/399\n",
      "42.69014000892639\n",
      "Epoch 4/399\n",
      "42.780088663101196\n",
      "Epoch 5/399\n",
      "42.736655950546265\n",
      "Epoch 6/399\n",
      "42.8609676361084\n",
      "Epoch 7/399\n",
      "42.754399061203\n",
      "Epoch 8/399\n",
      "42.720632791519165\n",
      "Epoch 9/399\n",
      "43.00636339187622\n",
      "Epoch 10/399\n",
      "42.831284523010254\n",
      "Epoch 11/399\n",
      "42.88921546936035\n",
      "Epoch 12/399\n",
      "42.74281644821167\n",
      "Epoch 13/399\n",
      "42.80290770530701\n",
      "Epoch 14/399\n",
      "42.67070198059082\n",
      "Epoch 15/399\n",
      "43.002769947052\n",
      "Epoch 16/399\n",
      "42.79887247085571\n",
      "Epoch 17/399\n",
      "42.8196907043457\n",
      "Epoch 18/399\n",
      "42.83842206001282\n",
      "Epoch 19/399\n",
      "42.78146052360535\n",
      "Epoch 20/399\n",
      "43.00862693786621\n",
      "Epoch 21/399\n",
      "42.82878923416138\n",
      "Epoch 22/399\n",
      "42.93002653121948\n",
      "Epoch 23/399\n",
      "42.916210651397705\n",
      "Epoch 24/399\n",
      "42.78356122970581\n",
      "Epoch 25/399\n",
      "42.83564066886902\n",
      "Epoch 26/399\n",
      "43.266053915023804\n",
      "Epoch 27/399\n",
      "43.06373476982117\n",
      "Epoch 28/399\n",
      "43.042901277542114\n",
      "Epoch 29/399\n",
      "43.1359384059906\n",
      "Epoch 30/399\n",
      "43.18497180938721\n",
      "Epoch 31/399\n",
      "43.2387170791626\n",
      "Epoch 32/399\n",
      "43.138439416885376\n",
      "Epoch 33/399\n",
      "43.07101893424988\n",
      "Epoch 34/399\n",
      "43.20906162261963\n",
      "Epoch 35/399\n",
      "43.14124870300293\n",
      "Epoch 36/399\n",
      "43.147690773010254\n",
      "Epoch 37/399\n",
      "43.25473165512085\n",
      "Epoch 38/399\n",
      "43.132596492767334\n",
      "Epoch 39/399\n",
      "43.14896583557129\n",
      "Epoch 40/399\n",
      "43.19914674758911\n",
      "Epoch 41/399\n",
      "43.10577845573425\n",
      "Epoch 42/399\n",
      "43.146721839904785\n",
      "Epoch 43/399\n",
      "43.189502000808716\n",
      "Epoch 44/399\n",
      "43.12044167518616\n",
      "Epoch 45/399\n",
      "43.14643907546997\n",
      "Epoch 46/399\n",
      "43.069873332977295\n",
      "Epoch 47/399\n",
      "43.04301595687866\n",
      "Epoch 48/399\n",
      "43.285311222076416\n",
      "Epoch 49/399\n",
      "43.17648768424988\n",
      "Epoch 50/399\n",
      "43.09832978248596\n",
      "Epoch 51/399\n",
      "43.047287940979004\n",
      "Epoch 52/399\n",
      "43.12631964683533\n",
      "Epoch 53/399\n",
      "43.09421968460083\n",
      "Epoch 54/399\n",
      "43.17025876045227\n",
      "Epoch 55/399\n",
      "43.108511209487915\n",
      "Epoch 56/399\n",
      "43.06414437294006\n",
      "Epoch 57/399\n",
      "43.086143255233765\n",
      "Epoch 58/399\n",
      "43.12638068199158\n",
      "Epoch 59/399\n",
      "43.06534814834595\n",
      "Epoch 60/399\n",
      "43.26197600364685\n",
      "Epoch 61/399\n",
      "42.99474382400513\n",
      "Epoch 62/399\n",
      "43.06085157394409\n",
      "Epoch 63/399\n",
      "42.98021411895752\n",
      "Epoch 64/399\n",
      "43.05230712890625\n",
      "Epoch 65/399\n",
      "43.10692882537842\n",
      "Epoch 66/399\n",
      "43.08565425872803\n",
      "Epoch 67/399\n",
      "43.128098487854004\n",
      "Epoch 68/399\n",
      "43.095980167388916\n",
      "Epoch 69/399\n",
      "43.08630704879761\n",
      "Epoch 70/399\n",
      "43.092228412628174\n",
      "Epoch 71/399\n",
      "43.176371574401855\n",
      "Epoch 72/399\n",
      "43.18507504463196\n",
      "Epoch 73/399\n",
      "43.161614179611206\n",
      "Epoch 74/399\n",
      "43.134406089782715\n",
      "Epoch 75/399\n",
      "43.06005001068115\n",
      "Epoch 76/399\n",
      "43.155670166015625\n",
      "Epoch 77/399\n",
      "43.285475969314575\n",
      "Epoch 78/399\n",
      "43.10716485977173\n",
      "Epoch 79/399\n",
      "43.156702756881714\n",
      "Epoch 80/399\n",
      "43.118964195251465\n",
      "Epoch 81/399\n",
      "43.15042161941528\n",
      "Epoch 82/399\n",
      "43.29801797866821\n",
      "Epoch 83/399\n",
      "43.140021324157715\n",
      "Epoch 84/399\n",
      "43.133445739746094\n",
      "Epoch 85/399\n",
      "43.110074520111084\n",
      "Epoch 86/399\n",
      "43.14742565155029\n",
      "Epoch 87/399\n",
      "43.16632056236267\n",
      "Epoch 88/399\n",
      "43.260629653930664\n",
      "Epoch 89/399\n",
      "43.11740732192993\n",
      "Epoch 90/399\n",
      "43.156394720077515\n",
      "Epoch 91/399\n",
      "43.09010887145996\n",
      "Epoch 92/399\n",
      "43.17709541320801\n",
      "Epoch 93/399\n",
      "43.19511437416077\n",
      "Epoch 94/399\n",
      "43.122119665145874\n",
      "Epoch 95/399\n",
      "43.10353899002075\n",
      "Epoch 96/399\n",
      "43.12559771537781\n",
      "Epoch 97/399\n",
      "43.110835552215576\n",
      "Epoch 98/399\n",
      "43.08223557472229\n",
      "Epoch 99/399\n",
      "43.23919200897217\n",
      "Epoch 100/399\n",
      "43.076180934906006\n",
      "Epoch 101/399\n",
      "43.04833436012268\n",
      "Epoch 102/399\n",
      "43.04902529716492\n",
      "Epoch 103/399\n",
      "43.016927003860474\n",
      "Epoch 104/399\n",
      "42.97803020477295\n",
      "Epoch 105/399\n",
      "43.15708923339844\n",
      "Epoch 106/399\n",
      "43.00637340545654\n",
      "Epoch 107/399\n",
      "42.99780058860779\n",
      "Epoch 108/399\n",
      "43.060025691986084\n",
      "Epoch 109/399\n",
      "43.05142283439636\n",
      "Epoch 110/399\n",
      "43.24094843864441\n",
      "Epoch 111/399\n",
      "43.08165788650513\n",
      "Epoch 112/399\n",
      "43.03290581703186\n",
      "Epoch 113/399\n",
      "43.117249727249146\n",
      "Epoch 114/399\n",
      "43.11360287666321\n",
      "Epoch 115/399\n",
      "43.09379601478577\n",
      "Epoch 116/399\n",
      "43.20842623710632\n",
      "Epoch 117/399\n",
      "43.11694002151489\n",
      "Epoch 118/399\n",
      "43.176899671554565\n",
      "Epoch 119/399\n",
      "43.11121106147766\n",
      "Epoch 120/399\n",
      "43.08506774902344\n",
      "Epoch 121/399\n",
      "43.235482692718506\n",
      "Epoch 122/399\n",
      "43.25570845603943\n",
      "Epoch 123/399\n",
      "43.221206188201904\n",
      "Epoch 124/399\n",
      "43.066843032836914\n",
      "Epoch 125/399\n",
      "43.17648243904114\n",
      "Epoch 126/399\n",
      "43.163365840911865\n",
      "Epoch 127/399\n",
      "43.20051980018616\n",
      "Epoch 128/399\n",
      "43.15798783302307\n",
      "Epoch 129/399\n",
      "43.096551179885864\n",
      "Epoch 130/399\n",
      "43.12038707733154\n",
      "Epoch 131/399\n",
      "43.006974935531616\n",
      "Epoch 132/399\n",
      "43.12195920944214\n",
      "Epoch 133/399\n",
      "43.23682379722595\n",
      "Epoch 134/399\n",
      "43.14021611213684\n",
      "Epoch 135/399\n",
      "43.09530758857727\n",
      "Epoch 136/399\n",
      "43.08020806312561\n",
      "Epoch 137/399\n",
      "43.113982915878296\n",
      "Epoch 138/399\n",
      "43.16946601867676\n",
      "Epoch 139/399\n",
      "43.15982747077942\n",
      "Epoch 140/399\n",
      "43.05425000190735\n",
      "Epoch 141/399\n",
      "43.082741498947144\n",
      "Epoch 142/399\n",
      "43.04989528656006\n",
      "Epoch 143/399\n",
      "43.01596450805664\n",
      "Epoch 144/399\n",
      "43.1950364112854\n",
      "Epoch 145/399\n",
      "43.00529074668884\n",
      "Epoch 146/399\n",
      "42.99689292907715\n",
      "Epoch 147/399\n",
      "43.05811405181885\n",
      "Epoch 148/399\n",
      "43.07489490509033\n",
      "Epoch 149/399\n",
      "43.047269105911255\n",
      "Epoch 150/399\n",
      "43.15255928039551\n",
      "Epoch 151/399\n",
      "43.14977693557739\n",
      "Epoch 152/399\n",
      "43.072925090789795\n",
      "Epoch 153/399\n",
      "43.03894662857056\n",
      "Epoch 154/399\n",
      "43.116050243377686\n",
      "Epoch 155/399\n",
      "43.203248500823975\n",
      "Epoch 156/399\n",
      "43.229432821273804\n",
      "Epoch 157/399\n",
      "43.10783672332764\n",
      "Epoch 158/399\n",
      "43.125523805618286\n",
      "Epoch 159/399\n",
      "43.189459800720215\n",
      "Epoch 160/399\n",
      "43.144052505493164\n",
      "Epoch 161/399\n",
      "43.287869691848755\n",
      "Epoch 162/399\n",
      "43.127914905548096\n",
      "Epoch 163/399\n",
      "43.172993898391724\n",
      "Epoch 164/399\n",
      "43.089269399642944\n",
      "Epoch 165/399\n",
      "43.106263875961304\n",
      "Epoch 166/399\n",
      "43.20316934585571\n",
      "Epoch 167/399\n",
      "43.21847438812256\n",
      "Epoch 168/399\n",
      "43.05968451499939\n",
      "Epoch 169/399\n",
      "43.1664023399353\n",
      "Epoch 170/399\n",
      "43.17286229133606\n",
      "Epoch 171/399\n",
      "43.07966732978821\n",
      "Epoch 172/399\n",
      "43.11750864982605\n",
      "Epoch 173/399\n",
      "43.29296040534973\n",
      "Epoch 174/399\n",
      "43.19470977783203\n",
      "Epoch 175/399\n",
      "43.13286781311035\n",
      "Epoch 176/399\n",
      "43.134833335876465\n",
      "Epoch 177/399\n",
      "43.137473344802856\n",
      "Epoch 178/399\n",
      "43.294856786727905\n",
      "Epoch 179/399\n",
      "43.132500886917114\n",
      "Epoch 180/399\n",
      "43.15145993232727\n",
      "Epoch 181/399\n",
      "43.11719346046448\n",
      "Epoch 182/399\n",
      "43.113479137420654\n",
      "Epoch 183/399\n",
      "43.06446576118469\n",
      "Epoch 184/399\n",
      "43.10385489463806\n",
      "Epoch 185/399\n",
      "43.038949728012085\n",
      "Epoch 186/399\n",
      "43.084557056427\n",
      "Epoch 187/399\n",
      "43.05112838745117\n",
      "Epoch 188/399\n",
      "42.98668432235718\n",
      "Epoch 189/399\n",
      "43.09804677963257\n",
      "Epoch 190/399\n",
      "43.237398862838745\n",
      "Epoch 191/399\n",
      "43.06649661064148\n",
      "Epoch 192/399\n",
      "43.0462441444397\n",
      "Epoch 193/399\n",
      "43.049198389053345\n",
      "Epoch 194/399\n",
      "43.120845079422\n",
      "Epoch 195/399\n",
      "43.182438373565674\n",
      "Epoch 196/399\n",
      "43.077982664108276\n",
      "Epoch 197/399\n",
      "43.12327194213867\n",
      "Epoch 198/399\n",
      "43.16745185852051\n",
      "Epoch 199/399\n",
      "43.169095516204834\n",
      "Epoch 200/399\n",
      "43.16444540023804\n",
      "Epoch 201/399\n",
      "43.203815937042236\n",
      "Epoch 202/399\n",
      "43.17716979980469\n",
      "Epoch 203/399\n",
      "43.177199363708496\n",
      "Epoch 204/399\n",
      "43.18572497367859\n",
      "Epoch 205/399\n",
      "43.17168641090393\n",
      "Epoch 206/399\n",
      "43.1302285194397\n",
      "Epoch 207/399\n",
      "43.2574622631073\n",
      "Epoch 208/399\n",
      "43.0599901676178\n",
      "Epoch 209/399\n",
      "43.083056688308716\n",
      "Epoch 210/399\n",
      "43.076143980026245\n",
      "Epoch 211/399\n",
      "43.035810232162476\n",
      "Epoch 212/399\n",
      "43.195663928985596\n",
      "Epoch 213/399\n",
      "43.12465286254883\n",
      "Epoch 214/399\n",
      "43.070953607559204\n",
      "Epoch 215/399\n",
      "43.0634765625\n",
      "Epoch 216/399\n",
      "43.16036939620972\n",
      "Epoch 217/399\n",
      "43.09397482872009\n",
      "Epoch 218/399\n",
      "43.24486708641052\n",
      "Epoch 219/399\n",
      "43.080992221832275\n",
      "Epoch 220/399\n",
      "43.15519881248474\n",
      "Epoch 221/399\n",
      "43.06769585609436\n",
      "Epoch 222/399\n",
      "43.095155477523804\n",
      "Epoch 223/399\n",
      "43.0862352848053\n",
      "Epoch 224/399\n",
      "43.19277763366699\n",
      "Epoch 225/399\n",
      "43.02338171005249\n",
      "Epoch 226/399\n",
      "43.067333936691284\n",
      "Epoch 227/399\n",
      "42.851778507232666\n",
      "Epoch 228/399\n",
      "42.80330538749695\n",
      "Epoch 229/399\n",
      "43.067012310028076\n",
      "Epoch 230/399\n",
      "42.839205741882324\n",
      "Epoch 231/399\n",
      "42.95028018951416\n",
      "Epoch 232/399\n",
      "42.94071173667908\n",
      "Epoch 233/399\n",
      "42.91138696670532\n",
      "Epoch 234/399\n",
      "42.888145446777344\n",
      "Epoch 235/399\n",
      "42.98887610435486\n",
      "Epoch 236/399\n",
      "42.94407320022583\n",
      "Epoch 237/399\n",
      "42.897271394729614\n",
      "Epoch 238/399\n",
      "42.97412443161011\n",
      "Epoch 239/399\n",
      "42.965491771698\n",
      "Epoch 240/399\n",
      "42.926392793655396\n",
      "Epoch 241/399\n",
      "43.094616651535034\n",
      "Epoch 242/399\n",
      "42.94315719604492\n",
      "Epoch 243/399\n",
      "43.03180503845215\n",
      "Epoch 244/399\n",
      "42.997076749801636\n",
      "Epoch 245/399\n",
      "43.01421308517456\n",
      "Epoch 246/399\n",
      "43.1864287853241\n",
      "Epoch 247/399\n",
      "42.99385404586792\n",
      "Epoch 248/399\n",
      "43.02787637710571\n",
      "Epoch 249/399\n",
      "43.1212842464447\n",
      "Epoch 250/399\n",
      "43.064523696899414\n",
      "Epoch 251/399\n",
      "43.096068382263184\n",
      "Epoch 252/399\n",
      "43.18022108078003\n",
      "Epoch 253/399\n",
      "43.004459857940674\n",
      "Epoch 254/399\n",
      "43.09650945663452\n",
      "Epoch 255/399\n",
      "42.9732551574707\n",
      "Epoch 256/399\n",
      "43.0359365940094\n",
      "Epoch 257/399\n",
      "43.22563886642456\n",
      "Epoch 258/399\n",
      "43.05886268615723\n",
      "Epoch 259/399\n",
      "43.1278760433197\n",
      "Epoch 260/399\n",
      "43.100093841552734\n",
      "Epoch 261/399\n",
      "43.015602111816406\n",
      "Epoch 262/399\n",
      "43.09840178489685\n",
      "Epoch 263/399\n",
      "43.19510293006897\n",
      "Epoch 264/399\n",
      "43.110268354415894\n",
      "Epoch 265/399\n",
      "43.05677509307861\n",
      "Epoch 266/399\n",
      "42.97695231437683\n",
      "Epoch 267/399\n",
      "42.84929609298706\n",
      "Epoch 268/399\n",
      "42.94165253639221\n",
      "Epoch 269/399\n",
      "43.05640411376953\n",
      "Epoch 270/399\n",
      "42.83445382118225\n",
      "Epoch 271/399\n",
      "42.827486991882324\n",
      "Epoch 272/399\n",
      "42.918355226516724\n",
      "Epoch 273/399\n",
      "42.83608794212341\n",
      "Epoch 274/399\n",
      "42.97077798843384\n",
      "Epoch 275/399\n",
      "42.971803188323975\n",
      "Epoch 276/399\n",
      "42.84247040748596\n",
      "Epoch 277/399\n",
      "42.873178243637085\n",
      "Epoch 278/399\n",
      "42.899144649505615\n",
      "Epoch 279/399\n",
      "43.009140729904175\n",
      "Epoch 280/399\n",
      "43.23368740081787\n",
      "Epoch 281/399\n",
      "42.9989333152771\n",
      "Epoch 282/399\n",
      "43.00867962837219\n",
      "Epoch 283/399\n",
      "43.12027287483215\n",
      "Epoch 284/399\n",
      "43.07555556297302\n",
      "Epoch 285/399\n",
      "43.02737903594971\n",
      "Epoch 286/399\n",
      "43.224920988082886\n",
      "Epoch 287/399\n",
      "43.10061073303223\n",
      "Epoch 288/399\n",
      "43.157262086868286\n",
      "Epoch 289/399\n",
      "43.1086266040802\n",
      "Epoch 290/399\n",
      "43.07510447502136\n",
      "Epoch 291/399\n",
      "43.18264818191528\n",
      "Epoch 292/399\n",
      "43.13994741439819\n",
      "Epoch 293/399\n",
      "43.09638714790344\n",
      "Epoch 294/399\n",
      "43.14363932609558\n",
      "Epoch 295/399\n",
      "43.09428358078003\n",
      "Epoch 296/399\n",
      "43.127129793167114\n",
      "Epoch 297/399\n",
      "43.21104693412781\n",
      "Epoch 298/399\n",
      "43.04486060142517\n",
      "Epoch 299/399\n",
      "43.03747844696045\n",
      "Epoch 300/399\n",
      "43.00454044342041\n",
      "Epoch 301/399\n",
      "42.97024655342102\n",
      "Epoch 302/399\n",
      "42.92949056625366\n",
      "Epoch 303/399\n",
      "42.94919300079346\n",
      "Epoch 304/399\n",
      "42.92789387702942\n",
      "Epoch 305/399\n",
      "42.83442497253418\n",
      "Epoch 306/399\n",
      "42.860458850860596\n",
      "Epoch 307/399\n",
      "42.88969159126282\n",
      "Epoch 308/399\n",
      "43.06975317001343\n",
      "Epoch 309/399\n",
      "42.90591835975647\n",
      "Epoch 310/399\n",
      "42.82636547088623\n",
      "Epoch 311/399\n",
      "42.92889857292175\n",
      "Epoch 312/399\n",
      "42.836323738098145\n",
      "Epoch 313/399\n",
      "42.881638050079346\n",
      "Epoch 314/399\n",
      "43.15911674499512\n",
      "Epoch 315/399\n",
      "43.0175895690918\n",
      "Epoch 316/399\n",
      "42.89088726043701\n",
      "Epoch 317/399\n",
      "43.02609086036682\n",
      "Epoch 318/399\n",
      "43.0218825340271\n",
      "Epoch 319/399\n",
      "43.02970910072327\n",
      "Epoch 320/399\n",
      "43.24260950088501\n",
      "Epoch 321/399\n",
      "43.065433502197266\n",
      "Epoch 322/399\n",
      "43.10517597198486\n",
      "Epoch 323/399\n",
      "43.054999113082886\n",
      "Epoch 324/399\n",
      "43.16641616821289\n",
      "Epoch 325/399\n",
      "43.25012922286987\n",
      "Epoch 326/399\n",
      "43.102649450302124\n",
      "Epoch 327/399\n",
      "43.165300607681274\n",
      "Epoch 328/399\n",
      "43.08725047111511\n",
      "Epoch 329/399\n",
      "43.211777448654175\n",
      "Epoch 330/399\n",
      "43.15077805519104\n",
      "Epoch 331/399\n",
      "43.27196216583252\n",
      "Epoch 332/399\n",
      "43.11362814903259\n",
      "Epoch 333/399\n",
      "43.05868983268738\n",
      "Epoch 334/399\n",
      "43.148601055145264\n",
      "Epoch 335/399\n",
      "43.17069435119629\n",
      "Epoch 336/399\n",
      "43.13323259353638\n",
      "Epoch 337/399\n",
      "43.21758556365967\n",
      "Epoch 338/399\n",
      "43.06000733375549\n",
      "Epoch 339/399\n",
      "43.11787509918213\n",
      "Epoch 340/399\n",
      "43.171515703201294\n",
      "Epoch 341/399\n",
      "43.10533308982849\n",
      "Epoch 342/399\n",
      "43.220924854278564\n",
      "Epoch 343/399\n",
      "43.11530637741089\n",
      "Epoch 344/399\n",
      "43.128084897994995\n",
      "Epoch 345/399\n",
      "43.11587476730347\n",
      "Epoch 346/399\n",
      "43.09028100967407\n",
      "Epoch 347/399\n",
      "43.08087778091431\n",
      "Epoch 348/399\n",
      "43.14736580848694\n",
      "Epoch 349/399\n",
      "43.044102907180786\n",
      "Epoch 350/399\n",
      "43.05567026138306\n",
      "Epoch 351/399\n",
      "43.087637186050415\n",
      "Epoch 352/399\n",
      "43.031858682632446\n",
      "Epoch 353/399\n",
      "43.034340381622314\n",
      "Epoch 354/399\n",
      "43.125452518463135\n",
      "Epoch 355/399\n",
      "43.00995349884033\n",
      "Epoch 356/399\n",
      "43.02816104888916\n",
      "Epoch 357/399\n",
      "43.02927112579346\n",
      "Epoch 358/399\n",
      "43.08555364608765\n",
      "Epoch 359/399\n",
      "43.159284353256226\n",
      "Epoch 360/399\n",
      "43.16822695732117\n",
      "Epoch 361/399\n",
      "43.0740704536438\n",
      "Epoch 362/399\n",
      "43.12503218650818\n",
      "Epoch 363/399\n",
      "43.1789824962616\n",
      "Epoch 364/399\n",
      "43.17140436172485\n",
      "Epoch 365/399\n",
      "43.24581503868103\n",
      "Epoch 366/399\n",
      "43.118752241134644\n",
      "Epoch 367/399\n",
      "43.14441919326782\n",
      "Epoch 368/399\n",
      "43.17006254196167\n",
      "Epoch 369/399\n",
      "43.14345979690552\n",
      "Epoch 370/399\n",
      "43.21605849266052\n",
      "Epoch 371/399\n",
      "43.11207914352417\n",
      "Epoch 372/399\n",
      "43.16605472564697\n",
      "Epoch 373/399\n",
      "43.132704734802246\n",
      "Epoch 374/399\n",
      "43.165083169937134\n",
      "Epoch 375/399\n",
      "43.11859107017517\n",
      "Epoch 376/399\n",
      "43.229368925094604\n",
      "Epoch 377/399\n",
      "43.15064787864685\n",
      "Epoch 378/399\n",
      "43.14267325401306\n",
      "Epoch 379/399\n",
      "43.11047339439392\n",
      "Epoch 380/399\n",
      "43.09515619277954\n",
      "Epoch 381/399\n",
      "43.171536922454834\n",
      "Epoch 382/399\n",
      "43.323044300079346\n",
      "Epoch 383/399\n",
      "43.104485273361206\n",
      "Epoch 384/399\n",
      "43.117653131484985\n",
      "Epoch 385/399\n",
      "43.21044898033142\n",
      "Epoch 386/399\n",
      "43.02736806869507\n",
      "Epoch 387/399\n",
      "43.12324666976929\n",
      "Epoch 388/399\n",
      "43.0160596370697\n",
      "Epoch 389/399\n",
      "42.96479606628418\n",
      "Epoch 390/399\n",
      "42.975653409957886\n",
      "Epoch 391/399\n",
      "43.0115225315094\n",
      "Epoch 392/399\n",
      "43.013994455337524\n",
      "Epoch 393/399\n",
      "43.09480881690979\n",
      "Epoch 394/399\n",
      "43.04998588562012\n",
      "Epoch 395/399\n",
      "42.89465069770813\n",
      "Epoch 396/399\n",
      "42.97994089126587\n",
      "Epoch 397/399\n",
      "42.941375970840454\n",
      "Epoch 398/399\n",
      "42.958680629730225\n",
      "Epoch 399/399\n",
      "43.11689019203186\n",
      "Training complete in 287m 10s\n",
      "Best val Acc: 0.934700\n"
     ]
    }
   ],
   "source": [
    "net_pugdrs = UPANets(args.filters, Num_class, args.blocks, img_size)  \n",
    "net_pugdrs.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "net_pugdrs.to(device)\n",
    "\n",
    "if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "    net_pugdrs = torch.nn.DataParallel(net_pugdrs)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "base_optimizer = optim.SGD\n",
    "optimizer = PUGDXRS(net_pugdrs.parameters(),\n",
    "                base_optimizer,\n",
    "                lr=args.lr,\n",
    "                max_epochs= args.epochs,\n",
    "                momentum=args.momentum,\n",
    "                weight_decay=args.wd,\n",
    "                min_beta_r = 0, \n",
    "                max_beta_r = 1, \n",
    "                method_r = 'cos',\n",
    "                min_beta_s = 0, \n",
    "                max_beta_s = 1,\n",
    "                method_s = 'sin',\n",
    "                dampening=0,   # 必须设置为0才能完全固定 \n",
    "                nesterov=False # 禁用Nesterov动量 \n",
    "                 )\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "\n",
    "net_pugdrs, metricsrs = train_model_alpha(net_pugdrs, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "model_path = \"./model/\"+args.datasets+\"/pugdrs_\" + str(optimizer.method_r) + str(optimizer.max_beta_r) + \"_\" + str(optimizer.min_beta_r) + \"_\" + str(optimizer.method_s) + str(optimizer.max_beta_s) + \"_\" + str(optimizer.min_beta_s) + \"_\" + str(args.epochs) + \".pth\"\n",
    "torch.save({\n",
    "    'model_state_dict': net_pugdrs.state_dict(), \n",
    "    'optimizer_state_dict': optimizer.state_dict()\n",
    "}, model_path) \n",
    "\n",
    "name = \"./results/\"+args.datasets+\"/pugdrs_\" + str(optimizer.method_r) + str(optimizer.max_beta_r) + \"_\" + str(optimizer.min_beta_r) + \"_\" + str(optimizer.method_s) + str(optimizer.max_beta_s) + \"_\" + str(optimizer.min_beta_s) + \"_\" + str(args.epochs) + \".json\"\n",
    "with open(name,  'w', encoding='utf-8') as f:\n",
    "    json.dump(metricsrs,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "672b77e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG-16 ResNet-18 DenseNet-121* growth rate in 16 UPANet-16 Overall Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "088d3670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## finetune\n",
    "\n",
    "# from transformers import ViTForImageClassification, DeiTForImageClassification \n",
    " \n",
    "# # 加载预训练模型 \n",
    "# vit_model = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224\", num_labels=10, ignore_mismatched_sizes=True, device_map=\"auto\", resume_download=True) \n",
    "# deit_model = DeiTForImageClassification.from_pretrained(\"facebook/deit-base-patch16-224\", num_labels=10, ignore_mismatched_sizes=True, device_map=\"auto\", resume_download=True) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd6b0f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau( \n",
    "#     optimizer,  # 绑定的优化器对象 \n",
    "#     mode='max',  # 监测指标模式 \n",
    "#     factor=0.5,  # 学习率衰减系数 \n",
    "#     patience=3   # 等待周期数 \n",
    "# )\n",
    "# for name, param in vit_model.named_parameters(): \n",
    "#     if 'encoder.layer.0'  in name:  # 冻结前N层 \n",
    "#         param.requires_grad  = False \n",
    "# # 修改分类头以适应CIFAR-10的10类 \n",
    "# vit_model.classifier  = torch.nn.Linear(vit_model.config.hidden_size,  10)\n",
    "# deit_model.classifier  = torch.nn.Linear(deit_model.config.hidden_size,  10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8923cee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(new_head.__dict__)\n",
    "# print(vars(new_head))\n",
    "# import optimizers\n",
    "# import importlib \n",
    "# importlib.reload(optimizers)   \n",
    "# from optimizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04c21966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_ft2 = timm.create_model('mobilenetv3_small_100', pretrained=True, num_classes=Num_class)\n",
    "# original_head = model_ft2.classifier   # MobileNetV3的分类头名为classifier \n",
    "# new_head = nn.Linear(original_head.in_features,  Num_class)\n",
    "# model_ft2 = model_ft2.to(device)\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# base_optimizer2 = optim.SGD\n",
    "# optimizer2 = PUGD2(model_ft2.parameters(),\n",
    "#                  base_optimizer2,\n",
    "#                  lr=args.lr,\n",
    "#                  momentum=args.momentum,\n",
    "#                  weight_decay=args.wd,\n",
    "#                  )\n",
    "\n",
    "\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "# exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer2, step_size=7, gamma=0.1)\n",
    "\n",
    "# model_ft2 = train_model2(model_ft2, criterion, optimizer2, exp_lr_scheduler, num_epochs=20) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
