{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c297172",
   "metadata": {},
   "source": [
    "Multi-level Perturbed Unit Gradient Descent, MPUGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51d2b3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data  import Subset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models  as models\n",
    "from types import SimpleNamespace \n",
    "import matplotlib.pyplot  as plt\n",
    "import numpy as np \n",
    "\n",
    "from optimizers import *\n",
    "from upanets import UPANets\n",
    "from torchsummary import summary\n",
    "import time, copy,timm\n",
    "import json\n",
    "import random \n",
    "import os\n",
    "from train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaa60ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "args = SimpleNamespace(\n",
    "    datasets='cifar_10',\n",
    "    batch_size = 500,\n",
    "    seed = 42,\n",
    "    lr=0.1, \n",
    "    momentum=0.9,\n",
    "    wd = 0.0005,\n",
    "    blocks = 1,\n",
    "    filters = 16,\n",
    "    epochs = 400,\n",
    "    start_epochs = 8\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bdda934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_all_seeds(seed=42):\n",
    "    # Python原生随机 \n",
    "    random.seed(seed) \n",
    "    # NumPy随机 \n",
    "    np.random.seed(seed) \n",
    "    # PyTorch随机 \n",
    "    torch.manual_seed(seed) \n",
    "    # CUDA随机（GPU相关）\n",
    "    torch.cuda.manual_seed_all(seed) \n",
    "    # CUDNN确定性模式 \n",
    "    torch.backends.cudnn.deterministic  = True \n",
    "    torch.backends.cudnn.benchmark  = False \n",
    " \n",
    "set_all_seeds(args.seed)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca2f2d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "557e50ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 50000, 'valid': 10000}\n"
     ]
    }
   ],
   "source": [
    "img_size = 32 # default image size for Cifar-10\n",
    "im_dimention = 32\n",
    "cifar_10_mean = [0.4914, 0.4822, 0.4465] \n",
    "cifar_10_std = [0.2023, 0.1994, 0.2010]\n",
    "cifar_100_mean = [0.5071, 0.4867, 0.4408]\n",
    "cifar_100_std = [0.2673, 0.2564, 0.2762]\n",
    "\n",
    "if args.datasets == 'cifar_10':\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize((im_dimention,im_dimention)),\n",
    "            transforms.RandomRotation(15,),\n",
    "            transforms.RandomCrop(im_dimention),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=cifar_10_mean, std=cifar_10_std)\n",
    "            # transforms.Lambda(lambda x: x.to(torch.float16))    # 最终输出FP16\n",
    "        ]),\n",
    "        # 'valid': transforms.Compose([\n",
    "        #     transforms.Resize((im_dimention,im_dimention)),\n",
    "        #     transforms.ToTensor(),\n",
    "        #     transforms.Normalize(mean=cifar_10_mean, std=cifar_10_std)\n",
    "        # ]),\n",
    "        'test': transforms.Compose([\n",
    "            transforms.Resize((im_dimention,im_dimention)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=cifar_10_mean, std=cifar_10_std)\n",
    "        ]),\n",
    "    }\n",
    " \n",
    "    full_trainset = torchvision.datasets.CIFAR10(\n",
    "        root='./data/cifar_10', train=True, download=True, transform=data_transforms['train'])\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root='./data/cifar_10', train=False, download=True, transform=data_transforms['test'])\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=args.batch_size, shuffle=False, num_workers=0)\n",
    "    Num_class = 10\n",
    "\n",
    "if args.datasets == 'cifar_100':\n",
    "    data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((im_dimention,im_dimention)),\n",
    "        transforms.RandomRotation(15,),\n",
    "        transforms.RandomCrop(im_dimention),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=cifar_100_mean, std=cifar_100_std)\n",
    "    ]),\n",
    "    # 'valid': transforms.Compose([\n",
    "    #     transforms.Resize((im_dimention,im_dimention)),\n",
    "    #     transforms.ToTensor(),\n",
    "    #     transforms.Normalize(mean=cifar_100_mean, std=cifar_100_std)\n",
    "    # ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((im_dimention,im_dimention)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=cifar_100_mean, std=cifar_100_std)\n",
    "    ]),\n",
    "    }\n",
    "    full_trainset = torchvision.datasets.CIFAR100(\n",
    "        root='./data/cifar_100', train=True, download=True, transform=data_transforms['train'])\n",
    "    testset = torchvision.datasets.CIFAR100(\n",
    "        root='./data/cifar_100', train=False, download=True, transform=data_transforms['test'])\n",
    "    testloader = DataLoader(\n",
    "        testset, batch_size=args.batch_size, shuffle=False,sampler=torch.utils.data.SequentialSampler(testset),  num_workers=0)\n",
    "    Num_class = 100\n",
    "\n",
    "# # 获取所有样本的标签 \n",
    "# labels = [full_trainset[i][1] for i in range(len(full_trainset))]\n",
    "\n",
    "# # 分层划分（stratify参数确保比例）\n",
    "# train_idx, val_idx = train_test_split(\n",
    "#     range(len(full_trainset)),\n",
    "#     test_size=0.2,\n",
    "#     shuffle=True,\n",
    "#     stratify=labels,\n",
    "#     random_state=args.seed  \n",
    "# )\n",
    "\n",
    "# train_data = np.stack([full_trainset.data[i]  for i in train_idx]) \n",
    "# train_targets = [full_trainset.targets[i] for i in train_idx] \n",
    "# val_data = np.stack([full_trainset.data[i]  for i in val_idx]) \n",
    "# val_targets = [full_trainset.targets[i] for i in val_idx] \n",
    "\n",
    "# valset = full_trainset\n",
    "# valset.data = val_data\n",
    "# valset.targets = val_targets\n",
    "# valset.transform = data_transforms['valid']\n",
    "\n",
    "# trainset = copy.deepcopy(valset)\n",
    "# trainset.data = train_data\n",
    "# trainset.targets = train_targets\n",
    "# trainset.transform = data_transforms['train']\n",
    "\n",
    "# trainloader = {\n",
    "#     'train':DataLoader(\n",
    "#     trainset, batch_size=args.batch_size, shuffle=False, sampler=torch.utils.data.SequentialSampler(trainset), num_workers=0),\n",
    "#     'valid':DataLoader(\n",
    "#     valset, batch_size=args.batch_size, shuffle=False, sampler=torch.utils.data.SequentialSampler(valset), num_workers=0)}\n",
    "\n",
    "# dataset_sizes = {\n",
    "#     'train': len(trainset),\n",
    "#     'valid': len(valset),            \n",
    "                #  }\n",
    "\n",
    "trainloader = {\n",
    "    'train':DataLoader(\n",
    "    full_trainset, batch_size=args.batch_size, shuffle=False, sampler=torch.utils.data.SequentialSampler(full_trainset), num_workers=0),\n",
    "    'valid':testloader\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "    'train': len(full_trainset),\n",
    "    'valid': len(testset),      \n",
    "}\n",
    "print(dataset_sizes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "840b5037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vit_tiny_patch16_224']\n"
     ]
    }
   ],
   "source": [
    "print(timm.list_models('*vit_tiny_patch16_224*')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ab5b31b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from torchvision.transforms.functional  import to_pil_image \n",
    "# 反归一化转换（需与transform中的参数对应）\n",
    "inv_normalize = transforms.Normalize(\n",
    "    mean=[-0.4914/0.2023, -0.4822/0.1994, -0.4465/0.2010],\n",
    "    std=[1/0.2023, 1/0.1994, 1/0.2010]\n",
    ")\n",
    " \n",
    "def show_images(loader, num_images=4):\n",
    "    # 获取一个batch的数据 \n",
    "    # images, labels = next(iter(loader))\n",
    "    for batch_idx, (images, labels) in enumerate(loader):\n",
    "        if batch_idx == 0:  # 只取第一个batch \n",
    "            break \n",
    "\n",
    "    # 创建子图 \n",
    "    fig, axes = plt.subplots(1,  num_images, figsize=(15, 3))\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        # 反归一化+通道顺序调整 \n",
    "        img = inv_normalize(images[i]).permute(1, 2, 0).numpy()\n",
    "        img = np.clip(img,  0, 1)  # 处理浮点误差 \n",
    "        \n",
    "        # 显示图像及标签 \n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f\"Label: {full_trainset.classes[labels[i]]}\") \n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.show() \n",
    " \n",
    "show_images(trainloader['train'])\n",
    "show_images(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5aa47f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./model/\" + args.datasets + \"/benchmark.pth\"\n",
    "if os.path.exists(model_path):\n",
    "    net_benckmark_data = torch.load(model_path,  map_location='cpu')\n",
    "    benckmark_state_dict = net_benckmark_data['model_state_dict'] \n",
    "else:\n",
    "    net_benchmark = UPANets(args.filters, Num_class, args.blocks, img_size)\n",
    "    torch.save({\n",
    "        'model_state_dict': net_benchmark.state_dict()\n",
    "    }, model_path)\n",
    "    benckmark_state_dict = net_benchmark.state_dict()\n",
    "\n",
    "def tensor_to_serializable(obj):\n",
    "    if isinstance(obj, (np.float32,  np.float64)):   # 处理NumPy浮点数\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.integer):               # 处理NumPy整数 \n",
    "        return int(obj)\n",
    "    elif isinstance(obj, torch.Tensor):            # 处理PyTorch Tensor \n",
    "        return obj.item()  if obj.numel()  == 1 else obj.tolist() \n",
    "    elif isinstance(obj, (np.ndarray)):             # 处理NumPy数组 \n",
    "        return obj.tolist() \n",
    "    elif hasattr(obj, '__dict__'):                 # 处理自定义对象（可选）\n",
    "        return obj.__dict__\n",
    "    return obj \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3ec9786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pugdt_delta = UPANets(args.filters, Num_class, args.blocks, img_size)  \n",
    "# net_pugdt_delta.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net_pugdt_delta.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     net_pugdt_delta = torch.nn.DataParallel(net_pugdt_delta)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDXT(net_pugdt_delta.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=args.lr,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                 )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "\n",
    "# net_pugdt_delta, metricst_delta = train_model_timing_delta(net_pugdt_delta, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes, int(args.epochs/10), 0.01, 10) \n",
    "\n",
    "# model_path = \"./model/\"+args.datasets+\"/pugdt_delta_\" + str(args.epochs) + \"xi\" + str(args.epochs/10) + \"mu0.01_t10.pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net_pugdt_delta.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/pugdt_delta_\" + str(args.epochs) + \"xi\" + str(args.epochs/10) + \"mu0.01_t10.json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metricst_delta,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efb925b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pugdt_var = UPANets(args.filters, Num_class, args.blocks, img_size)  \n",
    "# net_pugdt_var.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net_pugdt_var.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     net_pugdt_var = torch.nn.DataParallel(net_pugdt_var)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDXT(net_pugdt_var.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=args.lr,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                 )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "\n",
    "# net_pugdt_var, metricst_var = train_model_timing_var(net_pugdt_var, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes, int(args.epochs/10), 0.015, 10) \n",
    "\n",
    "# model_path = \"./model/\"+args.datasets+\"/pugdt_var_\" + str(args.epochs) + \"init_t\" + str(args.epochs/10) + \"gamma0.015_k10.pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net_pugdt_var.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/pugdt_var_\" + str(args.epochs) + \"init_t\" + str(args.epochs/10) + \"gamma0.015_k10.json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metricst_var,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a42d18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = UPANets(args.filters, Num_class, args.blocks, img_size)\n",
    "# net.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     net = torch.nn.DataParallel(net)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# optimizer = optim.SGD(net.parameters(),\n",
    "#                 lr=args.lr,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                  )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "# # exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# net, metrics_org = train_model_org(net, criterion, optimizer, scheduler, args.epochs * 2, trainloader, device, dataset_sizes) \n",
    "\n",
    "# # 保存模型架构+参数+优化器状态（完整恢复训练）\n",
    "# model_path = \"./model/\"+args.datasets+\"/org\" + str(args.epochs) + \".pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/org_\" + str(args.epochs) + \".json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metrics_org, f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n",
    " \n",
    "# # 加载 \n",
    "\n",
    "# # checkpoint = torch.load('full_model_checkpoint.pth',  map_location='cpu')  # 先加载到CPU避免设备冲突 \n",
    "# # 模型结构需提前定义（需与保存时一致）\n",
    "# # model = YourModelClass()  \n",
    "# # model.load_state_dict(checkpoint['model_state_dict']) \n",
    " \n",
    "# # # 恢复优化器和训练状态 \n",
    "# # optimizer = torch.optim.Adam(model.parameters())  \n",
    "# # optimizer.load_state_dict(checkpoint['optimizer_state_dict']) \n",
    "# # with open('data.json',  'r', encoding='utf-8') as f:\n",
    "# #     loaded_dict = json.load(f) \n",
    "\n",
    "\n",
    "# # summary(net, (3, img_size, img_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0db0a205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pugdr_sin = UPANets(args.filters, Num_class, args.blocks, img_size)\n",
    "# net_pugdr_sin.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net_pugdr_sin.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     model_ft_org = torch.nn.DataParallel(net_pugdr_sin)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDXR(net_pugdr_sin.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=args.lr,\n",
    "#                 max_epochs= args.epochs,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 min_beta = 0.2, \n",
    "#                 max_beta = 2.0, \n",
    "#                 method = 'sin',\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                 )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "# # exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# net_pugdr_sin, metricsr_sin = train_model_alpha(net_pugdr_sin, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "# model_path = \"./model/\"+args.datasets+\"/pugdr_sin\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net_pugdr_sin.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/pugdr_sin_\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metricsr_sin,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c82cb0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pugdr_cos = UPANets(args.filters, Num_class, args.blocks, img_size)\n",
    "# net_pugdr_cos.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net_pugdr_cos.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     model_ft_org = torch.nn.DataParallel(net_pugdr_cos)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDXR(net_pugdr_cos.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=args.lr,\n",
    "#                 max_epochs= args.epochs,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 min_beta = 0.001, \n",
    "#                 max_beta = 2.0, \n",
    "#                 method = 'cos',\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                 )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "# # exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# net_pugdr_cos, metricsr_sin = train_model_alpha(net_pugdr_cos, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "# model_path = \"./model/\"+args.datasets+\"/pugdr_cos\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net_pugdr_cos.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/pugdr_cos_\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metricsr_sin,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db4abe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "#     if metricsr_sin['bast_acc'] < 0.7234:\n",
    "#         net_pugdr_cos = UPANets(args.filters, Num_class, args.blocks, img_size)\n",
    "#         net_pugdr_cos.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "#         criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#         net_pugdr_cos.to(device)\n",
    "\n",
    "#         if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#             model_ft_org = torch.nn.DataParallel(net_pugdr_cos)\n",
    "#             cudnn.benchmark = True\n",
    "\n",
    "#         base_optimizer = optim.SGD\n",
    "#         optimizer = PUGDXR(net_pugdr_cos.parameters(),\n",
    "#                         base_optimizer,\n",
    "#                         lr=args.lr,\n",
    "#                         max_epochs= args.epochs,\n",
    "#                         momentum=args.momentum,\n",
    "#                         weight_decay=args.wd,\n",
    "#                         min_beta = 0.0, \n",
    "#                         max_beta = 2.0, \n",
    "#                         method = 'cos',\n",
    "#                         dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                         nesterov=False # 禁用Nesterov动量 \n",
    "#                         )\n",
    "\n",
    "#         scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "#         # Decay LR by a factor of 0.1 every 7 epochs\n",
    "#         # exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "#         net_pugdr_cos, metricsr_sin = train_model_alpha(net_pugdr_cos, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "#         model_path = \"./model/\"+args.datasets+\"/pugdr_cos\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".pth\"\n",
    "#         torch.save({\n",
    "#             'model_state_dict': net_pugdr_cos.state_dict(), \n",
    "#             'optimizer_state_dict': optimizer.state_dict()\n",
    "#         }, model_path) \n",
    "\n",
    "#         name = \"./results/\"+args.datasets+\"/pugdr_cos_\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".json\"\n",
    "#         with open(name,  'w', encoding='utf-8') as f:\n",
    "#             json.dump(metricsr_sin,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a514712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pugdr_cos = UPANets(args.filters, Num_class, args.blocks, img_size)\n",
    "# net_pugdr_cos.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net_pugdr_cos.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     model_ft_org = torch.nn.DataParallel(net_pugdr_cos)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDXR(net_pugdr_cos.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=args.lr,\n",
    "#                 max_epochs= args.epochs,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 min_beta = 0.0, \n",
    "#                 max_beta = 3.0, \n",
    "#                 method = 'cos',\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                 )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "# # exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# net_pugdr_cos, metricsr_sin = train_model_alpha(net_pugdr_cos, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "# model_path = \"./model/\"+args.datasets+\"/pugdr_cos\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net_pugdr_cos.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/pugdr_cos_\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metricsr_sin,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be3e5d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pugds_cos = UPANets(args.filters, Num_class, args.blocks, img_size)  \n",
    "# net_pugds_cos.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net_pugds_cos.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     net_pugds_cos = torch.nn.DataParallel(net_pugds_cos)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDXS(net_pugds_cos.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=args.lr,\n",
    "#                 max_epochs= args.epochs,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 min_beta = 1.2, \n",
    "#                 max_beta = 3.0,\n",
    "#                 method = 'cos',\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                  )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "# # exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# net_pugds_cos, metricss_cos = train_model_alpha(net_pugds_cos, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "# model_path = \"./model/\"+args.datasets+\"/pugds_cos\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net_pugds_cos.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/pugds_cos_\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metricss_cos,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14e79fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pugds_sin = UPANets(args.filters, Num_class, args.blocks, img_size)  \n",
    "# net_pugds_sin.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net_pugds_sin.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     net_pugds_sin = torch.nn.DataParallel(net_pugds_sin)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDXS(net_pugds_sin.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=args.lr,\n",
    "#                 max_epochs= args.epochs,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 min_beta = 1.8, \n",
    "#                 max_beta = 2.0,\n",
    "#                 method = 'sin',\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                  )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "\n",
    "# net_pugds_sin, metricss_sin = train_model_alpha(net_pugds_sin, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "# model_path = \"./model/\"+args.datasets+\"/pugds_sin\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net_pugds_sin.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/pugds_sin_\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metricss_sin,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1d2ef1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pugd = UPANets(args.filters, Num_class, args.blocks, img_size)  \n",
    "# net_pugd.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net_pugd.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     model_ft_org = torch.nn.DataParallel(net_pugd)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDX(net_pugd.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=args.lr,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                  )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "# # exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# net_pugd, metrics0 = train_model(net_pugd, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "# model_path = \"./model/\"+args.datasets+\"/pugd\" + str(args.epochs) + \".pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net_pugd.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/pugd_\" + str(args.epochs) + \".json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metrics0,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c195537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pugdr_cos = UPANets(args.filters, Num_class, args.blocks, img_size)  \n",
    "# net_pugdr_cos.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net_pugdr_cos.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     model_ft_org = torch.nn.DataParallel(net_pugdr_cos)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDXR(net_pugdr_cos.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=args.lr,\n",
    "#                 max_epochs= args.epochs,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 min_beta = 0.3, \n",
    "#                 max_beta = 1, \n",
    "#                 method = 'icos',\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                 )\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "\n",
    "# net_pugdr_cos, metricsr_cos = train_model_alpha(net_pugdr_cos, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "# model_path = \"./model/\"+args.datasets+\"/pugdr_icos\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net_pugdr_cos.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/pugdr_icos_\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metricsr_cos,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10cf6955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pugdr_sin = UPANets(args.filters, Num_class, args.blocks, img_size)\n",
    "# net_pugdr_sin.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net_pugdr_sin.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     model_ft_org = torch.nn.DataParallel(net_pugdr_sin)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDXR(net_pugdr_sin.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=args.lr,\n",
    "#                 max_epochs= args.epochs,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 min_beta = 0.1, \n",
    "#                 max_beta = 1, \n",
    "#                 method = 'isin',\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                 )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "# # exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# net_pugdr_sin, metricsr_sin = train_model_alpha(net_pugdr_sin, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "# model_path = \"./model/\"+args.datasets+\"/pugdr_isin\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net_pugdr_sin.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/pugdr_isin_\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metricsr_sin,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6b645d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pugds_icos = UPANets(args.filters, Num_class, args.blocks, img_size)  \n",
    "# net_pugds_icos.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net_pugds_icos.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     net_pugds_icos = torch.nn.DataParallel(net_pugds_icos)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDXS(net_pugds_icos.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=args.lr,\n",
    "#                 max_epochs= args.epochs,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 min_beta = 0.01, \n",
    "#                 max_beta = 0.5, \n",
    "#                 method = 'icos',\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                  )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "\n",
    "# net_pugds_icos, metricss_icos = train_model_alpha(net_pugds_icos, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "# model_path = \"./model/\"+args.datasets+\"/pugds_icos\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net_pugds_icos.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/pugds_icos_\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metricss_icos,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9575fe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pugds_icos = UPANets(args.filters, Num_class, args.blocks, img_size)  \n",
    "# net_pugds_icos.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net_pugds_icos.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     net_pugds_icos = torch.nn.DataParallel(net_pugds_icos)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDXS(net_pugds_icos.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=args.lr,\n",
    "#                 max_epochs= args.epochs,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 min_beta = 0.05, \n",
    "#                 max_beta = 1.0, \n",
    "#                 method = 'icos',\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                  )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "\n",
    "# net_pugds_icos, metricss_icos = train_model_alpha(net_pugds_icos, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "# model_path = \"./model/\"+args.datasets+\"/pugds_icos\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net_pugds_icos.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/pugds_icos_\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metricss_icos,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "214741d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pugds_isin = UPANets(args.filters, Num_class, args.blocks, img_size)  \n",
    "# net_pugds_isin.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net_pugds_isin.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     net_pugds_isin = torch.nn.DataParallel(net_pugds_isin)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDXS(net_pugds_isin.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=args.lr,\n",
    "#                 max_epochs= args.epochs,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 min_beta = 0.1, \n",
    "#                 max_beta = 2,\n",
    "#                 method = 'isin',\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                  )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "# # exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# net_pugds_isin, metricss_isin = train_model_alpha(net_pugds_isin, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "# model_path = \"./model/\"+args.datasets+\"/pugds_isin\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net_pugds_isin.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/pugds_isin_\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metricss_isin,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "156b0bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pugdrs = UPANets(args.filters, Num_class, args.blocks, img_size)  \n",
    "# net_pugdrs.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net_pugdrs.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     net_pugdrs = torch.nn.DataParallel(net_pugdrs)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDXRS(net_pugdrs.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=args.lr,\n",
    "#                 max_epochs= args.epochs,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 min_beta_r = 0.01, \n",
    "#                 max_beta_r = 2, \n",
    "#                 method_r = 'isin',\n",
    "#                 min_beta_s = 0, \n",
    "#                 max_beta_s = 1.5,\n",
    "#                 method_s = 'cos',\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                  )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "\n",
    "# net_pugdrs, metricsrs = train_model_alpha(net_pugdrs, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "# model_path = \"./model/\"+args.datasets+\"/pugdrs_\" + str(optimizer.method_r) + str(optimizer.max_beta_r) + \"_\" + str(optimizer.min_beta_r) + \"_\" + str(optimizer.method_s) + str(optimizer.max_beta_s) + \"_\" + str(optimizer.min_beta_s) + \"_\" + str(args.epochs) + \".pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net_pugdrs.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/pugdrs_\" + str(optimizer.method_r) + str(optimizer.max_beta_r) + \"_\" + str(optimizer.min_beta_r) + \"_\" + str(optimizer.method_s) + str(optimizer.max_beta_s) + \"_\" + str(optimizer.min_beta_s) + \"_\" + str(args.epochs) + \".json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metricsrs,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f20f6280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pugdrs = UPANets(args.filters, Num_class, args.blocks, img_size)  \n",
    "# net_pugdrs.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net_pugdrs.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     net_pugdrs = torch.nn.DataParallel(net_pugdrs)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDXRS(net_pugdrs.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=args.lr,\n",
    "#                 max_epochs= args.epochs,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 min_beta_r = 0.0,\n",
    "#                 max_beta_r = 2.0,\n",
    "#                 method_r = 'sin',\n",
    "#                 min_beta_s = 0.0, \n",
    "#                 max_beta_s = 2.0,\n",
    "#                 method_s = 'sin',\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                  )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "\n",
    "# net_pugdrs, metricsrs = train_model_alpha(net_pugdrs, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "# model_path = \"./model/\"+args.datasets+\"/pugdrs_\" + str(optimizer.method_r) + str(optimizer.max_beta_r) + \"_\" + str(optimizer.min_beta_r) + \"_\" + str(optimizer.method_s) + str(optimizer.max_beta_s) + \"_\" + str(optimizer.min_beta_s) + \"_\" + str(args.epochs) + \".pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net_pugdrs.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/pugdrs_\" + str(optimizer.method_r) + str(optimizer.max_beta_r) + \"_\" + str(optimizer.min_beta_r) + \"_\" + str(optimizer.method_s) + str(optimizer.max_beta_s) + \"_\" + str(optimizer.min_beta_s) + \"_\" + str(args.epochs) + \".json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metricsrs,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "672b77e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG-16 ResNet-18 DenseNet-121* growth rate in 16 UPANet-16 Overall Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "088d3670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## finetune\n",
    "\n",
    "# from transformers import ViTForImageClassification, DeiTForImageClassification \n",
    " \n",
    "# # 加载预训练模型 \n",
    "# vit_model = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224\", num_labels=10, ignore_mismatched_sizes=True, device_map=\"auto\", resume_download=True) \n",
    "# deit_model = DeiTForImageClassification.from_pretrained(\"facebook/deit-base-patch16-224\", num_labels=10, ignore_mismatched_sizes=True, device_map=\"auto\", resume_download=True) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd6b0f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau( \n",
    "#     optimizer,  # 绑定的优化器对象 \n",
    "#     mode='max',  # 监测指标模式 \n",
    "#     factor=0.5,  # 学习率衰减系数 \n",
    "#     patience=3   # 等待周期数 \n",
    "# )\n",
    "# for name, param in vit_model.named_parameters(): \n",
    "#     if 'encoder.layer.0'  in name:  # 冻结前N层 \n",
    "#         param.requires_grad  = False \n",
    "# # 修改分类头以适应CIFAR-10的10类 \n",
    "# vit_model.classifier  = torch.nn.Linear(vit_model.config.hidden_size,  10)\n",
    "# deit_model.classifier  = torch.nn.Linear(deit_model.config.hidden_size,  10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8923cee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(new_head.__dict__)\n",
    "# print(vars(new_head))\n",
    "# import optimizers\n",
    "# import importlib \n",
    "# importlib.reload(optimizers)   \n",
    "# from optimizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "04c21966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_ft2 = timm.create_model('mobilenetv3_small_100', pretrained=True, num_classes=Num_class)\n",
    "# original_head = model_ft2.classifier   # MobileNetV3的分类头名为classifier \n",
    "# new_head = nn.Linear(original_head.in_features,  Num_class)\n",
    "# model_ft2 = model_ft2.to(device)\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# base_optimizer2 = optim.SGD\n",
    "# optimizer2 = PUGD2(model_ft2.parameters(),\n",
    "#                  base_optimizer2,\n",
    "#                  lr=args.lr,\n",
    "#                  momentum=args.momentum,\n",
    "#                  weight_decay=args.wd,\n",
    "#                  )\n",
    "\n",
    "\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "# exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer2, step_size=7, gamma=0.1)\n",
    "\n",
    "# model_ft2 = train_model2(model_ft2, criterion, optimizer2, exp_lr_scheduler, num_epochs=20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5bd8ce5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft_epochs = 300\n",
    "# os.environ.update({ \n",
    "#     \"HF_ENDPOINT\": \"https://hf-mirror.com\", \n",
    "#     \"HF_HUB_OFFLINE\": \"0\",  # 确保非离线模式 \n",
    "#     \"HF_HUB_DISABLE_TELEMETRY\": \"1\",  # 禁用检测请求 \n",
    "#     \"HF_CDN_DOMAIN\": \"hf-mirror.com\", \n",
    "#     \"HF_S3_ENDPOINT\": \"hf-mirror.com\", \n",
    "#     \"TRANSFORMERS_OFFLINE\": \"0\",       # transformers专用设置 \n",
    "#     \"HF_DATASETS_OFFLINE\": \"0\"         # datasets专用设置 \n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0696aaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests \n",
    "# endpoints = [\"https://hf-mirror.com\",  \"https://huggingface.co\"] \n",
    "# for url in endpoints:\n",
    "#     try:\n",
    "#         r = requests.get(f\"{url}/api/models\",  timeout=5)\n",
    "#         print(f\"{url} 响应状态: {r.status_code}\") \n",
    "#     except Exception as e:\n",
    "#         print(f\"{url} 连接失败: {type(e).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "01616389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft_epochs = 300\n",
    "# # 加载预训练ResNet18\n",
    "# resnet18 = models.resnet18(weights=(\"pretrained\", models.ResNet18_Weights.IMAGENET1K_V1))\n",
    "\n",
    "# # 冻结所有卷积层\n",
    "# # for name, param in resnet18.named_parameters(): \n",
    "# #     if 'fc' not in name:  # 排除最后的全连接层\n",
    "# #         param.requires_grad  = False\n",
    "\n",
    "# resnet18.fc  = torch.nn.Linear(resnet18.fc.in_features,  Num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f9179dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet18_copy1 = copy.deepcopy(resnet18)\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# resnet18_copy1.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     model_ft_org = torch.nn.DataParallel(resnet18_copy1)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDX(resnet18_copy1.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=0.01,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                  )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=ft_epochs)\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "# # exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# resnet18_copy1, metrics0 = train_model(resnet18_copy1, criterion, optimizer, scheduler, ft_epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "# model_path = \"./model/lfs/\"+args.datasets+\"/resnet18_pugd\" + str(ft_epochs) + \".pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': resnet18_copy1.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/resnet18_pugd_\" + str(ft_epochs) + \".json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metrics0,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "86811ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet18_copy1 = copy.deepcopy(resnet18)\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# resnet18_copy1.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     model_ft_org = torch.nn.DataParallel(resnet18_copy1)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDXR(resnet18_copy1.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=0.01,\n",
    "#                 max_epochs= args.epochs,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 min_beta = 0.5, \n",
    "#                 max_beta = 1, \n",
    "#                 method = 'isin',\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                 )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=ft_epochs)\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "# # exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# resnet18_copy1, metrics0 = train_model(resnet18_copy1, criterion, optimizer, scheduler, ft_epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "# model_path = \"./model/lfs/\"+args.datasets+\"/resnet18_pugdr_\" + str(optimizer.method) + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(ft_epochs) + \".pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': resnet18_copy1.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/resnet18_pugdr_\" + str(optimizer.method) + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" +  str(ft_epochs) + \".json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metrics0,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1eab5450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import ViTImageProcessor, ViTForImageClassification\n",
    "ft_epochs = 200\n",
    "# 加载预训练ViT-B/16\n",
    "vit = timm.create_model('google/vit_base_patch16_224',  pretrained=True, \n",
    "                        img_size = 32, patch_size = 8, num_classes = Num_class)\n",
    "\n",
    "# vit = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224',\n",
    "#                                                 img_size = 32, patch_size = 8, num_classes = Num_class)\n",
    "# 冻结除head外的所有层\n",
    "# for name, param in vit.named_parameters(): \n",
    "#     if 'heads.head'  not in name:  # 仅保留分类头可训练\n",
    "#         param.requires_grad  = False\n",
    "\n",
    "# vit.heads.head  = torch.nn.Linear(vit.heads.head.in_features,  Num_class)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6f1b21be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vit_copy1 = copy.deepcopy(vit)\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# vit_copy1.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     model_ft_org = torch.nn.DataParallel(vit_copy1)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDX(vit_copy1.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=0.001,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                  )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=ft_epochs)\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "# # exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# vit_copy1, metrics0 = train_model(vit_copy1, criterion, optimizer, scheduler, ft_epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "# model_path = \"./model/lfs/\"+args.datasets+\"/vit_pugd\" + str(ft_epochs) + \".pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': vit_copy1.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/vit_pugd_\" + str(ft_epochs) + \".json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metrics0,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "63a6477f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:182: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.87724614143372\n",
      "Epoch 1/199\n",
      "85.90487122535706\n",
      "Epoch 2/199\n",
      "86.41270136833191\n",
      "Epoch 3/199\n",
      "86.61857795715332\n",
      "Epoch 4/199\n",
      "86.77046632766724\n",
      "Epoch 5/199\n",
      "87.4020471572876\n",
      "Epoch 6/199\n",
      "87.34405565261841\n",
      "Epoch 7/199\n",
      "87.23957777023315\n",
      "Epoch 8/199\n",
      "87.3390622138977\n",
      "Epoch 9/199\n",
      "87.75760293006897\n",
      "Epoch 10/199\n",
      "87.8286201953888\n",
      "Epoch 11/199\n",
      "87.91956782341003\n",
      "Epoch 12/199\n",
      "88.0678493976593\n",
      "Epoch 13/199\n",
      "87.9237711429596\n",
      "Epoch 14/199\n",
      "87.99692225456238\n",
      "Epoch 15/199\n",
      "88.17928576469421\n",
      "Epoch 16/199\n",
      "88.0247106552124\n",
      "Epoch 17/199\n",
      "88.11230134963989\n",
      "Epoch 18/199\n",
      "88.18818664550781\n",
      "Epoch 19/199\n",
      "88.28498601913452\n",
      "Epoch 20/199\n",
      "88.19757890701294\n",
      "Epoch 21/199\n",
      "88.28112125396729\n",
      "Epoch 22/199\n",
      "88.3425087928772\n",
      "Epoch 23/199\n",
      "88.22291946411133\n",
      "Epoch 24/199\n",
      "88.27940583229065\n",
      "Epoch 25/199\n",
      "88.262442111969\n",
      "Epoch 26/199\n",
      "88.28119707107544\n",
      "Epoch 27/199\n",
      "88.48531794548035\n",
      "Epoch 28/199\n",
      "88.31579828262329\n",
      "Epoch 29/199\n",
      "88.2794201374054\n",
      "Epoch 30/199\n",
      "88.30577373504639\n",
      "Epoch 31/199\n",
      "88.35963606834412\n",
      "Epoch 32/199\n",
      "88.28270149230957\n",
      "Epoch 33/199\n",
      "88.56455278396606\n",
      "Epoch 34/199\n",
      "88.44101238250732\n",
      "Epoch 35/199\n",
      "88.30054235458374\n",
      "Epoch 36/199\n",
      "88.42303729057312\n",
      "Epoch 37/199\n",
      "88.32544565200806\n",
      "Epoch 38/199\n",
      "88.27629113197327\n",
      "Epoch 39/199\n",
      "88.4602153301239\n",
      "Epoch 40/199\n",
      "88.26178812980652\n",
      "Epoch 41/199\n",
      "88.26337909698486\n",
      "Epoch 42/199\n",
      "88.27797651290894\n",
      "Epoch 43/199\n",
      "88.2798683643341\n",
      "Epoch 44/199\n",
      "88.35228824615479\n",
      "Epoch 45/199\n",
      "88.49626755714417\n",
      "Epoch 46/199\n",
      "88.32235407829285\n",
      "Epoch 47/199\n",
      "88.32518887519836\n",
      "Epoch 48/199\n",
      "88.34436178207397\n",
      "Epoch 49/199\n",
      "88.477956533432\n",
      "Epoch 50/199\n",
      "88.45778846740723\n",
      "Epoch 51/199\n",
      "88.38306307792664\n",
      "Epoch 52/199\n",
      "88.32133388519287\n",
      "Epoch 53/199\n",
      "87.98459148406982\n",
      "Epoch 54/199\n",
      "87.87429785728455\n",
      "Epoch 55/199\n",
      "87.59755182266235\n",
      "Epoch 56/199\n",
      "87.62394976615906\n",
      "Epoch 57/199\n",
      "87.58346247673035\n",
      "Epoch 58/199\n",
      "87.6202003955841\n",
      "Epoch 59/199\n",
      "87.47847032546997\n",
      "Epoch 60/199\n",
      "87.46128988265991\n",
      "Epoch 61/199\n",
      "87.44177484512329\n",
      "Epoch 62/199\n",
      "87.30064988136292\n",
      "Epoch 63/199\n",
      "87.34030199050903\n",
      "Epoch 64/199\n",
      "87.58020520210266\n",
      "Epoch 65/199\n",
      "87.64320969581604\n",
      "Epoch 66/199\n",
      "87.8275089263916\n",
      "Epoch 67/199\n",
      "87.94225072860718\n",
      "Epoch 68/199\n",
      "87.96214318275452\n",
      "Epoch 69/199\n",
      "88.11667251586914\n",
      "Epoch 70/199\n",
      "88.2929298877716\n",
      "Epoch 71/199\n",
      "88.05392718315125\n",
      "Epoch 72/199\n",
      "88.10720920562744\n",
      "Epoch 73/199\n",
      "88.18375062942505\n",
      "Epoch 74/199\n",
      "88.25525116920471\n",
      "Epoch 75/199\n",
      "88.2446436882019\n",
      "Epoch 76/199\n",
      "88.41149663925171\n",
      "Epoch 77/199\n",
      "88.33886218070984\n",
      "Epoch 78/199\n",
      "88.351886510849\n",
      "Epoch 79/199\n",
      "88.29674053192139\n",
      "Epoch 80/199\n",
      "88.44096159934998\n",
      "Epoch 81/199\n",
      "88.40518879890442\n",
      "Epoch 82/199\n",
      "88.44426703453064\n",
      "Epoch 83/199\n",
      "88.34248924255371\n",
      "Epoch 84/199\n",
      "88.38044786453247\n",
      "Epoch 85/199\n",
      "88.42387199401855\n",
      "Epoch 86/199\n",
      "88.31927394866943\n",
      "Epoch 87/199\n",
      "88.4659674167633\n",
      "Epoch 88/199\n",
      "88.52828311920166\n",
      "Epoch 89/199\n",
      "88.4272129535675\n",
      "Epoch 90/199\n",
      "88.43351912498474\n",
      "Epoch 91/199\n",
      "88.47648119926453\n",
      "Epoch 92/199\n",
      "88.3367817401886\n",
      "Epoch 93/199\n",
      "88.44766807556152\n",
      "Epoch 94/199\n",
      "88.4550621509552\n",
      "Epoch 95/199\n",
      "88.60978484153748\n",
      "Epoch 96/199\n",
      "88.42975878715515\n",
      "Epoch 97/199\n",
      "88.40197992324829\n",
      "Epoch 98/199\n",
      "88.4965705871582\n",
      "Epoch 99/199\n",
      "88.53209066390991\n",
      "Epoch 100/199\n",
      "88.46882700920105\n",
      "Epoch 101/199\n",
      "88.59375190734863\n",
      "Epoch 102/199\n",
      "88.49854469299316\n",
      "Epoch 103/199\n",
      "88.48681139945984\n",
      "Epoch 104/199\n",
      "88.4605975151062\n",
      "Epoch 105/199\n",
      "88.50944304466248\n",
      "Epoch 106/199\n",
      "88.47708773612976\n",
      "Epoch 107/199\n",
      "88.60047054290771\n",
      "Epoch 108/199\n",
      "88.46989941596985\n",
      "Epoch 109/199\n",
      "88.5292899608612\n",
      "Epoch 110/199\n",
      "88.45434617996216\n",
      "Epoch 111/199\n",
      "88.4888596534729\n",
      "Epoch 112/199\n",
      "88.56640338897705\n",
      "Epoch 113/199\n",
      "88.67674708366394\n",
      "Epoch 114/199\n",
      "88.50315284729004\n",
      "Epoch 115/199\n",
      "88.52187156677246\n",
      "Epoch 116/199\n",
      "88.42055916786194\n",
      "Epoch 117/199\n",
      "88.4245228767395\n",
      "Epoch 118/199\n",
      "88.51917290687561\n",
      "Epoch 119/199\n",
      "88.71483373641968\n",
      "Epoch 120/199\n",
      "88.48577904701233\n",
      "Epoch 121/199\n",
      "88.48269581794739\n",
      "Epoch 122/199\n",
      "88.44148445129395\n",
      "Epoch 123/199\n",
      "88.44130086898804\n",
      "Epoch 124/199\n",
      "88.48570489883423\n",
      "Epoch 125/199\n",
      "88.5194661617279\n",
      "Epoch 126/199\n",
      "88.65887665748596\n",
      "Epoch 127/199\n",
      "88.50275444984436\n",
      "Epoch 128/199\n",
      "88.55400395393372\n",
      "Epoch 129/199\n",
      "88.62960505485535\n",
      "Epoch 130/199\n",
      "88.444899559021\n",
      "Epoch 131/199\n",
      "88.57564401626587\n",
      "Epoch 132/199\n",
      "88.68351459503174\n",
      "Epoch 133/199\n",
      "88.54442477226257\n",
      "Epoch 134/199\n",
      "88.5466148853302\n",
      "Epoch 135/199\n",
      "88.62360000610352\n",
      "Epoch 136/199\n",
      "88.4346489906311\n",
      "Epoch 137/199\n",
      "88.47805285453796\n",
      "Epoch 138/199\n",
      "88.59986281394958\n",
      "Epoch 139/199\n",
      "88.57505917549133\n",
      "Epoch 140/199\n",
      "88.45926284790039\n",
      "Epoch 141/199\n",
      "88.45822811126709\n",
      "Epoch 142/199\n",
      "88.46202373504639\n",
      "Epoch 143/199\n",
      "88.5618908405304\n",
      "Epoch 144/199\n",
      "88.75056862831116\n",
      "Epoch 145/199\n",
      "88.5272467136383\n",
      "Epoch 146/199\n",
      "88.54247975349426\n",
      "Epoch 147/199\n",
      "88.62383389472961\n",
      "Epoch 148/199\n",
      "88.40180587768555\n",
      "Epoch 149/199\n",
      "88.58199858665466\n",
      "Epoch 150/199\n",
      "88.66057562828064\n",
      "Epoch 151/199\n",
      "88.5399010181427\n",
      "Epoch 152/199\n",
      "88.48357701301575\n",
      "Epoch 153/199\n",
      "88.4984803199768\n",
      "Epoch 154/199\n",
      "88.46279954910278\n",
      "Epoch 155/199\n",
      "88.62862730026245\n",
      "Epoch 156/199\n",
      "88.71928763389587\n",
      "Epoch 157/199\n",
      "88.57290482521057\n",
      "Epoch 158/199\n",
      "88.5276551246643\n",
      "Epoch 159/199\n",
      "88.6027581691742\n",
      "Epoch 160/199\n",
      "88.38178777694702\n",
      "Epoch 161/199\n",
      "88.48975801467896\n",
      "Epoch 162/199\n",
      "88.56740736961365\n",
      "Epoch 163/199\n",
      "88.61478447914124\n",
      "Epoch 164/199\n",
      "88.47243165969849\n",
      "Epoch 165/199\n",
      "88.51542925834656\n",
      "Epoch 166/199\n",
      "88.5639476776123\n",
      "Epoch 167/199\n",
      "88.51636958122253\n",
      "Epoch 168/199\n",
      "88.48869109153748\n",
      "Epoch 169/199\n",
      "88.70561218261719\n",
      "Epoch 170/199\n",
      "88.56727123260498\n",
      "Epoch 171/199\n",
      "88.4907009601593\n",
      "Epoch 172/199\n",
      "88.30937957763672\n",
      "Epoch 173/199\n",
      "88.37438726425171\n",
      "Epoch 174/199\n",
      "88.30548095703125\n",
      "Epoch 175/199\n",
      "88.67423439025879\n",
      "Epoch 176/199\n",
      "88.32665300369263\n",
      "Epoch 177/199\n",
      "88.42146229743958\n",
      "Epoch 178/199\n",
      "88.44374465942383\n",
      "Epoch 179/199\n",
      "88.48491048812866\n",
      "Epoch 180/199\n",
      "88.3202633857727\n",
      "Epoch 181/199\n",
      "88.43371105194092\n",
      "Epoch 182/199\n",
      "88.34501314163208\n",
      "Epoch 183/199\n",
      "88.36005687713623\n",
      "Epoch 184/199\n",
      "88.46119952201843\n",
      "Epoch 185/199\n",
      "88.32163763046265\n",
      "Epoch 186/199\n",
      "88.48445343971252\n",
      "Epoch 187/199\n",
      "88.56093835830688\n",
      "Epoch 188/199\n",
      "88.33979272842407\n",
      "Epoch 189/199\n",
      "88.38182020187378\n",
      "Epoch 190/199\n",
      "88.32507348060608\n",
      "Epoch 191/199\n",
      "88.32088899612427\n",
      "Epoch 192/199\n",
      "88.431955575943\n",
      "Epoch 193/199\n",
      "88.48791575431824\n",
      "Epoch 194/199\n",
      "88.46326112747192\n",
      "Epoch 195/199\n",
      "88.42118716239929\n",
      "Epoch 196/199\n",
      "88.34643054008484\n",
      "Epoch 197/199\n",
      "88.39928150177002\n",
      "Epoch 198/199\n",
      "88.44432735443115\n",
      "Epoch 199/199\n",
      "88.60729765892029\n",
      "Training complete in 294m 16s\n",
      "Best val Acc: 0.965100\n"
     ]
    }
   ],
   "source": [
    "vit_copy1 = copy.deepcopy(vit)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "vit_copy1.to(device)\n",
    "\n",
    "if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "    model_ft_org = torch.nn.DataParallel(vit_copy1)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "base_optimizer = optim.SGD\n",
    "optimizer = PUGDXR(vit_copy1.parameters(),\n",
    "                base_optimizer,\n",
    "                lr=0.001,\n",
    "                momentum=args.momentum,\n",
    "                weight_decay=args.wd,\n",
    "                min_beta = 0.5, \n",
    "                max_beta = 1.5, \n",
    "                method = 'cos',\n",
    "                dampening=0,   # 必须设置为0才能完全固定 \n",
    "                nesterov=False # 禁用Nesterov动量 \n",
    "                 )\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=ft_epochs)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "# exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "vit_copy1, metrics0 = train_model(vit_copy1, criterion, optimizer, scheduler, ft_epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "model_path = \"./model/lfs/\"+args.datasets+\"/vit_pugdr_\" + str(optimizer.method) + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(ft_epochs) + \".pth\"\n",
    "torch.save({\n",
    "    'model_state_dict': vit_copy1.state_dict(), \n",
    "    'optimizer_state_dict': optimizer.state_dict()\n",
    "}, model_path) \n",
    "\n",
    "name = \"./results/\"+args.datasets+\"/vit_pugdr_\" + str(optimizer.method) + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(ft_epochs) + \".json\"\n",
    "with open(name,  'w', encoding='utf-8') as f:\n",
    "    json.dump(metrics0,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1a7f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 加载预训练DeiT-B/16\n",
    "deit = timm.create_model('deit_base_patch16_224', pretrained=True, \n",
    "                        img_size = 32, patch_size = 8, num_classes = Num_class)\n",
    "# # 冻结所有层除了分类token和head\n",
    "# for name, param in deit.named_parameters(): \n",
    "#     if not name.startswith(('cls_token',  'pos_embed', 'head')):\n",
    "#         param.requires_grad  = False\n",
    "\n",
    "# # 修改分类头（20类任务示例）\n",
    "# deit.head  = torch.nn.Linear(deit.head.in_features,  Num_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bff32bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/199\n",
      "87.36373162269592\n",
      "Epoch 1/199\n",
      "87.66708898544312\n",
      "Epoch 2/199\n",
      "87.77909445762634\n",
      "Epoch 3/199\n",
      "87.92526483535767\n",
      "Epoch 4/199\n",
      "88.17939448356628\n",
      "Epoch 5/199\n",
      "88.0432550907135\n",
      "Epoch 6/199\n",
      "88.20689368247986\n",
      "Epoch 7/199\n",
      "88.07237386703491\n",
      "Epoch 8/199\n",
      "88.14583683013916\n",
      "Epoch 9/199\n",
      "88.18096208572388\n",
      "Epoch 10/199\n",
      "88.35973811149597\n",
      "Epoch 11/199\n",
      "88.28013563156128\n",
      "Epoch 12/199\n",
      "88.14469957351685\n",
      "Epoch 13/199\n",
      "88.23258781433105\n",
      "Epoch 14/199\n",
      "88.28969240188599\n",
      "Epoch 15/199\n",
      "88.26137948036194\n",
      "Epoch 16/199\n",
      "88.4018394947052\n",
      "Epoch 17/199\n",
      "88.71781349182129\n",
      "Epoch 18/199\n",
      "88.47157883644104\n",
      "Epoch 19/199\n",
      "88.35945844650269\n",
      "Epoch 20/199\n",
      "88.17918586730957\n",
      "Epoch 21/199\n",
      "88.06010413169861\n",
      "Epoch 22/199\n",
      "87.97826099395752\n",
      "Epoch 23/199\n",
      "87.82339358329773\n",
      "Epoch 24/199\n",
      "87.63494658470154\n",
      "Epoch 25/199\n",
      "87.48317241668701\n",
      "Epoch 26/199\n",
      "87.45754384994507\n",
      "Epoch 27/199\n",
      "87.36549162864685\n",
      "Epoch 28/199\n",
      "87.54567337036133\n",
      "Epoch 29/199\n",
      "87.90935921669006\n",
      "Epoch 30/199\n",
      "87.95722937583923\n",
      "Epoch 31/199\n",
      "88.04326581954956\n",
      "Epoch 32/199\n",
      "88.09952425956726\n",
      "Epoch 33/199\n",
      "88.09599685668945\n",
      "Epoch 34/199\n",
      "88.1416494846344\n",
      "Epoch 35/199\n",
      "88.14320349693298\n",
      "Epoch 36/199\n",
      "88.22527360916138\n",
      "Epoch 37/199\n",
      "88.18123006820679\n",
      "Epoch 38/199\n",
      "88.25945329666138\n",
      "Epoch 39/199\n",
      "88.13184833526611\n",
      "Epoch 40/199\n",
      "87.84307479858398\n",
      "Epoch 41/199\n",
      "87.7412531375885\n",
      "Epoch 42/199\n",
      "87.52217626571655\n",
      "Epoch 43/199\n",
      "87.40374565124512\n",
      "Epoch 44/199\n",
      "87.33839082717896\n",
      "Epoch 45/199\n",
      "87.36187267303467\n",
      "Epoch 46/199\n",
      "87.3778829574585\n",
      "Epoch 47/199\n",
      "87.44188094139099\n",
      "Epoch 48/199\n",
      "87.2630786895752\n",
      "Epoch 49/199\n",
      "87.51749014854431\n",
      "Epoch 50/199\n",
      "87.58741736412048\n",
      "Epoch 51/199\n",
      "87.68616104125977\n",
      "Epoch 52/199\n",
      "87.93570566177368\n",
      "Epoch 53/199\n",
      "87.53215503692627\n",
      "Epoch 54/199\n",
      "87.42487215995789\n",
      "Epoch 55/199\n",
      "87.79181742668152\n",
      "Epoch 56/199\n",
      "88.4673273563385\n",
      "Epoch 57/199\n",
      "88.53905749320984\n",
      "Epoch 58/199\n",
      "88.51383304595947\n",
      "Epoch 59/199\n",
      "88.55910634994507\n",
      "Epoch 60/199\n",
      "88.52119588851929\n",
      "Epoch 61/199\n",
      "88.47754693031311\n",
      "Epoch 62/199\n",
      "88.48439288139343\n",
      "Epoch 63/199\n",
      "88.40533137321472\n",
      "Epoch 64/199\n",
      "88.46105337142944\n",
      "Epoch 65/199\n",
      "88.35757422447205\n",
      "Epoch 66/199\n",
      "88.1210663318634\n",
      "Epoch 67/199\n",
      "87.92061400413513\n",
      "Epoch 68/199\n",
      "87.82110905647278\n",
      "Epoch 69/199\n",
      "87.79660534858704\n",
      "Epoch 70/199\n",
      "87.72614932060242\n",
      "Epoch 71/199\n",
      "87.76007604598999\n",
      "Epoch 72/199\n",
      "87.74070191383362\n",
      "Epoch 73/199\n",
      "87.9459810256958\n",
      "Epoch 74/199\n",
      "88.03818726539612\n",
      "Epoch 75/199\n",
      "88.14566898345947\n",
      "Epoch 76/199\n",
      "88.09502720832825\n",
      "Epoch 77/199\n",
      "88.10341620445251\n",
      "Epoch 78/199\n",
      "87.88953685760498\n",
      "Epoch 79/199\n",
      "87.88928604125977\n",
      "Epoch 80/199\n",
      "87.86462593078613\n",
      "Epoch 81/199\n",
      "87.93923902511597\n",
      "Epoch 82/199\n",
      "87.9237368106842\n",
      "Epoch 83/199\n",
      "88.10602569580078\n",
      "Epoch 84/199\n",
      "88.31781506538391\n",
      "Epoch 85/199\n",
      "88.222412109375\n",
      "Epoch 86/199\n",
      "88.29847812652588\n",
      "Epoch 87/199\n",
      "88.36617517471313\n",
      "Epoch 88/199\n",
      "88.39552164077759\n",
      "Epoch 89/199\n",
      "88.50478339195251\n",
      "Epoch 90/199\n",
      "88.64756989479065\n",
      "Epoch 91/199\n",
      "88.43760681152344\n",
      "Epoch 92/199\n",
      "88.44533896446228\n",
      "Epoch 93/199\n",
      "88.47975444793701\n",
      "Epoch 94/199\n",
      "88.43812394142151\n",
      "Epoch 95/199\n",
      "88.48943018913269\n",
      "Epoch 96/199\n",
      "88.653391122818\n",
      "Epoch 97/199\n",
      "88.51399397850037\n",
      "Epoch 98/199\n",
      "88.55091691017151\n",
      "Epoch 99/199\n",
      "88.64692640304565\n",
      "Epoch 100/199\n",
      "88.55346417427063\n",
      "Epoch 101/199\n",
      "88.55997037887573\n",
      "Epoch 102/199\n",
      "88.65076017379761\n",
      "Epoch 103/199\n",
      "88.47356534004211\n",
      "Epoch 104/199\n",
      "88.51707243919373\n",
      "Epoch 105/199\n",
      "88.52907085418701\n",
      "Epoch 106/199\n",
      "88.5601077079773\n",
      "Epoch 107/199\n",
      "88.505850315094\n",
      "Epoch 108/199\n",
      "88.75200581550598\n",
      "Epoch 109/199\n",
      "88.54670810699463\n",
      "Epoch 110/199\n",
      "88.6221399307251\n",
      "Epoch 111/199\n",
      "88.62550854682922\n",
      "Epoch 112/199\n",
      "88.6158754825592\n",
      "Epoch 113/199\n",
      "88.51056790351868\n",
      "Epoch 114/199\n",
      "88.70352458953857\n",
      "Epoch 115/199\n",
      "88.5929594039917\n",
      "Epoch 116/199\n",
      "88.5708601474762\n",
      "Epoch 117/199\n",
      "88.63253617286682\n",
      "Epoch 118/199\n",
      "88.65028738975525\n",
      "Epoch 119/199\n",
      "88.57072019577026\n",
      "Epoch 120/199\n",
      "88.60986542701721\n",
      "Epoch 121/199\n",
      "88.70027136802673\n",
      "Epoch 122/199\n",
      "88.63266038894653\n",
      "Epoch 123/199\n",
      "88.65045833587646\n",
      "Epoch 124/199\n",
      "88.55286383628845\n",
      "Epoch 125/199\n",
      "88.5417046546936\n",
      "Epoch 126/199\n",
      "88.6217451095581\n",
      "Epoch 127/199\n",
      "88.62151432037354\n",
      "Epoch 128/199\n",
      "88.63613438606262\n",
      "Epoch 129/199\n",
      "88.63077354431152\n",
      "Epoch 130/199\n",
      "88.56304454803467\n",
      "Epoch 131/199\n",
      "88.55448150634766\n",
      "Epoch 132/199\n",
      "88.56567811965942\n",
      "Epoch 133/199\n",
      "88.75782799720764\n",
      "Epoch 134/199\n",
      "88.65870237350464\n",
      "Epoch 135/199\n",
      "88.64844751358032\n",
      "Epoch 136/199\n",
      "88.6671621799469\n",
      "Epoch 137/199\n",
      "88.61022329330444\n",
      "Epoch 138/199\n",
      "88.62405633926392\n",
      "Epoch 139/199\n",
      "88.71896505355835\n",
      "Epoch 140/199\n",
      "88.64750266075134\n",
      "Epoch 141/199\n",
      "88.59872364997864\n",
      "Epoch 142/199\n",
      "88.59199094772339\n",
      "Epoch 143/199\n",
      "88.64541292190552\n",
      "Epoch 144/199\n",
      "88.54157519340515\n",
      "Epoch 145/199\n",
      "88.66267943382263\n",
      "Epoch 146/199\n",
      "88.56419563293457\n",
      "Epoch 147/199\n",
      "88.61889410018921\n",
      "Epoch 148/199\n",
      "88.68998336791992\n",
      "Epoch 149/199\n",
      "88.69196319580078\n",
      "Epoch 150/199\n",
      "88.55461192131042\n",
      "Epoch 151/199\n",
      "88.64151501655579\n",
      "Epoch 152/199\n",
      "88.53728985786438\n",
      "Epoch 153/199\n",
      "88.52589702606201\n",
      "Epoch 154/199\n",
      "88.59509062767029\n",
      "Epoch 155/199\n",
      "88.54444479942322\n",
      "Epoch 156/199\n",
      "88.52341747283936\n",
      "Epoch 157/199\n",
      "88.67339587211609\n",
      "Epoch 158/199\n",
      "88.57664346694946\n",
      "Epoch 159/199\n",
      "88.60503554344177\n",
      "Epoch 160/199\n",
      "88.60876202583313\n",
      "Epoch 161/199\n",
      "88.59461402893066\n",
      "Epoch 162/199\n",
      "88.48804259300232\n",
      "Epoch 163/199\n",
      "88.60130047798157\n",
      "Epoch 164/199\n",
      "88.78768491744995\n",
      "Epoch 165/199\n",
      "88.49261569976807\n",
      "Epoch 166/199\n",
      "88.54254794120789\n",
      "Epoch 167/199\n",
      "88.56423330307007\n",
      "Epoch 168/199\n",
      "88.49972891807556\n",
      "Epoch 169/199\n",
      "88.69741535186768\n",
      "Epoch 170/199\n",
      "88.78624892234802\n",
      "Epoch 171/199\n",
      "88.60675644874573\n",
      "Epoch 172/199\n",
      "88.59859085083008\n",
      "Epoch 173/199\n",
      "88.57864427566528\n",
      "Epoch 174/199\n",
      "88.54312014579773\n",
      "Epoch 175/199\n",
      "88.66463375091553\n",
      "Epoch 176/199\n",
      "88.76305198669434\n",
      "Epoch 177/199\n",
      "88.55753350257874\n",
      "Epoch 178/199\n",
      "88.52286982536316\n",
      "Epoch 179/199\n",
      "88.67247605323792\n",
      "Epoch 180/199\n",
      "88.62298655509949\n",
      "Epoch 181/199\n",
      "88.64883732795715\n",
      "Epoch 182/199\n",
      "88.77458310127258\n",
      "Epoch 183/199\n",
      "88.62754654884338\n",
      "Epoch 184/199\n",
      "88.56050062179565\n",
      "Epoch 185/199\n",
      "88.32048535346985\n",
      "Epoch 186/199\n",
      "88.20306611061096\n",
      "Epoch 187/199\n",
      "88.03968548774719\n",
      "Epoch 188/199\n",
      "87.984619140625\n",
      "Epoch 189/199\n",
      "87.84924626350403\n",
      "Epoch 190/199\n",
      "87.83117413520813\n",
      "Epoch 191/199\n",
      "87.83971405029297\n",
      "Epoch 192/199\n",
      "87.74217319488525\n",
      "Epoch 193/199\n",
      "87.72165703773499\n",
      "Epoch 194/199\n",
      "87.7420117855072\n",
      "Epoch 195/199\n",
      "87.77940773963928\n",
      "Epoch 196/199\n",
      "87.68346905708313\n",
      "Epoch 197/199\n",
      "87.6208565235138\n",
      "Epoch 198/199\n",
      "87.64361310005188\n",
      "Epoch 199/199\n",
      "87.59049034118652\n",
      "Training complete in 294m 15s\n",
      "Best val Acc: 0.945900\n"
     ]
    }
   ],
   "source": [
    "# ft_epochs = 200\n",
    "# deit_copy1 = copy.deepcopy(deit)\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# deit_copy1.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     model_ft_org = torch.nn.DataParallel(deit_copy1)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDX(deit_copy1.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=0.0005,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                  )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=ft_epochs)\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "# # exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# deit_copy1, metrics0 = train_model(deit_copy1, criterion, optimizer, scheduler, ft_epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "# model_path = \"./model/lfs/\"+args.datasets+\"/deit_pugd\" + str(ft_epochs) + \".pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': deit_copy1.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/deit_pugd_\" + str(ft_epochs) + \".json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metrics0,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "370f7516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/199\n",
      "88.32758331298828\n",
      "Epoch 1/199\n",
      "88.29199314117432\n",
      "Epoch 2/199\n",
      "88.1731231212616\n",
      "Epoch 3/199\n",
      "88.2812008857727\n",
      "Epoch 4/199\n",
      "88.23700284957886\n",
      "Epoch 5/199\n",
      "88.28622269630432\n",
      "Epoch 6/199\n",
      "88.2003881931305\n",
      "Epoch 7/199\n",
      "88.16246199607849\n",
      "Epoch 8/199\n",
      "88.22003483772278\n",
      "Epoch 9/199\n",
      "88.18071174621582\n",
      "Epoch 10/199\n",
      "88.32339715957642\n",
      "Epoch 11/199\n",
      "88.28018999099731\n",
      "Epoch 12/199\n",
      "88.1215226650238\n",
      "Epoch 13/199\n",
      "88.20197701454163\n",
      "Epoch 14/199\n",
      "88.20319080352783\n",
      "Epoch 15/199\n",
      "88.36165618896484\n",
      "Epoch 16/199\n",
      "88.22915172576904\n",
      "Epoch 17/199\n",
      "88.23093247413635\n",
      "Epoch 18/199\n",
      "88.49565744400024\n",
      "Epoch 19/199\n",
      "88.34661149978638\n",
      "Epoch 20/199\n",
      "88.36492204666138\n",
      "Epoch 21/199\n",
      "88.18130946159363\n",
      "Epoch 22/199\n",
      "88.15992307662964\n",
      "Epoch 23/199\n",
      "88.2024416923523\n",
      "Epoch 24/199\n",
      "88.3881630897522\n",
      "Epoch 25/199\n",
      "88.17520904541016\n",
      "Epoch 26/199\n",
      "88.18876338005066\n",
      "Epoch 27/199\n",
      "88.2556312084198\n",
      "Epoch 28/199\n",
      "88.22472643852234\n",
      "Epoch 29/199\n",
      "88.26851654052734\n",
      "Epoch 30/199\n",
      "88.30961966514587\n",
      "Epoch 31/199\n",
      "88.12324094772339\n",
      "Epoch 32/199\n",
      "88.27435731887817\n",
      "Epoch 33/199\n",
      "88.20818614959717\n",
      "Epoch 34/199\n",
      "88.25797271728516\n",
      "Epoch 35/199\n",
      "88.25556135177612\n",
      "Epoch 36/199\n",
      "88.40958285331726\n",
      "Epoch 37/199\n",
      "88.16938972473145\n",
      "Epoch 38/199\n",
      "88.30596661567688\n",
      "Epoch 39/199\n",
      "88.32617902755737\n",
      "Epoch 40/199\n",
      "88.29810118675232\n",
      "Epoch 41/199\n",
      "88.18664479255676\n",
      "Epoch 42/199\n",
      "88.28320741653442\n",
      "Epoch 43/199\n",
      "88.20468759536743\n",
      "Epoch 44/199\n",
      "88.24361610412598\n",
      "Epoch 45/199\n",
      "88.19913077354431\n",
      "Epoch 46/199\n",
      "88.30155611038208\n",
      "Epoch 47/199\n",
      "88.22258758544922\n",
      "Epoch 48/199\n",
      "88.3414306640625\n",
      "Epoch 49/199\n",
      "88.25388288497925\n",
      "Epoch 50/199\n",
      "88.21092247962952\n",
      "Epoch 51/199\n",
      "88.30695462226868\n",
      "Epoch 52/199\n",
      "88.21427273750305\n",
      "Epoch 53/199\n",
      "88.20125341415405\n",
      "Epoch 54/199\n",
      "88.43395161628723\n",
      "Epoch 55/199\n",
      "88.300128698349\n",
      "Epoch 56/199\n",
      "88.26916480064392\n",
      "Epoch 57/199\n",
      "88.22185611724854\n",
      "Epoch 58/199\n",
      "88.27185249328613\n",
      "Epoch 59/199\n",
      "88.3313992023468\n",
      "Epoch 60/199\n",
      "88.36079621315002\n",
      "Epoch 61/199\n",
      "88.22664618492126\n",
      "Epoch 62/199\n",
      "88.31930899620056\n",
      "Epoch 63/199\n",
      "88.3827269077301\n",
      "Epoch 64/199\n",
      "88.31958794593811\n",
      "Epoch 65/199\n",
      "88.37076258659363\n",
      "Epoch 66/199\n",
      "88.3348388671875\n",
      "Epoch 67/199\n",
      "88.48273706436157\n",
      "Epoch 68/199\n",
      "88.23892951011658\n",
      "Epoch 69/199\n",
      "88.3151330947876\n",
      "Epoch 70/199\n",
      "88.25043392181396\n",
      "Epoch 71/199\n",
      "88.24080777168274\n",
      "Epoch 72/199\n",
      "88.23893117904663\n",
      "Epoch 73/199\n",
      "88.32044076919556\n",
      "Epoch 74/199\n",
      "88.34488415718079\n",
      "Epoch 75/199\n",
      "88.38219094276428\n",
      "Epoch 76/199\n",
      "88.29687118530273\n",
      "Epoch 77/199\n",
      "88.25864744186401\n",
      "Epoch 78/199\n",
      "88.24307775497437\n",
      "Epoch 79/199\n",
      "88.523029088974\n",
      "Epoch 80/199\n",
      "88.46569299697876\n",
      "Epoch 81/199\n",
      "88.31664228439331\n",
      "Epoch 82/199\n",
      "88.30170202255249\n",
      "Epoch 83/199\n",
      "88.30715417861938\n",
      "Epoch 84/199\n",
      "88.17714834213257\n",
      "Epoch 85/199\n",
      "88.53972101211548\n",
      "Epoch 86/199\n",
      "88.38316464424133\n",
      "Epoch 87/199\n",
      "88.32122945785522\n",
      "Epoch 88/199\n",
      "88.4109582901001\n",
      "Epoch 89/199\n",
      "88.30374646186829\n",
      "Epoch 90/199\n",
      "88.2923572063446\n",
      "Epoch 91/199\n",
      "88.5013039112091\n",
      "Epoch 92/199\n",
      "88.26353788375854\n",
      "Epoch 93/199\n",
      "88.34697270393372\n",
      "Epoch 94/199\n",
      "88.37497925758362\n",
      "Epoch 95/199\n",
      "88.17928171157837\n",
      "Epoch 96/199\n",
      "88.35160231590271\n",
      "Epoch 97/199\n",
      "88.46878600120544\n",
      "Epoch 98/199\n",
      "88.32362246513367\n",
      "Epoch 99/199\n",
      "88.37682175636292\n",
      "Epoch 100/199\n",
      "88.39489507675171\n",
      "Epoch 101/199\n",
      "88.36766195297241\n",
      "Epoch 102/199\n",
      "88.2604775428772\n",
      "Epoch 103/199\n",
      "88.46503615379333\n",
      "Epoch 104/199\n",
      "88.28968334197998\n",
      "Epoch 105/199\n",
      "88.25516605377197\n",
      "Epoch 106/199\n",
      "88.31963801383972\n",
      "Epoch 107/199\n",
      "88.3886661529541\n",
      "Epoch 108/199\n",
      "88.09573650360107\n",
      "Epoch 109/199\n",
      "88.1967933177948\n",
      "Epoch 110/199\n",
      "88.18548512458801\n",
      "Epoch 111/199\n",
      "87.94120240211487\n",
      "Epoch 112/199\n",
      "87.98171591758728\n",
      "Epoch 113/199\n",
      "87.92471766471863\n",
      "Epoch 114/199\n",
      "87.98989868164062\n",
      "Epoch 115/199\n",
      "88.09464621543884\n",
      "Epoch 116/199\n",
      "88.13869881629944\n",
      "Epoch 117/199\n",
      "88.04054594039917\n",
      "Epoch 118/199\n",
      "87.45060181617737\n",
      "Epoch 119/199\n",
      "87.50657486915588\n",
      "Epoch 120/199\n",
      "87.49667310714722\n",
      "Epoch 121/199\n",
      "88.20168709754944\n",
      "Epoch 122/199\n",
      "88.42750954627991\n",
      "Epoch 123/199\n",
      "88.33827209472656\n",
      "Epoch 124/199\n",
      "88.3637444972992\n",
      "Epoch 125/199\n",
      "88.25992035865784\n",
      "Epoch 126/199\n",
      "88.4399402141571\n",
      "Epoch 127/199\n",
      "88.41938090324402\n",
      "Epoch 128/199\n",
      "88.48489117622375\n",
      "Epoch 129/199\n",
      "88.43826222419739\n",
      "Epoch 130/199\n",
      "88.44678592681885\n",
      "Epoch 131/199\n",
      "88.40514016151428\n",
      "Epoch 132/199\n",
      "88.3476710319519\n",
      "Epoch 133/199\n",
      "88.44000101089478\n",
      "Epoch 134/199\n",
      "88.46693086624146\n",
      "Epoch 135/199\n",
      "88.33057045936584\n",
      "Epoch 136/199\n",
      "88.41417360305786\n",
      "Epoch 137/199\n",
      "88.36333727836609\n",
      "Epoch 138/199\n",
      "88.42384958267212\n",
      "Epoch 139/199\n",
      "88.39565443992615\n",
      "Epoch 140/199\n",
      "88.33371639251709\n",
      "Epoch 141/199\n",
      "88.25143337249756\n",
      "Epoch 142/199\n",
      "88.16192722320557\n",
      "Epoch 143/199\n",
      "88.14348602294922\n",
      "Epoch 144/199\n",
      "87.87988257408142\n",
      "Epoch 145/199\n",
      "87.87975144386292\n",
      "Epoch 146/199\n",
      "87.58230137825012\n",
      "Epoch 147/199\n",
      "87.7391152381897\n",
      "Epoch 148/199\n",
      "87.52316117286682\n",
      "Epoch 149/199\n",
      "87.72562956809998\n",
      "Epoch 150/199\n",
      "87.86522269248962\n",
      "Epoch 151/199\n",
      "87.89642786979675\n",
      "Epoch 152/199\n",
      "88.01801443099976\n",
      "Epoch 153/199\n",
      "88.22454881668091\n",
      "Epoch 154/199\n",
      "88.27619647979736\n",
      "Epoch 155/199\n",
      "88.12248611450195\n",
      "Epoch 156/199\n",
      "88.18090033531189\n",
      "Epoch 157/199\n",
      "88.1259298324585\n",
      "Epoch 158/199\n",
      "87.92199373245239\n",
      "Epoch 159/199\n",
      "88.13506937026978\n",
      "Epoch 160/199\n",
      "87.54327273368835\n",
      "Epoch 161/199\n",
      "87.54468941688538\n",
      "Epoch 162/199\n",
      "87.55871891975403\n",
      "Epoch 163/199\n",
      "87.54478144645691\n",
      "Epoch 164/199\n",
      "87.40117025375366\n",
      "Epoch 165/199\n",
      "87.53819179534912\n",
      "Epoch 166/199\n",
      "87.44382977485657\n",
      "Epoch 167/199\n",
      "87.31953740119934\n",
      "Epoch 168/199\n",
      "87.32651734352112\n",
      "Epoch 169/199\n",
      "87.41161561012268\n",
      "Epoch 170/199\n",
      "87.32569003105164\n",
      "Epoch 171/199\n",
      "87.42042684555054\n",
      "Epoch 172/199\n",
      "87.3061215877533\n",
      "Epoch 173/199\n",
      "87.32012891769409\n",
      "Epoch 174/199\n",
      "87.42234802246094\n",
      "Epoch 175/199\n",
      "87.45960259437561\n",
      "Epoch 176/199\n",
      "87.74321389198303\n",
      "Epoch 177/199\n",
      "87.90342688560486\n",
      "Epoch 178/199\n",
      "87.87816786766052\n",
      "Epoch 179/199\n",
      "87.96246671676636\n",
      "Epoch 180/199\n",
      "87.96509861946106\n",
      "Epoch 181/199\n",
      "87.98047661781311\n",
      "Epoch 182/199\n",
      "88.06107258796692\n",
      "Epoch 183/199\n",
      "88.19897174835205\n",
      "Epoch 184/199\n",
      "88.17992830276489\n",
      "Epoch 185/199\n",
      "88.16916799545288\n",
      "Epoch 186/199\n",
      "88.18394255638123\n",
      "Epoch 187/199\n",
      "88.30330777168274\n",
      "Epoch 188/199\n",
      "88.15115237236023\n",
      "Epoch 189/199\n",
      "88.21322989463806\n",
      "Epoch 190/199\n",
      "88.48034501075745\n",
      "Epoch 191/199\n",
      "88.33502674102783\n",
      "Epoch 192/199\n",
      "88.2602858543396\n",
      "Epoch 193/199\n",
      "88.30391120910645\n",
      "Epoch 194/199\n",
      "88.3873221874237\n",
      "Epoch 195/199\n",
      "88.26651692390442\n",
      "Epoch 196/199\n",
      "88.44298219680786\n",
      "Epoch 197/199\n",
      "88.40105175971985\n",
      "Epoch 198/199\n",
      "88.34798860549927\n",
      "Epoch 199/199\n",
      "88.17754292488098\n",
      "Training complete in 293m 53s\n",
      "Best val Acc: 0.947600\n"
     ]
    }
   ],
   "source": [
    "ft_epochs = 200\n",
    "deit_copy1 = copy.deepcopy(deit)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "deit_copy1.to(device)\n",
    "\n",
    "if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "    model_ft_org = torch.nn.DataParallel(deit_copy1)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "base_optimizer = optim.SGD\n",
    "optimizer = PUGDXR(deit_copy1.parameters(),\n",
    "                base_optimizer,\n",
    "                lr=0.0005,\n",
    "                momentum=args.momentum,\n",
    "                weight_decay=args.wd,\n",
    "                min_beta = 0.1, \n",
    "                max_beta = 2, \n",
    "                method = 'icos',\n",
    "                dampening=0,   # 必须设置为0才能完全固定 \n",
    "                nesterov=False # 禁用Nesterov动量 \n",
    "                 )\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=ft_epochs)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "# exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "deit_copy1, metrics0 = train_model(deit_copy1, criterion, optimizer, scheduler, ft_epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "model_path = \"./model/lfs/\"+args.datasets+\"/deit_pugdr_\" + str(optimizer.method) + str(optimizer.max_beta) + \"_\"  + str(optimizer.min_beta) + \"_\" + str(ft_epochs) + \".pth\"\n",
    "torch.save({\n",
    "    'model_state_dict': deit_copy1.state_dict(), \n",
    "    'optimizer_state_dict': optimizer.state_dict()\n",
    "}, model_path) \n",
    "\n",
    "name = \"./results/\"+args.datasets+\"/deit_pugdr_\" + str(optimizer.method) + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\"  + str(ft_epochs) + \".json\"\n",
    "with open(name,  'w', encoding='utf-8') as f:\n",
    "    json.dump(metrics0,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
