{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d229fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c297172",
   "metadata": {},
   "source": [
    "Multi-level Perturbed Unit Gradient Descent, MPUGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51d2b3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data  import Subset, DataLoader\n",
    "from sklearn.model_selection  import train_test_split \n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from types import SimpleNamespace \n",
    "import matplotlib.pyplot  as plt\n",
    "import numpy as np \n",
    "\n",
    "from optimizers import *\n",
    "from upanets import UPANets\n",
    "from torchsummary import summary\n",
    "import time, copy,timm\n",
    "import json\n",
    "import random \n",
    "import os\n",
    "from train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaa60ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "args = SimpleNamespace(\n",
    "    datasets='cifar_10',\n",
    "    batch_size = 500,\n",
    "    seed = 42,\n",
    "    lr=0.1, \n",
    "    momentum=0.9,\n",
    "    wd = 0.0005,\n",
    "    blocks = 1,\n",
    "    filters = 16,\n",
    "    epochs = 400,\n",
    "    start_epochs = 8\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bdda934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_all_seeds(seed=42):\n",
    "    # Python原生随机 \n",
    "    random.seed(seed) \n",
    "    # NumPy随机 \n",
    "    np.random.seed(seed) \n",
    "    # PyTorch随机 \n",
    "    torch.manual_seed(seed) \n",
    "    # CUDA随机（GPU相关）\n",
    "    torch.cuda.manual_seed_all(seed) \n",
    "    # CUDNN确定性模式 \n",
    "    torch.backends.cudnn.deterministic  = True \n",
    "    torch.backends.cudnn.benchmark  = False \n",
    " \n",
    "set_all_seeds(args.seed)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca2f2d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "557e50ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 50000, 'valid': 10000}\n"
     ]
    }
   ],
   "source": [
    "img_size = 32 # default image size for Cifar-10\n",
    "im_dimention = 32\n",
    "cifar_10_mean = [0.4914, 0.4822, 0.4465] \n",
    "cifar_10_std = [0.2023, 0.1994, 0.2010]\n",
    "cifar_100_mean = [0.5071, 0.4867, 0.4408]\n",
    "cifar_100_std = [0.2673, 0.2564, 0.2762]\n",
    "\n",
    "if args.datasets == 'cifar_10':\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize((im_dimention,im_dimention)),\n",
    "            transforms.RandomRotation(15,),\n",
    "            transforms.RandomCrop(im_dimention),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=cifar_10_mean, std=cifar_10_std)\n",
    "            # transforms.Lambda(lambda x: x.to(torch.float16))    # 最终输出FP16\n",
    "        ]),\n",
    "        # 'valid': transforms.Compose([\n",
    "        #     transforms.Resize((im_dimention,im_dimention)),\n",
    "        #     transforms.ToTensor(),\n",
    "        #     transforms.Normalize(mean=cifar_10_mean, std=cifar_10_std)\n",
    "        # ]),\n",
    "        'test': transforms.Compose([\n",
    "            transforms.Resize((im_dimention,im_dimention)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=cifar_10_mean, std=cifar_10_std)\n",
    "        ]),\n",
    "    }\n",
    " \n",
    "    full_trainset = torchvision.datasets.CIFAR10(\n",
    "        root='./data/cifar_10', train=True, download=True, transform=data_transforms['train'])\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root='./data/cifar_10', train=False, download=True, transform=data_transforms['test'])\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=args.batch_size, shuffle=False, num_workers=0)\n",
    "    Num_class = 10\n",
    "\n",
    "if args.datasets == 'cifar_100':\n",
    "    data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((im_dimention,im_dimention)),\n",
    "        transforms.RandomRotation(15,),\n",
    "        transforms.RandomCrop(im_dimention),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=cifar_100_mean, std=cifar_100_std)\n",
    "    ]),\n",
    "    # 'valid': transforms.Compose([\n",
    "    #     transforms.Resize((im_dimention,im_dimention)),\n",
    "    #     transforms.ToTensor(),\n",
    "    #     transforms.Normalize(mean=cifar_100_mean, std=cifar_100_std)\n",
    "    # ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((im_dimention,im_dimention)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=cifar_100_mean, std=cifar_100_std)\n",
    "    ]),\n",
    "    }\n",
    "    full_trainset = torchvision.datasets.CIFAR100(\n",
    "        root='./data/cifar_100', train=True, download=True, transform=data_transforms['train'])\n",
    "    testset = torchvision.datasets.CIFAR100(\n",
    "        root='./data/cifar_100', train=False, download=True, transform=data_transforms['test'])\n",
    "    testloader = DataLoader(\n",
    "        testset, batch_size=args.batch_size, shuffle=False,sampler=torch.utils.data.SequentialSampler(testset),  num_workers=0)\n",
    "    Num_class = 100\n",
    "\n",
    "# # 获取所有样本的标签 \n",
    "# labels = [full_trainset[i][1] for i in range(len(full_trainset))]\n",
    "\n",
    "# # 分层划分（stratify参数确保比例）\n",
    "# train_idx, val_idx = train_test_split(\n",
    "#     range(len(full_trainset)),\n",
    "#     test_size=0.2,\n",
    "#     shuffle=True,\n",
    "#     stratify=labels,\n",
    "#     random_state=args.seed  \n",
    "# )\n",
    "\n",
    "# train_data = np.stack([full_trainset.data[i]  for i in train_idx]) \n",
    "# train_targets = [full_trainset.targets[i] for i in train_idx] \n",
    "# val_data = np.stack([full_trainset.data[i]  for i in val_idx]) \n",
    "# val_targets = [full_trainset.targets[i] for i in val_idx] \n",
    "\n",
    "# valset = full_trainset\n",
    "# valset.data = val_data\n",
    "# valset.targets = val_targets\n",
    "# valset.transform = data_transforms['valid']\n",
    "\n",
    "# trainset = copy.deepcopy(valset)\n",
    "# trainset.data = train_data\n",
    "# trainset.targets = train_targets\n",
    "# trainset.transform = data_transforms['train']\n",
    "\n",
    "# trainloader = {\n",
    "#     'train':DataLoader(\n",
    "#     trainset, batch_size=args.batch_size, shuffle=False, sampler=torch.utils.data.SequentialSampler(trainset), num_workers=0),\n",
    "#     'valid':DataLoader(\n",
    "#     valset, batch_size=args.batch_size, shuffle=False, sampler=torch.utils.data.SequentialSampler(valset), num_workers=0)}\n",
    "\n",
    "# dataset_sizes = {\n",
    "#     'train': len(trainset),\n",
    "#     'valid': len(valset),            \n",
    "                #  }\n",
    "\n",
    "trainloader = {\n",
    "    'train':DataLoader(\n",
    "    full_trainset, batch_size=args.batch_size, shuffle=False, sampler=torch.utils.data.SequentialSampler(full_trainset), num_workers=0),\n",
    "    'valid':testloader\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "    'train': len(full_trainset),\n",
    "    'valid': len(testset),      \n",
    "}\n",
    "print(dataset_sizes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "840b5037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vit_tiny_patch16_224']\n"
     ]
    }
   ],
   "source": [
    "print(timm.list_models('*vit_tiny_patch16_224*')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ab5b31b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from torchvision.transforms.functional  import to_pil_image \n",
    "# 反归一化转换（需与transform中的参数对应）\n",
    "inv_normalize = transforms.Normalize(\n",
    "    mean=[-0.4914/0.2023, -0.4822/0.1994, -0.4465/0.2010],\n",
    "    std=[1/0.2023, 1/0.1994, 1/0.2010]\n",
    ")\n",
    " \n",
    "def show_images(loader, num_images=4):\n",
    "    # 获取一个batch的数据 \n",
    "    # images, labels = next(iter(loader))\n",
    "    for batch_idx, (images, labels) in enumerate(loader):\n",
    "        if batch_idx == 0:  # 只取第一个batch \n",
    "            break \n",
    "\n",
    "    # 创建子图 \n",
    "    fig, axes = plt.subplots(1,  num_images, figsize=(15, 3))\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        # 反归一化+通道顺序调整 \n",
    "        img = inv_normalize(images[i]).permute(1, 2, 0).numpy()\n",
    "        img = np.clip(img,  0, 1)  # 处理浮点误差 \n",
    "        \n",
    "        # 显示图像及标签 \n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f\"Label: {full_trainset.classes[labels[i]]}\") \n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.show() \n",
    " \n",
    "show_images(trainloader['train'])\n",
    "show_images(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5aa47f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./model/\" + args.datasets + \"/benckmark.pth\"\n",
    "if os.path.exists(model_path):\n",
    "    net_benckmark_data = torch.load(model_path,  map_location='cpu')\n",
    "    benckmark_state_dict = net_benckmark_data['model_state_dict'] \n",
    "else:\n",
    "    net_benchmark = UPANets(args.filters, Num_class, args.blocks, img_size)\n",
    "    torch.save({\n",
    "        'model_state_dict': net_benchmark.state_dict()\n",
    "    }, model_path)\n",
    "    benckmark_state_dict = net_benchmark.state_dict()\n",
    "\n",
    "def tensor_to_serializable(obj):\n",
    "    if isinstance(obj, (np.float32,  np.float64)):   # 处理NumPy浮点数\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.integer):               # 处理NumPy整数 \n",
    "        return int(obj)\n",
    "    elif isinstance(obj, torch.Tensor):            # 处理PyTorch Tensor \n",
    "        return obj.item()  if obj.numel()  == 1 else obj.tolist() \n",
    "    elif isinstance(obj, (np.ndarray)):             # 处理NumPy数组 \n",
    "        return obj.tolist() \n",
    "    elif hasattr(obj, '__dict__'):                 # 处理自定义对象（可选）\n",
    "        return obj.__dict__\n",
    "    return obj \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3ec9786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pugdt_delta = UPANets(args.filters, Num_class, args.blocks, img_size)  \n",
    "# net_pugdt_delta.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net_pugdt_delta.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     net_pugdt_delta = torch.nn.DataParallel(net_pugdt_delta)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDXT(net_pugdt_delta.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=args.lr,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                 )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "\n",
    "# net_pugdt_delta, metricst_delta = train_model_timing_delta(net_pugdt_delta, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes, int(args.epochs/10), 0.01, 10) \n",
    "\n",
    "# model_path = \"./model/\"+args.datasets+\"/pugdt_delta_\" + str(args.epochs) + \"xi\" + str(args.epochs/10) + \"mu0.01_t10.pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net_pugdt_delta.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/pugdt_delta_\" + str(args.epochs) + \"xi\" + str(args.epochs/10) + \"mu0.01_t10.json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metricst_delta,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efb925b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pugdt_var = UPANets(args.filters, Num_class, args.blocks, img_size)  \n",
    "# net_pugdt_var.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net_pugdt_var.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     net_pugdt_var = torch.nn.DataParallel(net_pugdt_var)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDXT(net_pugdt_var.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=args.lr,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                 )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "\n",
    "# net_pugdt_var, metricst_var = train_model_timing_var(net_pugdt_var, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes, int(args.epochs/10), 0.015, 10) \n",
    "\n",
    "# model_path = \"./model/\"+args.datasets+\"/pugdt_var_\" + str(args.epochs) + \"init_t\" + str(args.epochs/10) + \"gamma0.015_k10.pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net_pugdt_var.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/pugdt_var_\" + str(args.epochs) + \"init_t\" + str(args.epochs/10) + \"gamma0.015_k10.json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metricst_var,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a42d18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = UPANets(args.filters, Num_class, args.blocks, img_size)\n",
    "# net.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     net = torch.nn.DataParallel(net)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# optimizer = optim.SGD(net.parameters(),\n",
    "#                 lr=args.lr,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                  )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "# # exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# net, metrics_org = train_model_org(net, criterion, optimizer, scheduler, args.epochs * 2, trainloader, device, dataset_sizes) \n",
    "\n",
    "# # 保存模型架构+参数+优化器状态（完整恢复训练）\n",
    "# model_path = \"./model/\"+args.datasets+\"/org\" + str(args.epochs) + \".pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/org_\" + str(args.epochs) + \".json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metrics_org, f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n",
    " \n",
    "# # 加载 \n",
    "\n",
    "# # checkpoint = torch.load('full_model_checkpoint.pth',  map_location='cpu')  # 先加载到CPU避免设备冲突 \n",
    "# # 模型结构需提前定义（需与保存时一致）\n",
    "# # model = YourModelClass()  \n",
    "# # model.load_state_dict(checkpoint['model_state_dict']) \n",
    " \n",
    "# # # 恢复优化器和训练状态 \n",
    "# # optimizer = torch.optim.Adam(model.parameters())  \n",
    "# # optimizer.load_state_dict(checkpoint['optimizer_state_dict']) \n",
    "# # with open('data.json',  'r', encoding='utf-8') as f:\n",
    "# #     loaded_dict = json.load(f) \n",
    "\n",
    "\n",
    "# # summary(net, (3, img_size, img_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0db0a205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241.7836492061615\n",
      "Epoch 1/399\n",
      "243.46752834320068\n",
      "Epoch 2/399\n",
      "246.0016748905182\n",
      "Epoch 3/399\n",
      "244.0839307308197\n",
      "Epoch 4/399\n",
      "244.4616322517395\n",
      "Epoch 5/399\n",
      "244.92393517494202\n",
      "Epoch 6/399\n",
      "241.48592495918274\n",
      "Epoch 7/399\n",
      "240.06820273399353\n",
      "Epoch 8/399\n",
      "240.20319437980652\n",
      "Epoch 9/399\n",
      "240.16366243362427\n",
      "Epoch 10/399\n",
      "239.99059128761292\n",
      "Epoch 11/399\n",
      "240.53280353546143\n",
      "Epoch 12/399\n",
      "240.393301486969\n",
      "Epoch 13/399\n",
      "240.57809853553772\n",
      "Epoch 14/399\n",
      "243.5778353214264\n",
      "Epoch 15/399\n",
      "247.7289810180664\n",
      "Epoch 16/399\n",
      "246.7749547958374\n",
      "Epoch 17/399\n",
      "247.61413049697876\n",
      "Epoch 18/399\n",
      "247.101238489151\n",
      "Epoch 19/399\n",
      "248.3034393787384\n",
      "Epoch 20/399\n",
      "247.9653663635254\n",
      "Epoch 21/399\n",
      "247.60131192207336\n",
      "Epoch 22/399\n",
      "247.05935883522034\n",
      "Epoch 23/399\n",
      "245.59500741958618\n",
      "Epoch 24/399\n",
      "242.21474480628967\n",
      "Epoch 25/399\n",
      "241.72860956192017\n",
      "Epoch 26/399\n",
      "241.42920541763306\n",
      "Epoch 27/399\n",
      "241.5365972518921\n",
      "Epoch 28/399\n",
      "241.6073076725006\n",
      "Epoch 29/399\n",
      "241.39691996574402\n",
      "Epoch 30/399\n",
      "241.8632116317749\n",
      "Epoch 31/399\n",
      "242.09808349609375\n",
      "Epoch 32/399\n",
      "241.88425874710083\n",
      "Epoch 33/399\n",
      "241.85751128196716\n",
      "Epoch 34/399\n",
      "241.96094250679016\n",
      "Epoch 35/399\n",
      "242.01419377326965\n",
      "Epoch 36/399\n",
      "241.91000866889954\n",
      "Epoch 37/399\n",
      "241.85809564590454\n",
      "Epoch 38/399\n",
      "241.49995470046997\n",
      "Epoch 39/399\n",
      "242.14386630058289\n",
      "Epoch 40/399\n",
      "241.95925164222717\n",
      "Epoch 41/399\n",
      "241.90669894218445\n",
      "Epoch 42/399\n",
      "241.8508415222168\n",
      "Epoch 43/399\n",
      "241.96289229393005\n",
      "Epoch 44/399\n",
      "242.43047380447388\n",
      "Epoch 45/399\n",
      "241.91377758979797\n",
      "Epoch 46/399\n",
      "241.9647285938263\n",
      "Epoch 47/399\n",
      "241.55417847633362\n",
      "Epoch 48/399\n",
      "241.86851239204407\n",
      "Epoch 49/399\n",
      "242.04055666923523\n",
      "Epoch 50/399\n",
      "242.1181938648224\n",
      "Epoch 51/399\n",
      "242.08004927635193\n",
      "Epoch 52/399\n",
      "241.99291920661926\n",
      "Epoch 53/399\n",
      "241.8042562007904\n",
      "Epoch 54/399\n",
      "241.95480585098267\n",
      "Epoch 55/399\n",
      "242.23689675331116\n",
      "Epoch 56/399\n",
      "242.05610847473145\n",
      "Epoch 57/399\n",
      "242.09908866882324\n",
      "Epoch 58/399\n",
      "241.62706804275513\n",
      "Epoch 59/399\n",
      "242.04914021492004\n",
      "Epoch 60/399\n",
      "242.2428138256073\n",
      "Epoch 61/399\n",
      "241.964994430542\n",
      "Epoch 62/399\n",
      "241.6533558368683\n",
      "Epoch 63/399\n",
      "241.94597959518433\n",
      "Epoch 64/399\n",
      "241.5817952156067\n",
      "Epoch 65/399\n",
      "242.0786738395691\n",
      "Epoch 66/399\n",
      "248.32581162452698\n",
      "Epoch 67/399\n",
      "248.76497840881348\n",
      "Epoch 68/399\n",
      "249.13442635536194\n",
      "Epoch 69/399\n",
      "249.10167527198792\n",
      "Epoch 70/399\n",
      "248.03894305229187\n",
      "Epoch 71/399\n",
      "242.51278710365295\n",
      "Epoch 72/399\n",
      "242.43138790130615\n",
      "Epoch 73/399\n",
      "242.54432272911072\n",
      "Epoch 74/399\n",
      "242.19738245010376\n",
      "Epoch 75/399\n",
      "242.24694156646729\n",
      "Epoch 76/399\n",
      "242.47903275489807\n",
      "Epoch 77/399\n",
      "242.67612838745117\n",
      "Epoch 78/399\n",
      "242.69786620140076\n",
      "Epoch 79/399\n",
      "242.72227907180786\n",
      "Epoch 80/399\n",
      "242.36209988594055\n",
      "Epoch 81/399\n",
      "242.75790119171143\n",
      "Epoch 82/399\n",
      "242.4584596157074\n",
      "Epoch 83/399\n",
      "242.66780424118042\n",
      "Epoch 84/399\n",
      "242.72844314575195\n",
      "Epoch 85/399\n",
      "242.48578929901123\n",
      "Epoch 86/399\n",
      "242.631653547287\n",
      "Epoch 87/399\n",
      "242.4504256248474\n",
      "Epoch 88/399\n",
      "242.5199100971222\n",
      "Epoch 89/399\n",
      "243.04181241989136\n",
      "Epoch 90/399\n",
      "242.40487122535706\n",
      "Epoch 91/399\n",
      "243.21700716018677\n",
      "Epoch 92/399\n",
      "242.4132707118988\n",
      "Epoch 93/399\n",
      "246.8800802230835\n",
      "Epoch 94/399\n",
      "243.05571937561035\n",
      "Epoch 95/399\n",
      "246.98296332359314\n",
      "Epoch 96/399\n",
      "249.03572463989258\n",
      "Epoch 97/399\n",
      "248.63582158088684\n",
      "Epoch 98/399\n",
      "249.31772875785828\n",
      "Epoch 99/399\n",
      "249.13454413414001\n",
      "Epoch 100/399\n",
      "246.33815908432007\n",
      "Epoch 101/399\n",
      "243.22859048843384\n",
      "Epoch 102/399\n",
      "243.50832986831665\n",
      "Epoch 103/399\n",
      "243.0559892654419\n",
      "Epoch 104/399\n",
      "242.79107475280762\n",
      "Epoch 105/399\n",
      "242.55910110473633\n",
      "Epoch 106/399\n",
      "242.494220495224\n",
      "Epoch 107/399\n",
      "242.59818053245544\n",
      "Epoch 108/399\n",
      "242.56837391853333\n",
      "Epoch 109/399\n",
      "242.6011552810669\n",
      "Epoch 110/399\n",
      "242.27208042144775\n",
      "Epoch 111/399\n",
      "243.2482967376709\n",
      "Epoch 112/399\n",
      "242.76946568489075\n",
      "Epoch 113/399\n",
      "242.66104888916016\n",
      "Epoch 114/399\n",
      "242.71092534065247\n",
      "Epoch 115/399\n",
      "243.11403703689575\n",
      "Epoch 116/399\n",
      "242.94084215164185\n",
      "Epoch 117/399\n",
      "242.65730500221252\n",
      "Epoch 118/399\n",
      "242.48030853271484\n",
      "Epoch 119/399\n",
      "242.354674577713\n",
      "Epoch 120/399\n",
      "242.6451096534729\n",
      "Epoch 121/399\n",
      "242.60940408706665\n",
      "Epoch 122/399\n",
      "242.66670393943787\n",
      "Epoch 123/399\n",
      "242.86768102645874\n",
      "Epoch 124/399\n",
      "242.90952348709106\n",
      "Epoch 125/399\n",
      "242.207777261734\n",
      "Epoch 126/399\n",
      "242.25894355773926\n",
      "Epoch 127/399\n",
      "242.36229062080383\n",
      "Epoch 128/399\n",
      "242.33459877967834\n",
      "Epoch 129/399\n",
      "243.22562527656555\n",
      "Epoch 130/399\n",
      "242.41463041305542\n",
      "Epoch 131/399\n",
      "242.81428575515747\n",
      "Epoch 132/399\n",
      "242.470144033432\n",
      "Epoch 133/399\n",
      "243.19544672966003\n",
      "Epoch 134/399\n",
      "242.45494532585144\n",
      "Epoch 135/399\n",
      "242.91848635673523\n",
      "Epoch 136/399\n",
      "242.51325726509094\n",
      "Epoch 137/399\n",
      "242.50071120262146\n",
      "Epoch 138/399\n",
      "242.55808877944946\n",
      "Epoch 139/399\n",
      "242.78535223007202\n",
      "Epoch 140/399\n",
      "243.08593201637268\n",
      "Epoch 141/399\n",
      "242.76930022239685\n",
      "Epoch 142/399\n",
      "242.71286463737488\n",
      "Epoch 143/399\n",
      "242.52648663520813\n",
      "Epoch 144/399\n",
      "243.1632571220398\n",
      "Epoch 145/399\n",
      "247.74830603599548\n",
      "Epoch 146/399\n",
      "247.51800107955933\n",
      "Epoch 147/399\n",
      "246.95118737220764\n",
      "Epoch 148/399\n",
      "246.801087141037\n",
      "Epoch 149/399\n",
      "247.35163378715515\n",
      "Epoch 150/399\n",
      "249.61529397964478\n",
      "Epoch 151/399\n",
      "305.73791241645813\n",
      "Epoch 152/399\n",
      "314.9500906467438\n",
      "Epoch 153/399\n",
      "319.02055382728577\n",
      "Epoch 154/399\n",
      "303.8104577064514\n",
      "Epoch 155/399\n",
      "312.70483899116516\n",
      "Epoch 156/399\n",
      "316.5235514640808\n",
      "Epoch 157/399\n",
      "318.2137062549591\n",
      "Epoch 158/399\n",
      "263.6860566139221\n",
      "Epoch 159/399\n",
      "252.30616974830627\n",
      "Epoch 160/399\n",
      "253.23595809936523\n",
      "Epoch 161/399\n",
      "251.7645947933197\n",
      "Epoch 162/399\n",
      "251.5262575149536\n",
      "Epoch 163/399\n",
      "251.1684708595276\n",
      "Epoch 164/399\n",
      "251.0845890045166\n",
      "Epoch 165/399\n",
      "251.46076917648315\n",
      "Epoch 166/399\n",
      "250.63558387756348\n",
      "Epoch 167/399\n",
      "250.52250361442566\n",
      "Epoch 168/399\n",
      "251.34260272979736\n",
      "Epoch 169/399\n",
      "251.13366794586182\n",
      "Epoch 170/399\n",
      "251.44288420677185\n",
      "Epoch 171/399\n",
      "251.12404990196228\n",
      "Epoch 172/399\n",
      "252.12122082710266\n",
      "Epoch 173/399\n",
      "252.27676844596863\n",
      "Epoch 174/399\n",
      "251.4773724079132\n",
      "Epoch 175/399\n",
      "251.21425414085388\n",
      "Epoch 176/399\n",
      "251.37083268165588\n",
      "Epoch 177/399\n",
      "251.03772068023682\n",
      "Epoch 178/399\n",
      "251.50796723365784\n",
      "Epoch 179/399\n",
      "251.538254737854\n",
      "Epoch 180/399\n",
      "251.56991624832153\n",
      "Epoch 181/399\n",
      "251.92198061943054\n",
      "Epoch 182/399\n",
      "251.97009229660034\n",
      "Epoch 183/399\n",
      "252.03453421592712\n",
      "Epoch 184/399\n",
      "250.32929515838623\n",
      "Epoch 185/399\n",
      "244.47482180595398\n",
      "Epoch 186/399\n",
      "250.16205739974976\n",
      "Epoch 187/399\n",
      "251.95165586471558\n",
      "Epoch 188/399\n",
      "253.94139528274536\n",
      "Epoch 189/399\n",
      "251.58458614349365\n",
      "Epoch 190/399\n",
      "250.6533544063568\n",
      "Epoch 191/399\n",
      "249.94909167289734\n",
      "Epoch 192/399\n",
      "250.07019305229187\n",
      "Epoch 193/399\n",
      "250.31822395324707\n",
      "Epoch 194/399\n",
      "247.16878604888916\n",
      "Epoch 195/399\n",
      "250.04870080947876\n",
      "Epoch 196/399\n",
      "248.58454608917236\n",
      "Epoch 197/399\n",
      "250.6953570842743\n",
      "Epoch 198/399\n",
      "252.0407612323761\n",
      "Epoch 199/399\n",
      "251.9009177684784\n",
      "Epoch 200/399\n",
      "251.70113801956177\n",
      "Epoch 201/399\n",
      "251.4014072418213\n",
      "Epoch 202/399\n",
      "251.8431441783905\n",
      "Epoch 203/399\n",
      "251.15934777259827\n",
      "Epoch 204/399\n",
      "249.68628215789795\n",
      "Epoch 205/399\n",
      "249.96615266799927\n",
      "Epoch 206/399\n",
      "251.0845685005188\n",
      "Epoch 207/399\n",
      "245.79552149772644\n",
      "Epoch 208/399\n",
      "244.7464303970337\n",
      "Epoch 209/399\n",
      "245.3507535457611\n",
      "Epoch 210/399\n",
      "244.96799635887146\n",
      "Epoch 211/399\n",
      "244.54707622528076\n",
      "Epoch 212/399\n",
      "244.90306639671326\n",
      "Epoch 213/399\n",
      "244.9053030014038\n",
      "Epoch 214/399\n",
      "245.05833458900452\n",
      "Epoch 215/399\n",
      "245.0501720905304\n",
      "Epoch 216/399\n",
      "249.45141792297363\n",
      "Epoch 217/399\n",
      "249.5676257610321\n",
      "Epoch 218/399\n",
      "251.06803154945374\n",
      "Epoch 219/399\n",
      "251.48450589179993\n",
      "Epoch 220/399\n",
      "250.09981870651245\n",
      "Epoch 221/399\n",
      "244.7475802898407\n",
      "Epoch 222/399\n",
      "244.90421557426453\n",
      "Epoch 223/399\n",
      "245.1710753440857\n",
      "Epoch 224/399\n",
      "245.00051879882812\n",
      "Epoch 225/399\n",
      "245.30042433738708\n",
      "Epoch 226/399\n",
      "244.7606120109558\n",
      "Epoch 227/399\n",
      "245.03557801246643\n",
      "Epoch 228/399\n",
      "245.1769881248474\n",
      "Epoch 229/399\n",
      "245.38838243484497\n",
      "Epoch 230/399\n",
      "244.91673183441162\n",
      "Epoch 231/399\n",
      "245.22859811782837\n",
      "Epoch 232/399\n",
      "244.89161205291748\n",
      "Epoch 233/399\n",
      "244.90818548202515\n",
      "Epoch 234/399\n",
      "244.6611888408661\n",
      "Epoch 235/399\n",
      "245.1597728729248\n",
      "Epoch 236/399\n",
      "245.09178972244263\n",
      "Epoch 237/399\n",
      "244.76975464820862\n",
      "Epoch 238/399\n",
      "244.94007182121277\n",
      "Epoch 239/399\n",
      "244.7637951374054\n",
      "Epoch 240/399\n",
      "244.98601603507996\n",
      "Epoch 241/399\n",
      "244.7861351966858\n",
      "Epoch 242/399\n",
      "245.12585306167603\n",
      "Epoch 243/399\n",
      "244.90046048164368\n",
      "Epoch 244/399\n",
      "245.14072489738464\n",
      "Epoch 245/399\n",
      "244.92647075653076\n",
      "Epoch 246/399\n",
      "244.87144327163696\n",
      "Epoch 247/399\n",
      "244.65012407302856\n",
      "Epoch 248/399\n",
      "244.61343216896057\n",
      "Epoch 249/399\n",
      "244.9027497768402\n",
      "Epoch 250/399\n",
      "244.64288234710693\n",
      "Epoch 251/399\n",
      "245.09866762161255\n",
      "Epoch 252/399\n",
      "244.89262700080872\n",
      "Epoch 253/399\n",
      "244.82482981681824\n",
      "Epoch 254/399\n",
      "245.29647707939148\n",
      "Epoch 255/399\n",
      "245.38566493988037\n",
      "Epoch 256/399\n",
      "245.22867155075073\n",
      "Epoch 257/399\n",
      "244.72448205947876\n",
      "Epoch 258/399\n",
      "245.23410868644714\n",
      "Epoch 259/399\n",
      "244.7912974357605\n",
      "Epoch 260/399\n",
      "244.78299736976624\n",
      "Epoch 261/399\n",
      "244.62881088256836\n",
      "Epoch 262/399\n",
      "244.91061353683472\n",
      "Epoch 263/399\n",
      "245.23077750205994\n",
      "Epoch 264/399\n",
      "244.72088193893433\n",
      "Epoch 265/399\n",
      "245.00006747245789\n",
      "Epoch 266/399\n",
      "244.91404485702515\n",
      "Epoch 267/399\n",
      "245.24264979362488\n",
      "Epoch 268/399\n",
      "245.1098370552063\n",
      "Epoch 269/399\n",
      "244.92101097106934\n",
      "Epoch 270/399\n",
      "245.0548849105835\n",
      "Epoch 271/399\n",
      "244.9604115486145\n",
      "Epoch 272/399\n",
      "244.62535738945007\n",
      "Epoch 273/399\n",
      "244.74800181388855\n",
      "Epoch 274/399\n",
      "245.15240621566772\n",
      "Epoch 275/399\n",
      "244.73558115959167\n",
      "Epoch 276/399\n",
      "244.5409276485443\n",
      "Epoch 277/399\n",
      "245.19830536842346\n",
      "Epoch 278/399\n",
      "244.18598914146423\n",
      "Epoch 279/399\n",
      "244.9328374862671\n",
      "Epoch 280/399\n",
      "244.85383677482605\n",
      "Epoch 281/399\n",
      "244.56044673919678\n",
      "Epoch 282/399\n",
      "244.98209047317505\n",
      "Epoch 283/399\n",
      "244.87599420547485\n",
      "Epoch 284/399\n",
      "244.61381459236145\n",
      "Epoch 285/399\n",
      "244.892320394516\n",
      "Epoch 286/399\n",
      "244.6222448348999\n",
      "Epoch 287/399\n",
      "244.7227644920349\n",
      "Epoch 288/399\n",
      "244.79128694534302\n",
      "Epoch 289/399\n",
      "244.6660726070404\n",
      "Epoch 290/399\n",
      "244.86733627319336\n",
      "Epoch 291/399\n",
      "244.98746061325073\n",
      "Epoch 292/399\n",
      "244.97261595726013\n",
      "Epoch 293/399\n",
      "244.50501537322998\n",
      "Epoch 294/399\n",
      "244.8379557132721\n",
      "Epoch 295/399\n",
      "244.8996503353119\n",
      "Epoch 296/399\n",
      "244.80769157409668\n",
      "Epoch 297/399\n",
      "244.84633111953735\n",
      "Epoch 298/399\n",
      "244.8969714641571\n",
      "Epoch 299/399\n",
      "244.99935293197632\n",
      "Epoch 300/399\n",
      "244.9241771697998\n",
      "Epoch 301/399\n",
      "244.89567112922668\n",
      "Epoch 302/399\n",
      "245.00226759910583\n",
      "Epoch 303/399\n",
      "245.04444646835327\n",
      "Epoch 304/399\n",
      "244.608172416687\n",
      "Epoch 305/399\n",
      "244.93559336662292\n",
      "Epoch 306/399\n",
      "244.43326544761658\n",
      "Epoch 307/399\n",
      "244.6758680343628\n",
      "Epoch 308/399\n",
      "244.65829491615295\n",
      "Epoch 309/399\n",
      "244.57342433929443\n",
      "Epoch 310/399\n",
      "244.79573559761047\n",
      "Epoch 311/399\n",
      "244.76508021354675\n",
      "Epoch 312/399\n",
      "244.78702545166016\n",
      "Epoch 313/399\n",
      "244.40138602256775\n",
      "Epoch 314/399\n",
      "244.8008153438568\n",
      "Epoch 315/399\n",
      "244.97740721702576\n",
      "Epoch 316/399\n",
      "244.8713128566742\n",
      "Epoch 317/399\n",
      "244.52319288253784\n",
      "Epoch 318/399\n",
      "244.59317827224731\n",
      "Epoch 319/399\n",
      "244.55069708824158\n",
      "Epoch 320/399\n",
      "244.56027460098267\n",
      "Epoch 321/399\n",
      "244.7797553539276\n",
      "Epoch 322/399\n",
      "244.71107935905457\n",
      "Epoch 323/399\n",
      "244.39248371124268\n",
      "Epoch 324/399\n",
      "244.56129598617554\n",
      "Epoch 325/399\n",
      "244.78576231002808\n",
      "Epoch 326/399\n",
      "244.61831855773926\n",
      "Epoch 327/399\n",
      "244.68342447280884\n",
      "Epoch 328/399\n",
      "244.5384600162506\n",
      "Epoch 329/399\n",
      "244.9608314037323\n",
      "Epoch 330/399\n",
      "244.6704204082489\n",
      "Epoch 331/399\n",
      "244.83012199401855\n",
      "Epoch 332/399\n",
      "244.506445646286\n",
      "Epoch 333/399\n",
      "244.74893450737\n",
      "Epoch 334/399\n",
      "244.9995937347412\n",
      "Epoch 335/399\n",
      "244.86493134498596\n",
      "Epoch 336/399\n",
      "244.46361804008484\n",
      "Epoch 337/399\n",
      "244.84324622154236\n",
      "Epoch 338/399\n",
      "245.0246729850769\n",
      "Epoch 339/399\n",
      "245.12491273880005\n",
      "Epoch 340/399\n",
      "244.9417130947113\n",
      "Epoch 341/399\n",
      "244.76852774620056\n",
      "Epoch 342/399\n",
      "244.49062657356262\n",
      "Epoch 343/399\n",
      "244.7920801639557\n",
      "Epoch 344/399\n",
      "245.06475281715393\n",
      "Epoch 345/399\n",
      "244.82830953598022\n",
      "Epoch 346/399\n",
      "244.67888116836548\n",
      "Epoch 347/399\n",
      "244.84608721733093\n",
      "Epoch 348/399\n",
      "244.73338341712952\n",
      "Epoch 349/399\n",
      "244.54290199279785\n",
      "Epoch 350/399\n",
      "245.04066634178162\n",
      "Epoch 351/399\n",
      "247.37804174423218\n",
      "Epoch 352/399\n",
      "247.35419249534607\n",
      "Epoch 353/399\n",
      "246.40216374397278\n",
      "Epoch 354/399\n",
      "246.8855459690094\n",
      "Epoch 355/399\n",
      "247.00102376937866\n",
      "Epoch 356/399\n",
      "249.8591079711914\n",
      "Epoch 357/399\n",
      "250.03665399551392\n",
      "Epoch 358/399\n",
      "250.86959028244019\n",
      "Epoch 359/399\n",
      "251.5318784713745\n",
      "Epoch 360/399\n",
      "251.36886191368103\n",
      "Epoch 361/399\n",
      "246.9500172138214\n",
      "Epoch 362/399\n",
      "244.72500729560852\n",
      "Epoch 363/399\n",
      "244.3400628566742\n",
      "Epoch 364/399\n",
      "244.5219578742981\n",
      "Epoch 365/399\n",
      "250.4622347354889\n",
      "Epoch 366/399\n",
      "251.16752576828003\n",
      "Epoch 367/399\n",
      "251.2678027153015\n",
      "Epoch 368/399\n",
      "250.88979148864746\n",
      "Epoch 369/399\n",
      "249.04099345207214\n",
      "Epoch 370/399\n",
      "245.01456689834595\n",
      "Epoch 371/399\n",
      "245.15752172470093\n",
      "Epoch 372/399\n",
      "244.75729751586914\n",
      "Epoch 373/399\n",
      "245.64695858955383\n",
      "Epoch 374/399\n",
      "244.96146178245544\n",
      "Epoch 375/399\n",
      "244.5470485687256\n",
      "Epoch 376/399\n",
      "244.99104261398315\n",
      "Epoch 377/399\n",
      "245.1158323287964\n",
      "Epoch 378/399\n",
      "244.7524061203003\n",
      "Epoch 379/399\n",
      "244.67070627212524\n",
      "Epoch 380/399\n",
      "244.6312963962555\n",
      "Epoch 381/399\n",
      "245.0865979194641\n",
      "Epoch 382/399\n",
      "245.19559502601624\n",
      "Epoch 383/399\n",
      "245.03878021240234\n",
      "Epoch 384/399\n",
      "245.37539911270142\n",
      "Epoch 385/399\n",
      "245.0699462890625\n",
      "Epoch 386/399\n",
      "244.72849011421204\n",
      "Epoch 387/399\n",
      "244.86103296279907\n",
      "Epoch 388/399\n",
      "245.08807969093323\n",
      "Epoch 389/399\n",
      "245.10264134407043\n",
      "Epoch 390/399\n",
      "245.2717092037201\n",
      "Epoch 391/399\n",
      "244.94606924057007\n",
      "Epoch 392/399\n",
      "245.3240807056427\n",
      "Epoch 393/399\n",
      "245.38160753250122\n",
      "Epoch 394/399\n",
      "245.15550351142883\n",
      "Epoch 395/399\n",
      "245.13973569869995\n",
      "Epoch 396/399\n",
      "244.89677214622498\n",
      "Epoch 397/399\n",
      "245.35095739364624\n",
      "Epoch 398/399\n",
      "245.38364577293396\n",
      "Epoch 399/399\n",
      "245.48072504997253\n",
      "Training complete in 1643m 28s\n",
      "Best val Acc: 0.935800\n"
     ]
    }
   ],
   "source": [
    "net_pugdr_sin = UPANets(args.filters, Num_class, args.blocks, img_size)\n",
    "net_pugdr_sin.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "net_pugdr_sin.to(device)\n",
    "\n",
    "if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "    model_ft_org = torch.nn.DataParallel(net_pugdr_sin)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "base_optimizer = optim.SGD\n",
    "optimizer = PUGDXR(net_pugdr_sin.parameters(),\n",
    "                base_optimizer,\n",
    "                lr=args.lr,\n",
    "                max_epochs= args.epochs,\n",
    "                momentum=args.momentum,\n",
    "                weight_decay=args.wd,\n",
    "                min_beta = 0.5, \n",
    "                max_beta = 1.5, \n",
    "                method = 'sin',\n",
    "                dampening=0,   # 必须设置为0才能完全固定 \n",
    "                nesterov=False # 禁用Nesterov动量 \n",
    "                )\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "# exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "net_pugdr_sin, metricsr_sin = train_model_alpha(net_pugdr_sin, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "model_path = \"./model/\"+args.datasets+\"/pugdr_sin\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".pth\"\n",
    "torch.save({\n",
    "    'model_state_dict': net_pugdr_sin.state_dict(), \n",
    "    'optimizer_state_dict': optimizer.state_dict()\n",
    "}, model_path) \n",
    "\n",
    "name = \"./results/\"+args.datasets+\"/pugdr_sin_\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".json\"\n",
    "with open(name,  'w', encoding='utf-8') as f:\n",
    "    json.dump(metricsr_sin,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c82cb0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/399\n",
      "249.75502681732178\n",
      "Epoch 1/399\n",
      "252.5345275402069\n",
      "Epoch 2/399\n",
      "251.52871227264404\n",
      "Epoch 3/399\n",
      "251.5738582611084\n",
      "Epoch 4/399\n",
      "252.28443241119385\n",
      "Epoch 5/399\n",
      "253.63430190086365\n",
      "Epoch 6/399\n",
      "252.22831988334656\n",
      "Epoch 7/399\n",
      "246.8425886631012\n",
      "Epoch 8/399\n",
      "246.66606187820435\n",
      "Epoch 9/399\n",
      "247.3492419719696\n",
      "Epoch 10/399\n",
      "246.41909289360046\n",
      "Epoch 11/399\n",
      "246.8299331665039\n",
      "Epoch 12/399\n",
      "247.09714698791504\n",
      "Epoch 13/399\n",
      "246.70776844024658\n",
      "Epoch 14/399\n",
      "246.68972444534302\n",
      "Epoch 15/399\n",
      "246.72980976104736\n",
      "Epoch 16/399\n",
      "246.73444247245789\n",
      "Epoch 17/399\n",
      "246.63131523132324\n",
      "Epoch 18/399\n",
      "246.88073110580444\n",
      "Epoch 19/399\n",
      "246.48232579231262\n",
      "Epoch 20/399\n",
      "247.34051370620728\n",
      "Epoch 21/399\n",
      "246.77393102645874\n",
      "Epoch 22/399\n",
      "247.11726260185242\n",
      "Epoch 23/399\n",
      "247.02446031570435\n",
      "Epoch 24/399\n",
      "246.4842028617859\n",
      "Epoch 25/399\n",
      "250.5487163066864\n",
      "Epoch 26/399\n",
      "252.09057068824768\n",
      "Epoch 27/399\n",
      "252.613783121109\n",
      "Epoch 28/399\n",
      "253.13262009620667\n",
      "Epoch 29/399\n",
      "254.28450202941895\n",
      "Epoch 30/399\n",
      "248.11770105361938\n",
      "Epoch 31/399\n",
      "246.81007051467896\n",
      "Epoch 32/399\n",
      "247.47520232200623\n",
      "Epoch 33/399\n",
      "247.57713770866394\n",
      "Epoch 34/399\n",
      "247.6033296585083\n",
      "Epoch 35/399\n",
      "247.11759686470032\n",
      "Epoch 36/399\n",
      "247.19308161735535\n",
      "Epoch 37/399\n",
      "247.14571261405945\n",
      "Epoch 38/399\n",
      "247.50991702079773\n",
      "Epoch 39/399\n",
      "247.78409028053284\n",
      "Epoch 40/399\n",
      "247.04326224327087\n",
      "Epoch 41/399\n",
      "247.4066023826599\n",
      "Epoch 42/399\n",
      "247.13814973831177\n",
      "Epoch 43/399\n",
      "247.47358107566833\n",
      "Epoch 44/399\n",
      "247.36526012420654\n",
      "Epoch 45/399\n",
      "247.27559542655945\n",
      "Epoch 46/399\n",
      "247.34721899032593\n",
      "Epoch 47/399\n",
      "247.49989080429077\n",
      "Epoch 48/399\n",
      "247.3509237766266\n",
      "Epoch 49/399\n",
      "247.1007261276245\n",
      "Epoch 50/399\n",
      "247.01223421096802\n",
      "Epoch 51/399\n",
      "247.6607542037964\n",
      "Epoch 52/399\n",
      "247.25281381607056\n",
      "Epoch 53/399\n",
      "247.7728395462036\n",
      "Epoch 54/399\n",
      "247.48554611206055\n",
      "Epoch 55/399\n",
      "247.7040512561798\n",
      "Epoch 56/399\n",
      "247.73449969291687\n",
      "Epoch 57/399\n",
      "247.61346459388733\n",
      "Epoch 58/399\n",
      "247.5917627811432\n",
      "Epoch 59/399\n",
      "247.25699090957642\n",
      "Epoch 60/399\n",
      "247.42512583732605\n",
      "Epoch 61/399\n",
      "247.4556496143341\n",
      "Epoch 62/399\n",
      "247.50789046287537\n",
      "Epoch 63/399\n",
      "247.06648349761963\n",
      "Epoch 64/399\n",
      "247.38265752792358\n",
      "Epoch 65/399\n",
      "247.24029850959778\n",
      "Epoch 66/399\n",
      "246.99691653251648\n",
      "Epoch 67/399\n",
      "246.95132422447205\n",
      "Epoch 68/399\n",
      "247.67670845985413\n",
      "Epoch 69/399\n",
      "247.46721482276917\n",
      "Epoch 70/399\n",
      "246.92821311950684\n",
      "Epoch 71/399\n",
      "247.1085455417633\n",
      "Epoch 72/399\n",
      "247.09065985679626\n",
      "Epoch 73/399\n",
      "247.521746635437\n",
      "Epoch 74/399\n",
      "247.0544159412384\n",
      "Epoch 75/399\n",
      "247.22552037239075\n",
      "Epoch 76/399\n",
      "247.2026698589325\n",
      "Epoch 77/399\n",
      "247.3602991104126\n",
      "Epoch 78/399\n",
      "246.9870674610138\n",
      "Epoch 79/399\n",
      "247.18011164665222\n",
      "Epoch 80/399\n",
      "247.61591744422913\n",
      "Epoch 81/399\n",
      "247.36007142066956\n",
      "Epoch 82/399\n",
      "246.9206202030182\n",
      "Epoch 83/399\n",
      "247.48931884765625\n",
      "Epoch 84/399\n",
      "246.9256706237793\n",
      "Epoch 85/399\n",
      "247.0877857208252\n",
      "Epoch 86/399\n",
      "247.2041335105896\n",
      "Epoch 87/399\n",
      "247.47550702095032\n",
      "Epoch 88/399\n",
      "247.59579730033875\n",
      "Epoch 89/399\n",
      "246.75757241249084\n",
      "Epoch 90/399\n",
      "247.21105360984802\n",
      "Epoch 91/399\n",
      "246.75917172431946\n",
      "Epoch 92/399\n",
      "247.16454648971558\n",
      "Epoch 93/399\n",
      "247.77900886535645\n",
      "Epoch 94/399\n",
      "247.13048577308655\n",
      "Epoch 95/399\n",
      "247.12877368927002\n",
      "Epoch 96/399\n",
      "247.21153450012207\n",
      "Epoch 97/399\n",
      "247.1526346206665\n",
      "Epoch 98/399\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     25\u001b[39m scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Decay LR by a factor of 0.1 every 7 epochs\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m net_pugdr_cos, metricsr_sin = \u001b[43mtrain_model_alpha\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet_pugdr_cos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_sizes\u001b[49m\u001b[43m)\u001b[49m \n\u001b[32m     31\u001b[39m model_path = \u001b[33m\"\u001b[39m\u001b[33m./model/\u001b[39m\u001b[33m\"\u001b[39m+args.datasets+\u001b[33m\"\u001b[39m\u001b[33m/pugdr_cos\u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(optimizer.max_beta) + \u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(optimizer.min_beta) + \u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(args.epochs) + \u001b[33m\"\u001b[39m\u001b[33m.pth\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     32\u001b[39m torch.save({\n\u001b[32m     33\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmodel_state_dict\u001b[39m\u001b[33m'\u001b[39m: net_pugdr_cos.state_dict(), \n\u001b[32m     34\u001b[39m     \u001b[33m'\u001b[39m\u001b[33moptimizer_state_dict\u001b[39m\u001b[33m'\u001b[39m: optimizer.state_dict()\n\u001b[32m     35\u001b[39m }, model_path) \n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\CV_TRY\\train.py:317\u001b[39m, in \u001b[36mtrain_model_alpha\u001b[39m\u001b[34m(model, criterion, optimizer, scheduler, num_epochs, trainloader, device, dataset_sizes)\u001b[39m\n\u001b[32m    315\u001b[39m         loss = criterion(outputs, labels)       \n\u001b[32m    316\u001b[39m         loss.backward()\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m         \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43msecond_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[38;5;66;03m# statistics\u001b[39;00m\n\u001b[32m    319\u001b[39m running_loss += loss.item() * inputs.size(\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\CV_TRY\\optimizers.py:159\u001b[39m, in \u001b[36mPUGDXR.second_step\u001b[39m\u001b[34m(self, zero_grad)\u001b[39m\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(group[\u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m]):\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m p.grad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m         \u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43msub_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43me_w\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    160\u001b[39m         p.grad = p.grad * grad_norm_reciprocal\n\u001b[32m    162\u001b[39m \u001b[38;5;28mself\u001b[39m.base_optimizer.step()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "net_pugdr_cos = UPANets(args.filters, Num_class, args.blocks, img_size)\n",
    "net_pugdr_cos.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "net_pugdr_cos.to(device)\n",
    "\n",
    "if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "    model_ft_org = torch.nn.DataParallel(net_pugdr_cos)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "base_optimizer = optim.SGD\n",
    "optimizer = PUGDXR(net_pugdr_cos.parameters(),\n",
    "                base_optimizer,\n",
    "                lr=args.lr,\n",
    "                max_epochs= args.epochs,\n",
    "                momentum=args.momentum,\n",
    "                weight_decay=args.wd,\n",
    "                min_beta = 0.5, \n",
    "                max_beta = 1.5, \n",
    "                method = 'cos',\n",
    "                dampening=0,   # 必须设置为0才能完全固定 \n",
    "                nesterov=False # 禁用Nesterov动量 \n",
    "                )\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "# exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "net_pugdr_cos, metricsr_sin = train_model_alpha(net_pugdr_cos, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "model_path = \"./model/\"+args.datasets+\"/pugdr_cos\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".pth\"\n",
    "torch.save({\n",
    "    'model_state_dict': net_pugdr_cos.state_dict(), \n",
    "    'optimizer_state_dict': optimizer.state_dict()\n",
    "}, model_path) \n",
    "\n",
    "name = \"./results/\"+args.datasets+\"/pugdr_cos_\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".json\"\n",
    "with open(name,  'w', encoding='utf-8') as f:\n",
    "    json.dump(metricsr_sin,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be3e5d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pugds_cos = UPANets(args.filters, Num_class, args.blocks, img_size)  \n",
    "# net_pugds_cos.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net_pugds_cos.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     net_pugds_cos = torch.nn.DataParallel(net_pugds_cos)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDXS(net_pugds_cos.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=args.lr,\n",
    "#                 max_epochs= args.epochs,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 min_beta = 0.0, \n",
    "#                 max_beta = 2,\n",
    "#                 method = 'cos',\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                  )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "# # exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# net_pugds_cos, metricss_cos = train_model_alpha(net_pugds_cos, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "# model_path = \"./model/\"+args.datasets+\"/pugds_cos\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net_pugds_cos.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/pugds_cos_\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metricss_cos,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14e79fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pugds_sin = UPANets(args.filters, Num_class, args.blocks, img_size)  \n",
    "# net_pugds_sin.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net_pugds_sin.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     net_pugds_sin = torch.nn.DataParallel(net_pugds_sin)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDXS(net_pugds_sin.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=args.lr,\n",
    "#                 max_epochs= args.epochs,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 min_beta = 0.0, \n",
    "#                 max_beta = 2,\n",
    "#                 method = 'sin',\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                  )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "# # exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# net_pugds_sin, metricss_sin = train_model_alpha(net_pugds_sin, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "# model_path = \"./model/\"+args.datasets+\"/pugds_sin\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net_pugds_sin.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/pugds_sin_\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metricss_sin,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1d2ef1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pugd = UPANets(args.filters, Num_class, args.blocks, img_size)  \n",
    "# net_pugd.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net_pugd.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     model_ft_org = torch.nn.DataParallel(net_pugd)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDX(net_pugd.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=args.lr,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                  )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "# # exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# net_pugd, metrics0 = train_model(net_pugd, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "# model_path = \"./model/\"+args.datasets+\"/pugd\" + str(args.epochs) + \".pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net_pugd.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/pugd_\" + str(args.epochs) + \".json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metrics0,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c195537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pugdr_cos = UPANets(args.filters, Num_class, args.blocks, img_size)  \n",
    "# net_pugdr_cos.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net_pugdr_cos.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     model_ft_org = torch.nn.DataParallel(net_pugdr_cos)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDXR(net_pugdr_cos.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=args.lr,\n",
    "#                 max_epochs= args.epochs,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 min_beta = 0.01, \n",
    "#                 max_beta = 2, \n",
    "#                 method = 'icos',\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                 )\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "\n",
    "# net_pugdr_cos, metricsr_cos = train_model_alpha(net_pugdr_cos, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "# model_path = \"./model/\"+args.datasets+\"/pugdr_icos\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net_pugdr_cos.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/pugdr_icos_\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metricsr_cos,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10cf6955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pugdr_sin = UPANets(args.filters, Num_class, args.blocks, img_size)\n",
    "# net_pugdr_sin.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net_pugdr_sin.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     model_ft_org = torch.nn.DataParallel(net_pugdr_sin)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDXR(net_pugdr_sin.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=args.lr,\n",
    "#                 max_epochs= args.epochs,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 min_beta = 0.01, \n",
    "#                 max_beta = 2, \n",
    "#                 method = 'isin',\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                 )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "# # exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# net_pugdr_sin, metricsr_sin = train_model_alpha(net_pugdr_sin, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "# model_path = \"./model/\"+args.datasets+\"/pugdr_isin\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net_pugdr_sin.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/pugdr_isin_\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metricsr_sin,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6b645d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pugds_icos = UPANets(args.filters, Num_class, args.blocks, img_size)  \n",
    "# net_pugds_icos.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net_pugds_icos.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     net_pugds_icos = torch.nn.DataParallel(net_pugds_icos)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDXS(net_pugds_icos.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=args.lr,\n",
    "#                 max_epochs= args.epochs,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 min_beta = 0.8, \n",
    "#                 max_beta = 3, \n",
    "#                 method = 'icos',\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                  )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "# # exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# net_pugds_icos, metricss_icos = train_model_alpha(net_pugds_icos, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "# model_path = \"./model/\"+args.datasets+\"/pugds_icos\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net_pugds_icos.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/pugds_icos_\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metricss_icos,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "214741d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pugds_isin = UPANets(args.filters, Num_class, args.blocks, img_size)  \n",
    "# net_pugds_isin.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net_pugds_isin.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     net_pugds_isin = torch.nn.DataParallel(net_pugds_isin)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDXS(net_pugds_isin.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=args.lr,\n",
    "#                 max_epochs= args.epochs,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 min_beta = 0.8, \n",
    "#                 max_beta = 3, \n",
    "#                 method = 'isin',\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                  )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "# # exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# net_pugds_isin, metricss_isin = train_model_alpha(net_pugds_isin, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "# model_path = \"./model/\"+args.datasets+\"/pugds_isin\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net_pugds_isin.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/pugds_isin_\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metricss_isin,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672b77e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8923cee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(new_head.__dict__)\n",
    "# print(vars(new_head))\n",
    "# import optimizers\n",
    "# import importlib \n",
    "# importlib.reload(optimizers)   \n",
    "# from optimizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04c21966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_ft2 = timm.create_model('mobilenetv3_small_100', pretrained=True, num_classes=Num_class)\n",
    "# original_head = model_ft2.classifier   # MobileNetV3的分类头名为classifier \n",
    "# new_head = nn.Linear(original_head.in_features,  Num_class)\n",
    "# model_ft2 = model_ft2.to(device)\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# base_optimizer2 = optim.SGD\n",
    "# optimizer2 = PUGD2(model_ft2.parameters(),\n",
    "#                  base_optimizer2,\n",
    "#                  lr=args.lr,\n",
    "#                  momentum=args.momentum,\n",
    "#                  weight_decay=args.wd,\n",
    "#                  )\n",
    "\n",
    "\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "# exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer2, step_size=7, gamma=0.1)\n",
    "\n",
    "# model_ft2 = train_model2(model_ft2, criterion, optimizer2, exp_lr_scheduler, num_epochs=20) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
