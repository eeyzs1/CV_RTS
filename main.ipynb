{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d229fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c297172",
   "metadata": {},
   "source": [
    "Multi-level Perturbed Unit Gradient Descent, MPUGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51d2b3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data  import Subset, DataLoader\n",
    "from sklearn.model_selection  import train_test_split \n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from types import SimpleNamespace \n",
    "import matplotlib.pyplot  as plt\n",
    "import numpy as np \n",
    "\n",
    "from optimizers import *\n",
    "from upanets import UPANets\n",
    "from torchsummary import summary\n",
    "import time, copy,timm\n",
    "import json\n",
    "import random \n",
    "import os\n",
    "from train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaa60ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "args = SimpleNamespace(\n",
    "    datasets='cifar_10',\n",
    "    batch_size = 500,\n",
    "    seed = 42,\n",
    "    lr=0.1, \n",
    "    momentum=0.9,\n",
    "    wd = 0.0005,\n",
    "    blocks = 1,\n",
    "    filters = 16,\n",
    "    epochs = 400,\n",
    "    start_epochs = 8\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bdda934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_all_seeds(seed=42):\n",
    "    # Python原生随机 \n",
    "    random.seed(seed) \n",
    "    # NumPy随机 \n",
    "    np.random.seed(seed) \n",
    "    # PyTorch随机 \n",
    "    torch.manual_seed(seed) \n",
    "    # CUDA随机（GPU相关）\n",
    "    torch.cuda.manual_seed_all(seed) \n",
    "    # CUDNN确定性模式 \n",
    "    torch.backends.cudnn.deterministic  = True \n",
    "    torch.backends.cudnn.benchmark  = False \n",
    " \n",
    "set_all_seeds(args.seed)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca2f2d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "557e50ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 50000, 'valid': 10000}\n"
     ]
    }
   ],
   "source": [
    "img_size = 32 # default image size for Cifar-10\n",
    "im_dimention = 32\n",
    "cifar_10_mean = [0.4914, 0.4822, 0.4465] \n",
    "cifar_10_std = [0.2023, 0.1994, 0.2010]\n",
    "cifar_100_mean = [0.5071, 0.4867, 0.4408]\n",
    "cifar_100_std = [0.2673, 0.2564, 0.2762]\n",
    "\n",
    "if args.datasets == 'cifar_10':\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize((im_dimention,im_dimention)),\n",
    "            transforms.RandomRotation(15,),\n",
    "            transforms.RandomCrop(im_dimention),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=cifar_10_mean, std=cifar_10_std)\n",
    "        ]),\n",
    "        # 'valid': transforms.Compose([\n",
    "        #     transforms.Resize((im_dimention,im_dimention)),\n",
    "        #     transforms.ToTensor(),\n",
    "        #     transforms.Normalize(mean=cifar_10_mean, std=cifar_10_std)\n",
    "        # ]),\n",
    "        'test': transforms.Compose([\n",
    "            transforms.Resize((im_dimention,im_dimention)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=cifar_10_mean, std=cifar_10_std)\n",
    "        ]),\n",
    "    }\n",
    " \n",
    "    full_trainset = torchvision.datasets.CIFAR10(\n",
    "        root='./data/cifar_10', train=True, download=True, transform=data_transforms['train'])\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root='./data/cifar_10', train=False, download=True, transform=data_transforms['test'])\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=args.batch_size, shuffle=False, num_workers=0)\n",
    "    Num_class = 10\n",
    "\n",
    "if args.datasets == 'cifar_100':\n",
    "    data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((im_dimention,im_dimention)),\n",
    "        transforms.RandomRotation(15,),\n",
    "        transforms.RandomCrop(im_dimention),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=cifar_100_mean, std=cifar_100_std)\n",
    "    ]),\n",
    "    # 'valid': transforms.Compose([\n",
    "    #     transforms.Resize((im_dimention,im_dimention)),\n",
    "    #     transforms.ToTensor(),\n",
    "    #     transforms.Normalize(mean=cifar_100_mean, std=cifar_100_std)\n",
    "    # ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((im_dimention,im_dimention)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=cifar_100_mean, std=cifar_100_std)\n",
    "    ]),\n",
    "    }\n",
    "    full_trainset = torchvision.datasets.CIFAR100(\n",
    "        root='./data/cifar_100', train=True, download=True, transform=data_transforms['train'])\n",
    "    testset = torchvision.datasets.CIFAR100(\n",
    "        root='./data/cifar_100', train=False, download=True, transform=data_transforms['test'])\n",
    "    testloader = DataLoader(\n",
    "        testset, batch_size=args.batch_size, shuffle=False,sampler=torch.utils.data.SequentialSampler(testset),  num_workers=0)\n",
    "    Num_class = 100\n",
    "\n",
    "# # 获取所有样本的标签 \n",
    "# labels = [full_trainset[i][1] for i in range(len(full_trainset))]\n",
    "\n",
    "# # 分层划分（stratify参数确保比例）\n",
    "# train_idx, val_idx = train_test_split(\n",
    "#     range(len(full_trainset)),\n",
    "#     test_size=0.2,\n",
    "#     shuffle=True,\n",
    "#     stratify=labels,\n",
    "#     random_state=args.seed  \n",
    "# )\n",
    "\n",
    "# train_data = np.stack([full_trainset.data[i]  for i in train_idx]) \n",
    "# train_targets = [full_trainset.targets[i] for i in train_idx] \n",
    "# val_data = np.stack([full_trainset.data[i]  for i in val_idx]) \n",
    "# val_targets = [full_trainset.targets[i] for i in val_idx] \n",
    "\n",
    "# valset = full_trainset\n",
    "# valset.data = val_data\n",
    "# valset.targets = val_targets\n",
    "# valset.transform = data_transforms['valid']\n",
    "\n",
    "# trainset = copy.deepcopy(valset)\n",
    "# trainset.data = train_data\n",
    "# trainset.targets = train_targets\n",
    "# trainset.transform = data_transforms['train']\n",
    "\n",
    "# trainloader = {\n",
    "#     'train':DataLoader(\n",
    "#     trainset, batch_size=args.batch_size, shuffle=False, sampler=torch.utils.data.SequentialSampler(trainset), num_workers=0),\n",
    "#     'valid':DataLoader(\n",
    "#     valset, batch_size=args.batch_size, shuffle=False, sampler=torch.utils.data.SequentialSampler(valset), num_workers=0)}\n",
    "\n",
    "# dataset_sizes = {\n",
    "#     'train': len(trainset),\n",
    "#     'valid': len(valset),            \n",
    "                #  }\n",
    "\n",
    "trainloader = {\n",
    "    'train':DataLoader(\n",
    "    full_trainset, batch_size=args.batch_size, shuffle=False, sampler=torch.utils.data.SequentialSampler(full_trainset), num_workers=0),\n",
    "    'valid':testloader\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "    'train': len(full_trainset),\n",
    "    'valid': len(testset),      \n",
    "}\n",
    "print(dataset_sizes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "840b5037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vit_tiny_patch16_224']\n"
     ]
    }
   ],
   "source": [
    "print(timm.list_models('*vit_tiny_patch16_224*')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ab5b31b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from torchvision.transforms.functional  import to_pil_image \n",
    "# 反归一化转换（需与transform中的参数对应）\n",
    "inv_normalize = transforms.Normalize(\n",
    "    mean=[-0.4914/0.2023, -0.4822/0.1994, -0.4465/0.2010],\n",
    "    std=[1/0.2023, 1/0.1994, 1/0.2010]\n",
    ")\n",
    " \n",
    "def show_images(loader, num_images=4):\n",
    "    # 获取一个batch的数据 \n",
    "    # images, labels = next(iter(loader))\n",
    "    for batch_idx, (images, labels) in enumerate(loader):\n",
    "        if batch_idx == 0:  # 只取第一个batch \n",
    "            break \n",
    "\n",
    "    # 创建子图 \n",
    "    fig, axes = plt.subplots(1,  num_images, figsize=(15, 3))\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        # 反归一化+通道顺序调整 \n",
    "        img = inv_normalize(images[i]).permute(1, 2, 0).numpy()\n",
    "        img = np.clip(img,  0, 1)  # 处理浮点误差 \n",
    "        \n",
    "        # 显示图像及标签 \n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f\"Label: {full_trainset.classes[labels[i]]}\") \n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.show() \n",
    " \n",
    "show_images(trainloader['train'])\n",
    "show_images(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5aa47f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./model/\" + args.datasets + \"/benckmark.pth\"\n",
    "if os.path.exists(model_path):\n",
    "    net_benckmark_data = torch.load(model_path,  map_location='cpu')\n",
    "    benckmark_state_dict = net_benckmark_data['model_state_dict'] \n",
    "else:\n",
    "    net_benchmark = UPANets(args.filters, Num_class, args.blocks, img_size)\n",
    "    torch.save({\n",
    "        'model_state_dict': net_benchmark.state_dict()\n",
    "    }, model_path)\n",
    "    benckmark_state_dict = net_benchmark.state_dict()\n",
    "\n",
    "def tensor_to_serializable(obj):\n",
    "    if isinstance(obj, (np.float32,  np.float64)):   # 处理NumPy浮点数\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.integer):               # 处理NumPy整数 \n",
    "        return int(obj)\n",
    "    elif isinstance(obj, torch.Tensor):            # 处理PyTorch Tensor \n",
    "        return obj.item()  if obj.numel()  == 1 else obj.tolist() \n",
    "    elif isinstance(obj, (np.ndarray)):             # 处理NumPy数组 \n",
    "        return obj.tolist() \n",
    "    elif hasattr(obj, '__dict__'):                 # 处理自定义对象（可选）\n",
    "        return obj.__dict__\n",
    "    return obj \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3ec9786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pugdt_delta = UPANets(args.filters, Num_class, args.blocks, img_size)  \n",
    "# net_pugdt_delta.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net_pugdt_delta.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     net_pugdt_delta = torch.nn.DataParallel(net_pugdt_delta)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDXT(net_pugdt_delta.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=args.lr,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                 )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "\n",
    "# net_pugdt_delta, metricst_delta = train_model_timing_delta(net_pugdt_delta, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes, int(args.epochs/10), 0.01, 10) \n",
    "\n",
    "# model_path = \"./model/\"+args.datasets+\"/pugdt_delta_\" + str(args.epochs) + \"xi\" + str(args.epochs/10) + \"mu0.01_t10.pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net_pugdt_delta.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/pugdt_delta_\" + str(args.epochs) + \"xi\" + str(args.epochs/10) + \"mu0.01_t10.json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metricst_delta,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efb925b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pugdt_var = UPANets(args.filters, Num_class, args.blocks, img_size)  \n",
    "# net_pugdt_var.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net_pugdt_var.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     net_pugdt_var = torch.nn.DataParallel(net_pugdt_var)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDXT(net_pugdt_var.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=args.lr,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                 )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "\n",
    "# net_pugdt_var, metricst_var = train_model_timing_var(net_pugdt_var, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes, int(args.epochs/10), 0.015, 10) \n",
    "\n",
    "# model_path = \"./model/\"+args.datasets+\"/pugdt_var_\" + str(args.epochs) + \"init_t\" + str(args.epochs/10) + \"gamma0.015_k10.pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net_pugdt_var.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/pugdt_var_\" + str(args.epochs) + \"init_t\" + str(args.epochs/10) + \"gamma0.015_k10.json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metricst_var,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a42d18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = UPANets(args.filters, Num_class, args.blocks, img_size)\n",
    "# net.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     net = torch.nn.DataParallel(net)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# optimizer = optim.SGD(net.parameters(),\n",
    "#                 lr=args.lr,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                  )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "# # exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# net, metrics_org = train_model_org(net, criterion, optimizer, scheduler, args.epochs * 2, trainloader, device, dataset_sizes) \n",
    "\n",
    "# # 保存模型架构+参数+优化器状态（完整恢复训练）\n",
    "# model_path = \"./model/\"+args.datasets+\"/org\" + str(args.epochs) + \".pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/org_\" + str(args.epochs) + \".json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metrics_org, f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n",
    " \n",
    "# # 加载 \n",
    "\n",
    "# # checkpoint = torch.load('full_model_checkpoint.pth',  map_location='cpu')  # 先加载到CPU避免设备冲突 \n",
    "# # 模型结构需提前定义（需与保存时一致）\n",
    "# # model = YourModelClass()  \n",
    "# # model.load_state_dict(checkpoint['model_state_dict']) \n",
    " \n",
    "# # # 恢复优化器和训练状态 \n",
    "# # optimizer = torch.optim.Adam(model.parameters())  \n",
    "# # optimizer.load_state_dict(checkpoint['optimizer_state_dict']) \n",
    "# # with open('data.json',  'r', encoding='utf-8') as f:\n",
    "# #     loaded_dict = json.load(f) \n",
    "\n",
    "\n",
    "# # summary(net, (3, img_size, img_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db0a205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/399\n"
     ]
    }
   ],
   "source": [
    "net_pugdr_sin = UPANets(args.filters, Num_class, args.blocks, img_size)\n",
    "net_pugdr_sin.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "net_pugdr_sin.to(device)\n",
    "\n",
    "if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "    model_ft_org = torch.nn.DataParallel(net_pugdr_sin)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "base_optimizer = optim.SGD\n",
    "optimizer = PUGDXR(net_pugdr_sin.parameters(),\n",
    "                base_optimizer,\n",
    "                lr=args.lr,\n",
    "                max_epochs= args.epochs,\n",
    "                momentum=args.momentum,\n",
    "                weight_decay=args.wd,\n",
    "                min_beta = 0.5, \n",
    "                max_beta = 10, \n",
    "                method = 'sin',\n",
    "                dampening=0,   # 必须设置为0才能完全固定 \n",
    "                nesterov=False # 禁用Nesterov动量 \n",
    "                )\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "# exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "net_pugdr_sin, metricsr_sin = train_model_alpha(net_pugdr_sin, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "model_path = \"./model/\"+args.datasets+\"/pugdr_sin\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".pth\"\n",
    "torch.save({\n",
    "    'model_state_dict': net_pugdr_sin.state_dict(), \n",
    "    'optimizer_state_dict': optimizer.state_dict()\n",
    "}, model_path) \n",
    "\n",
    "name = \"./results/\"+args.datasets+\"/pugdr_sin_\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".json\"\n",
    "with open(name,  'w', encoding='utf-8') as f:\n",
    "    json.dump(metricsr_sin,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82cb0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243.23909068107605\n",
      "Epoch 1/399\n",
      "243.8208713531494\n",
      "Epoch 2/399\n",
      "244.28518533706665\n",
      "Epoch 3/399\n",
      "242.08074593544006\n",
      "Epoch 4/399\n",
      "240.59423112869263\n",
      "Epoch 5/399\n",
      "242.60903525352478\n",
      "Epoch 6/399\n",
      "243.90893530845642\n",
      "Epoch 7/399\n",
      "243.85498547554016\n",
      "Epoch 8/399\n",
      "241.4214117527008\n",
      "Epoch 9/399\n",
      "239.13090682029724\n",
      "Epoch 10/399\n",
      "239.42193603515625\n",
      "Epoch 11/399\n",
      "239.6088948249817\n",
      "Epoch 12/399\n",
      "239.37951564788818\n",
      "Epoch 13/399\n",
      "239.0820472240448\n",
      "Epoch 14/399\n",
      "238.1838583946228\n",
      "Epoch 15/399\n",
      "237.84930634498596\n",
      "Epoch 16/399\n",
      "243.41496300697327\n",
      "Epoch 17/399\n",
      "249.7070915699005\n",
      "Epoch 18/399\n",
      "257.45102095603943\n",
      "Epoch 19/399\n",
      "305.91173028945923\n",
      "Epoch 20/399\n",
      "312.9165709018707\n",
      "Epoch 21/399\n",
      "312.7051131725311\n",
      "Epoch 22/399\n",
      "312.83190631866455\n",
      "Epoch 23/399\n",
      "314.9016764163971\n",
      "Epoch 24/399\n",
      "313.1760764122009\n",
      "Epoch 25/399\n",
      "313.5197010040283\n",
      "Epoch 26/399\n",
      "316.90435457229614\n",
      "Epoch 27/399\n",
      "313.43523836135864\n",
      "Epoch 28/399\n",
      "311.92808175086975\n",
      "Epoch 29/399\n",
      "314.8286085128784\n",
      "Epoch 30/399\n",
      "311.97400975227356\n",
      "Epoch 31/399\n",
      "310.6834762096405\n",
      "Epoch 32/399\n",
      "306.0119380950928\n",
      "Epoch 33/399\n",
      "312.2126009464264\n",
      "Epoch 34/399\n",
      "312.8573513031006\n",
      "Epoch 35/399\n",
      "279.22347235679626\n",
      "Epoch 36/399\n",
      "252.43659090995789\n",
      "Epoch 37/399\n",
      "251.98134088516235\n",
      "Epoch 38/399\n",
      "251.45058941841125\n",
      "Epoch 39/399\n",
      "251.43408703804016\n",
      "Epoch 40/399\n",
      "247.01580333709717\n",
      "Epoch 41/399\n",
      "246.33452010154724\n",
      "Epoch 42/399\n",
      "245.97565817832947\n",
      "Epoch 43/399\n",
      "246.208913564682\n",
      "Epoch 44/399\n",
      "246.51798367500305\n",
      "Epoch 45/399\n",
      "246.12278747558594\n",
      "Epoch 46/399\n",
      "246.24455451965332\n",
      "Epoch 47/399\n",
      "246.31405019760132\n",
      "Epoch 48/399\n",
      "245.88006711006165\n",
      "Epoch 49/399\n",
      "246.07342171669006\n",
      "Epoch 50/399\n",
      "245.87481689453125\n",
      "Epoch 51/399\n",
      "246.2285602092743\n",
      "Epoch 52/399\n",
      "245.95909667015076\n",
      "Epoch 53/399\n",
      "248.94648122787476\n",
      "Epoch 54/399\n",
      "252.4305293560028\n",
      "Epoch 55/399\n",
      "252.1705892086029\n",
      "Epoch 56/399\n",
      "252.3011772632599\n",
      "Epoch 57/399\n",
      "252.2333858013153\n",
      "Epoch 58/399\n",
      "247.56795287132263\n",
      "Epoch 59/399\n",
      "245.9716489315033\n",
      "Epoch 60/399\n",
      "245.62228393554688\n",
      "Epoch 61/399\n",
      "245.73859286308289\n",
      "Epoch 62/399\n",
      "245.6747546195984\n",
      "Epoch 63/399\n",
      "245.86486649513245\n",
      "Epoch 64/399\n",
      "246.0393898487091\n",
      "Epoch 65/399\n",
      "245.91284775733948\n",
      "Epoch 66/399\n",
      "250.5884187221527\n",
      "Epoch 67/399\n",
      "251.48165798187256\n",
      "Epoch 68/399\n",
      "251.85953307151794\n",
      "Epoch 69/399\n",
      "251.59488558769226\n",
      "Epoch 70/399\n",
      "251.86502408981323\n",
      "Epoch 71/399\n",
      "246.94157767295837\n",
      "Epoch 72/399\n",
      "245.6394808292389\n",
      "Epoch 73/399\n",
      "245.8745675086975\n",
      "Epoch 74/399\n",
      "245.93281412124634\n",
      "Epoch 75/399\n",
      "246.22107124328613\n",
      "Epoch 76/399\n",
      "245.55105328559875\n",
      "Epoch 77/399\n",
      "245.74356722831726\n",
      "Epoch 78/399\n",
      "245.85775661468506\n",
      "Epoch 79/399\n",
      "245.95273780822754\n",
      "Epoch 80/399\n",
      "245.72894644737244\n",
      "Epoch 81/399\n",
      "245.66128087043762\n",
      "Epoch 82/399\n",
      "245.89278411865234\n",
      "Epoch 83/399\n",
      "245.79433393478394\n",
      "Epoch 84/399\n",
      "245.96102929115295\n",
      "Epoch 85/399\n",
      "245.62576270103455\n",
      "Epoch 86/399\n",
      "246.07462453842163\n",
      "Epoch 87/399\n",
      "245.94102931022644\n",
      "Epoch 88/399\n",
      "245.68753957748413\n",
      "Epoch 89/399\n",
      "245.93418097496033\n",
      "Epoch 90/399\n",
      "245.78356409072876\n",
      "Epoch 91/399\n",
      "245.95894932746887\n",
      "Epoch 92/399\n",
      "245.77017378807068\n",
      "Epoch 93/399\n",
      "245.75651860237122\n",
      "Epoch 94/399\n",
      "245.74562978744507\n",
      "Epoch 95/399\n",
      "245.7344033718109\n",
      "Epoch 96/399\n",
      "246.20224595069885\n",
      "Epoch 97/399\n",
      "245.77285146713257\n",
      "Epoch 98/399\n",
      "245.77564096450806\n",
      "Epoch 99/399\n",
      "245.6834900379181\n",
      "Epoch 100/399\n",
      "245.9258930683136\n",
      "Epoch 101/399\n",
      "245.53977012634277\n",
      "Epoch 102/399\n",
      "245.5566804409027\n",
      "Epoch 103/399\n",
      "245.5695607662201\n",
      "Epoch 104/399\n",
      "245.92706680297852\n",
      "Epoch 105/399\n",
      "245.51763772964478\n",
      "Epoch 106/399\n",
      "245.3561327457428\n",
      "Epoch 107/399\n",
      "245.5023639202118\n",
      "Epoch 108/399\n",
      "245.61813974380493\n",
      "Epoch 109/399\n",
      "245.47827076911926\n",
      "Epoch 110/399\n",
      "245.87608647346497\n",
      "Epoch 111/399\n",
      "245.33090257644653\n",
      "Epoch 112/399\n",
      "245.8275978565216\n",
      "Epoch 113/399\n",
      "245.8963131904602\n",
      "Epoch 114/399\n",
      "245.72360801696777\n",
      "Epoch 115/399\n",
      "245.51614570617676\n",
      "Epoch 116/399\n",
      "245.64031338691711\n",
      "Epoch 117/399\n",
      "245.85310554504395\n",
      "Epoch 118/399\n",
      "245.69608545303345\n",
      "Epoch 119/399\n",
      "246.09224390983582\n",
      "Epoch 120/399\n",
      "245.74705719947815\n",
      "Epoch 121/399\n",
      "245.80368661880493\n",
      "Epoch 122/399\n",
      "245.54445505142212\n",
      "Epoch 123/399\n",
      "245.82579851150513\n",
      "Epoch 124/399\n",
      "246.03204870224\n",
      "Epoch 125/399\n",
      "245.59166741371155\n",
      "Epoch 126/399\n",
      "245.54280543327332\n",
      "Epoch 127/399\n",
      "245.63026595115662\n",
      "Epoch 128/399\n",
      "245.69206070899963\n",
      "Epoch 129/399\n",
      "245.64096784591675\n",
      "Epoch 130/399\n",
      "245.51441049575806\n",
      "Epoch 131/399\n",
      "245.89607167243958\n",
      "Epoch 132/399\n",
      "245.5720407962799\n",
      "Epoch 133/399\n",
      "245.65604758262634\n",
      "Epoch 134/399\n",
      "245.53910851478577\n",
      "Epoch 135/399\n",
      "245.6592149734497\n",
      "Epoch 136/399\n",
      "245.53264546394348\n",
      "Epoch 137/399\n",
      "245.98974108695984\n",
      "Epoch 138/399\n",
      "245.354834318161\n",
      "Epoch 139/399\n",
      "245.6514434814453\n",
      "Epoch 140/399\n",
      "245.5761296749115\n",
      "Epoch 141/399\n",
      "245.74307298660278\n",
      "Epoch 142/399\n",
      "245.64192152023315\n",
      "Epoch 143/399\n",
      "245.63857007026672\n",
      "Epoch 144/399\n",
      "245.8966188430786\n",
      "Epoch 145/399\n",
      "245.69098687171936\n",
      "Epoch 146/399\n",
      "245.8778851032257\n",
      "Epoch 147/399\n",
      "245.67482542991638\n",
      "Epoch 148/399\n",
      "245.26323795318604\n",
      "Epoch 149/399\n",
      "245.66299176216125\n",
      "Epoch 150/399\n",
      "245.6679368019104\n",
      "Epoch 151/399\n",
      "245.58204197883606\n",
      "Epoch 152/399\n",
      "245.5567364692688\n",
      "Epoch 153/399\n",
      "245.6257438659668\n",
      "Epoch 154/399\n",
      "245.44650745391846\n",
      "Epoch 155/399\n",
      "245.3203830718994\n",
      "Epoch 156/399\n",
      "245.47173500061035\n",
      "Epoch 157/399\n",
      "245.52015233039856\n",
      "Epoch 158/399\n",
      "245.51841568946838\n",
      "Epoch 159/399\n",
      "245.33716917037964\n",
      "Epoch 160/399\n",
      "246.0915288925171\n",
      "Epoch 161/399\n",
      "245.38397932052612\n",
      "Epoch 162/399\n",
      "245.43986630439758\n",
      "Epoch 163/399\n",
      "245.48708176612854\n",
      "Epoch 164/399\n",
      "245.78504490852356\n",
      "Epoch 165/399\n",
      "245.17019271850586\n",
      "Epoch 166/399\n",
      "245.23332810401917\n",
      "Epoch 167/399\n",
      "245.42588996887207\n",
      "Epoch 168/399\n",
      "245.18744468688965\n",
      "Epoch 169/399\n",
      "245.4424238204956\n",
      "Epoch 170/399\n",
      "245.53016233444214\n",
      "Epoch 171/399\n",
      "245.2614061832428\n",
      "Epoch 172/399\n",
      "245.33703207969666\n",
      "Epoch 173/399\n",
      "245.3401095867157\n",
      "Epoch 174/399\n",
      "245.40606355667114\n",
      "Epoch 175/399\n",
      "245.1880464553833\n",
      "Epoch 176/399\n",
      "245.3658411502838\n",
      "Epoch 177/399\n",
      "245.8861165046692\n",
      "Epoch 178/399\n",
      "245.6264955997467\n",
      "Epoch 179/399\n",
      "245.1290693283081\n",
      "Epoch 180/399\n",
      "245.25067806243896\n",
      "Epoch 181/399\n",
      "245.1718192100525\n",
      "Epoch 182/399\n",
      "245.2211890220642\n",
      "Epoch 183/399\n",
      "244.98899912834167\n",
      "Epoch 184/399\n",
      "245.0438048839569\n",
      "Epoch 185/399\n",
      "245.3828248977661\n",
      "Epoch 186/399\n",
      "244.9624800682068\n",
      "Epoch 187/399\n",
      "245.48452520370483\n",
      "Epoch 188/399\n",
      "245.31293869018555\n",
      "Epoch 189/399\n",
      "245.16939234733582\n",
      "Epoch 190/399\n",
      "245.36059880256653\n",
      "Epoch 191/399\n",
      "245.06642055511475\n",
      "Epoch 192/399\n",
      "245.22615909576416\n",
      "Epoch 193/399\n",
      "245.54193496704102\n",
      "Epoch 194/399\n",
      "245.41373753547668\n",
      "Epoch 195/399\n",
      "245.31499314308167\n",
      "Epoch 196/399\n",
      "245.12071657180786\n",
      "Epoch 197/399\n",
      "245.6312599182129\n",
      "Epoch 198/399\n",
      "245.5019235610962\n",
      "Epoch 199/399\n",
      "244.87830519676208\n",
      "Epoch 200/399\n",
      "244.8278408050537\n",
      "Epoch 201/399\n",
      "245.02604174613953\n",
      "Epoch 202/399\n",
      "245.32241797447205\n",
      "Epoch 203/399\n",
      "245.1976683139801\n",
      "Epoch 204/399\n",
      "245.25027585029602\n",
      "Epoch 205/399\n",
      "245.02755045890808\n",
      "Epoch 206/399\n",
      "244.95144271850586\n",
      "Epoch 207/399\n",
      "244.98886609077454\n",
      "Epoch 208/399\n",
      "245.1255943775177\n",
      "Epoch 209/399\n",
      "245.1423671245575\n",
      "Epoch 210/399\n",
      "245.42146611213684\n",
      "Epoch 211/399\n",
      "245.32452249526978\n",
      "Epoch 212/399\n",
      "245.2846908569336\n",
      "Epoch 213/399\n",
      "245.1142041683197\n",
      "Epoch 214/399\n",
      "245.1215124130249\n",
      "Epoch 215/399\n",
      "245.17909955978394\n",
      "Epoch 216/399\n",
      "245.64585852622986\n",
      "Epoch 217/399\n",
      "245.90610003471375\n",
      "Epoch 218/399\n",
      "245.25811648368835\n",
      "Epoch 219/399\n",
      "245.16147232055664\n",
      "Epoch 220/399\n",
      "245.8065767288208\n",
      "Epoch 221/399\n",
      "245.60704231262207\n",
      "Epoch 222/399\n",
      "245.1891758441925\n",
      "Epoch 223/399\n",
      "245.40851497650146\n",
      "Epoch 224/399\n",
      "245.3618083000183\n",
      "Epoch 225/399\n",
      "245.2860791683197\n",
      "Epoch 226/399\n",
      "245.25237607955933\n",
      "Epoch 227/399\n",
      "245.35874152183533\n",
      "Epoch 228/399\n",
      "245.22969937324524\n",
      "Epoch 229/399\n",
      "245.19041657447815\n",
      "Epoch 230/399\n",
      "245.17547082901\n",
      "Epoch 231/399\n",
      "245.49870920181274\n",
      "Epoch 232/399\n",
      "244.92801070213318\n",
      "Epoch 233/399\n",
      "245.10564422607422\n",
      "Epoch 234/399\n",
      "245.60772347450256\n",
      "Epoch 235/399\n",
      "245.10764360427856\n",
      "Epoch 236/399\n",
      "245.47179985046387\n",
      "Epoch 237/399\n",
      "245.66894125938416\n",
      "Epoch 238/399\n",
      "245.34972715377808\n",
      "Epoch 239/399\n",
      "245.55395793914795\n",
      "Epoch 240/399\n",
      "246.00288653373718\n",
      "Epoch 241/399\n",
      "245.74668550491333\n",
      "Epoch 242/399\n",
      "245.5755205154419\n",
      "Epoch 243/399\n",
      "245.61455655097961\n",
      "Epoch 244/399\n",
      "245.41973519325256\n",
      "Epoch 245/399\n",
      "245.36093926429749\n",
      "Epoch 246/399\n",
      "245.7674355506897\n",
      "Epoch 247/399\n",
      "245.52872586250305\n",
      "Epoch 248/399\n",
      "245.8011212348938\n",
      "Epoch 249/399\n",
      "245.66535568237305\n",
      "Epoch 250/399\n",
      "245.7089490890503\n",
      "Epoch 251/399\n",
      "245.58351874351501\n",
      "Epoch 252/399\n",
      "245.78408551216125\n",
      "Epoch 253/399\n",
      "245.46965193748474\n",
      "Epoch 254/399\n",
      "245.62950134277344\n",
      "Epoch 255/399\n",
      "245.69036960601807\n",
      "Epoch 256/399\n",
      "244.8550364971161\n",
      "Epoch 257/399\n",
      "245.20189499855042\n",
      "Epoch 258/399\n",
      "245.35280203819275\n",
      "Epoch 259/399\n",
      "245.74858832359314\n",
      "Epoch 260/399\n",
      "246.03955149650574\n",
      "Epoch 261/399\n",
      "246.02101612091064\n",
      "Epoch 262/399\n",
      "245.95242047309875\n",
      "Epoch 263/399\n",
      "245.946524143219\n",
      "Epoch 264/399\n",
      "246.11817693710327\n",
      "Epoch 265/399\n",
      "246.28568196296692\n",
      "Epoch 266/399\n",
      "246.01901173591614\n",
      "Epoch 267/399\n",
      "245.99430680274963\n",
      "Epoch 268/399\n",
      "245.6743905544281\n",
      "Epoch 269/399\n",
      "246.28763365745544\n",
      "Epoch 270/399\n",
      "246.50465273857117\n",
      "Epoch 271/399\n",
      "246.19252252578735\n",
      "Epoch 272/399\n",
      "246.1533145904541\n",
      "Epoch 273/399\n",
      "252.11876225471497\n",
      "Epoch 274/399\n",
      "252.28247213363647\n",
      "Epoch 275/399\n",
      "245.50346112251282\n",
      "Epoch 276/399\n",
      "244.878568649292\n",
      "Epoch 277/399\n",
      "244.89908361434937\n",
      "Epoch 278/399\n",
      "244.80190134048462\n",
      "Epoch 279/399\n",
      "244.68596076965332\n",
      "Epoch 280/399\n",
      "243.1341588497162\n",
      "Epoch 281/399\n",
      "244.90203833580017\n",
      "Epoch 282/399\n",
      "246.83051681518555\n",
      "Epoch 283/399\n",
      "247.19742584228516\n",
      "Epoch 284/399\n",
      "247.0769681930542\n",
      "Epoch 285/399\n",
      "247.49052095413208\n",
      "Epoch 286/399\n",
      "247.85590815544128\n",
      "Epoch 287/399\n",
      "247.36836171150208\n",
      "Epoch 288/399\n",
      "244.18234872817993\n",
      "Epoch 289/399\n",
      "246.27480721473694\n",
      "Epoch 290/399\n",
      "246.961168050766\n",
      "Epoch 291/399\n",
      "248.5091736316681\n",
      "Epoch 292/399\n",
      "247.42422127723694\n",
      "Epoch 293/399\n",
      "247.43731546401978\n",
      "Epoch 294/399\n",
      "246.81227278709412\n",
      "Epoch 295/399\n",
      "248.0246078968048\n",
      "Epoch 296/399\n",
      "246.90534281730652\n",
      "Epoch 297/399\n",
      "246.7551348209381\n",
      "Epoch 298/399\n",
      "247.75711727142334\n",
      "Epoch 299/399\n",
      "248.43805718421936\n",
      "Epoch 300/399\n",
      "248.25042700767517\n",
      "Epoch 301/399\n",
      "246.60929036140442\n",
      "Epoch 302/399\n",
      "244.98192262649536\n",
      "Epoch 303/399\n",
      "245.24440574645996\n",
      "Epoch 304/399\n",
      "244.1820125579834\n",
      "Epoch 305/399\n",
      "244.53020238876343\n",
      "Epoch 306/399\n",
      "243.82011198997498\n",
      "Epoch 307/399\n",
      "249.45865774154663\n",
      "Epoch 308/399\n",
      "246.88652348518372\n",
      "Epoch 309/399\n",
      "246.83326268196106\n",
      "Epoch 310/399\n",
      "244.7927987575531\n",
      "Epoch 311/399\n",
      "245.1019148826599\n",
      "Epoch 312/399\n",
      "245.14666938781738\n",
      "Epoch 313/399\n",
      "245.85224437713623\n",
      "Epoch 314/399\n",
      "246.83933901786804\n",
      "Epoch 315/399\n",
      "246.90560936927795\n",
      "Epoch 316/399\n",
      "246.84213066101074\n",
      "Epoch 317/399\n",
      "246.6692876815796\n",
      "Epoch 318/399\n",
      "245.69408774375916\n",
      "Epoch 319/399\n",
      "248.25561213493347\n",
      "Epoch 320/399\n",
      "245.83507466316223\n",
      "Epoch 321/399\n",
      "246.30208587646484\n",
      "Epoch 322/399\n",
      "248.11246490478516\n",
      "Epoch 323/399\n",
      "247.18885111808777\n",
      "Epoch 324/399\n",
      "245.63060593605042\n",
      "Epoch 325/399\n",
      "245.03383827209473\n",
      "Epoch 326/399\n",
      "245.08106660842896\n",
      "Epoch 327/399\n",
      "245.61913990974426\n",
      "Epoch 328/399\n",
      "245.5159204006195\n",
      "Epoch 329/399\n",
      "244.44658708572388\n",
      "Epoch 330/399\n",
      "243.5395781993866\n",
      "Epoch 331/399\n",
      "243.23534607887268\n",
      "Epoch 332/399\n",
      "243.1108057498932\n",
      "Epoch 333/399\n",
      "243.56722736358643\n",
      "Epoch 334/399\n",
      "242.8971574306488\n",
      "Epoch 335/399\n",
      "243.03863334655762\n",
      "Epoch 336/399\n",
      "243.01399326324463\n",
      "Epoch 337/399\n",
      "243.25264525413513\n",
      "Epoch 338/399\n",
      "243.4217553138733\n",
      "Epoch 339/399\n",
      "243.36849904060364\n",
      "Epoch 340/399\n",
      "243.17241716384888\n",
      "Epoch 341/399\n",
      "243.38751864433289\n",
      "Epoch 342/399\n",
      "242.957923412323\n",
      "Epoch 343/399\n",
      "243.24518203735352\n",
      "Epoch 344/399\n",
      "243.02256870269775\n",
      "Epoch 345/399\n",
      "242.79779314994812\n",
      "Epoch 346/399\n",
      "242.99422073364258\n",
      "Epoch 347/399\n",
      "243.01885414123535\n",
      "Epoch 348/399\n",
      "242.95348858833313\n",
      "Epoch 349/399\n",
      "242.9980640411377\n",
      "Epoch 350/399\n",
      "243.51723718643188\n",
      "Epoch 351/399\n",
      "242.973228931427\n",
      "Epoch 352/399\n",
      "243.14850640296936\n",
      "Epoch 353/399\n",
      "243.3739459514618\n",
      "Epoch 354/399\n",
      "243.02977228164673\n",
      "Epoch 355/399\n",
      "243.24723434448242\n",
      "Epoch 356/399\n",
      "242.824768781662\n",
      "Epoch 357/399\n",
      "243.33450365066528\n",
      "Epoch 358/399\n",
      "243.13444256782532\n",
      "Epoch 359/399\n",
      "242.97357630729675\n",
      "Epoch 360/399\n",
      "243.1256284713745\n",
      "Epoch 361/399\n",
      "242.86591005325317\n",
      "Epoch 362/399\n",
      "242.85376381874084\n",
      "Epoch 363/399\n",
      "243.23796701431274\n",
      "Epoch 364/399\n",
      "242.9571259021759\n",
      "Epoch 365/399\n",
      "243.10808658599854\n",
      "Epoch 366/399\n",
      "243.00277376174927\n",
      "Epoch 367/399\n",
      "243.16443824768066\n",
      "Epoch 368/399\n",
      "243.03274655342102\n",
      "Epoch 369/399\n",
      "243.1218225955963\n",
      "Epoch 370/399\n",
      "242.91850638389587\n",
      "Epoch 371/399\n",
      "242.57384181022644\n",
      "Epoch 372/399\n",
      "242.91951942443848\n",
      "Epoch 373/399\n",
      "242.46076369285583\n",
      "Epoch 374/399\n",
      "243.93839573860168\n",
      "Epoch 375/399\n",
      "253.87490320205688\n",
      "Epoch 376/399\n",
      "306.7059004306793\n",
      "Epoch 377/399\n",
      "318.67229747772217\n",
      "Epoch 378/399\n",
      "313.9781131744385\n",
      "Epoch 379/399\n",
      "306.53385519981384\n",
      "Epoch 380/399\n",
      "306.55377554893494\n",
      "Epoch 381/399\n",
      "303.033371925354\n",
      "Epoch 382/399\n",
      "312.92661476135254\n",
      "Epoch 383/399\n",
      "309.1377384662628\n",
      "Epoch 384/399\n",
      "308.9038302898407\n",
      "Epoch 385/399\n",
      "299.26729917526245\n",
      "Epoch 386/399\n",
      "243.59635210037231\n",
      "Epoch 387/399\n",
      "239.7896749973297\n",
      "Epoch 388/399\n",
      "239.4307622909546\n",
      "Epoch 389/399\n",
      "239.2725875377655\n",
      "Epoch 390/399\n",
      "239.6215226650238\n",
      "Epoch 391/399\n",
      "237.83674311637878\n",
      "Epoch 392/399\n",
      "237.43069624900818\n",
      "Epoch 393/399\n",
      "237.32843446731567\n",
      "Epoch 394/399\n",
      "237.24693512916565\n",
      "Epoch 395/399\n",
      "236.96974110603333\n",
      "Epoch 396/399\n",
      "237.39584755897522\n",
      "Epoch 397/399\n",
      "237.56073260307312\n",
      "Epoch 398/399\n",
      "237.09381484985352\n",
      "Epoch 399/399\n",
      "237.40032839775085\n",
      "Training complete in 1664m 7s\n",
      "Best val Acc: 0.934100\n"
     ]
    }
   ],
   "source": [
    "net_pugdr_cos = UPANets(args.filters, Num_class, args.blocks, img_size)\n",
    "net_pugdr_cos.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "net_pugdr_cos.to(device)\n",
    "\n",
    "if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "    model_ft_org = torch.nn.DataParallel(net_pugdr_cos)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "base_optimizer = optim.SGD\n",
    "optimizer = PUGDXR(net_pugdr_cos.parameters(),\n",
    "                base_optimizer,\n",
    "                lr=args.lr,\n",
    "                max_epochs= args.epochs,\n",
    "                momentum=args.momentum,\n",
    "                weight_decay=args.wd,\n",
    "                min_beta = 0.5, \n",
    "                max_beta = 10, \n",
    "                method = 'cos',\n",
    "                dampening=0,   # 必须设置为0才能完全固定 \n",
    "                nesterov=False # 禁用Nesterov动量 \n",
    "                )\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "# exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "net_pugdr_cos, metricsr_sin = train_model_alpha(net_pugdr_cos, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "model_path = \"./model/\"+args.datasets+\"/pugdr_cos\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".pth\"\n",
    "torch.save({\n",
    "    'model_state_dict': net_pugdr_cos.state_dict(), \n",
    "    'optimizer_state_dict': optimizer.state_dict()\n",
    "}, model_path) \n",
    "\n",
    "name = \"./results/\"+args.datasets+\"/pugdr_cos_\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".json\"\n",
    "with open(name,  'w', encoding='utf-8') as f:\n",
    "    json.dump(metricsr_sin,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3e5d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/399\n",
      "238.24491143226624\n",
      "Epoch 1/399\n",
      "238.25149607658386\n",
      "Epoch 2/399\n",
      "238.084787607193\n",
      "Epoch 3/399\n",
      "238.01379132270813\n",
      "Epoch 4/399\n",
      "237.8834583759308\n",
      "Epoch 5/399\n",
      "238.22664093971252\n",
      "Epoch 6/399\n",
      "237.9279646873474\n",
      "Epoch 7/399\n",
      "238.24479007720947\n",
      "Epoch 8/399\n",
      "237.99950051307678\n",
      "Epoch 9/399\n",
      "238.29937624931335\n",
      "Epoch 10/399\n",
      "237.58017420768738\n",
      "Epoch 11/399\n",
      "237.5952799320221\n",
      "Epoch 12/399\n",
      "237.89272236824036\n",
      "Epoch 13/399\n",
      "237.9565875530243\n",
      "Epoch 14/399\n",
      "237.95927500724792\n",
      "Epoch 15/399\n",
      "237.703706741333\n",
      "Epoch 16/399\n",
      "238.1137387752533\n",
      "Epoch 17/399\n",
      "237.81772708892822\n",
      "Epoch 18/399\n",
      "237.7958962917328\n",
      "Epoch 19/399\n",
      "237.75867462158203\n",
      "Epoch 20/399\n",
      "238.0954041481018\n",
      "Epoch 21/399\n",
      "237.8363687992096\n",
      "Epoch 22/399\n",
      "237.81177592277527\n",
      "Epoch 23/399\n",
      "237.59105944633484\n",
      "Epoch 24/399\n",
      "237.8412046432495\n",
      "Epoch 25/399\n",
      "237.60826563835144\n",
      "Epoch 26/399\n",
      "237.62866497039795\n",
      "Epoch 27/399\n",
      "237.6779625415802\n",
      "Epoch 28/399\n",
      "237.74140071868896\n",
      "Epoch 29/399\n",
      "237.73286652565002\n",
      "Epoch 30/399\n",
      "237.56040239334106\n",
      "Epoch 31/399\n",
      "237.9919285774231\n",
      "Epoch 32/399\n",
      "237.6316683292389\n",
      "Epoch 33/399\n",
      "237.5265142917633\n",
      "Epoch 34/399\n",
      "237.60925316810608\n",
      "Epoch 35/399\n",
      "237.31702780723572\n",
      "Epoch 36/399\n",
      "237.6173276901245\n",
      "Epoch 37/399\n",
      "242.85810256004333\n",
      "Epoch 38/399\n",
      "240.1659824848175\n",
      "Epoch 39/399\n",
      "242.3038365840912\n",
      "Epoch 40/399\n",
      "240.68418550491333\n",
      "Epoch 41/399\n",
      "239.174809217453\n",
      "Epoch 42/399\n",
      "239.87630939483643\n",
      "Epoch 43/399\n",
      "239.63926815986633\n",
      "Epoch 44/399\n",
      "239.44289469718933\n",
      "Epoch 45/399\n",
      "239.3401176929474\n",
      "Epoch 46/399\n",
      "239.5483808517456\n",
      "Epoch 47/399\n",
      "238.67309427261353\n",
      "Epoch 48/399\n",
      "237.94282269477844\n",
      "Epoch 49/399\n",
      "242.00631475448608\n",
      "Epoch 50/399\n",
      "241.38317227363586\n",
      "Epoch 51/399\n",
      "242.48881268501282\n",
      "Epoch 52/399\n",
      "242.32799553871155\n",
      "Epoch 53/399\n",
      "245.06281042099\n",
      "Epoch 54/399\n",
      "243.54224276542664\n",
      "Epoch 55/399\n",
      "242.0569725036621\n",
      "Epoch 56/399\n",
      "242.80292463302612\n",
      "Epoch 57/399\n",
      "240.17846775054932\n",
      "Epoch 58/399\n",
      "240.7734727859497\n",
      "Epoch 59/399\n",
      "245.56770181655884\n",
      "Epoch 60/399\n",
      "245.61858105659485\n",
      "Epoch 61/399\n",
      "245.77912855148315\n",
      "Epoch 62/399\n",
      "245.18977975845337\n",
      "Epoch 63/399\n",
      "244.76970863342285\n",
      "Epoch 64/399\n",
      "241.16390800476074\n",
      "Epoch 65/399\n",
      "240.91701579093933\n",
      "Epoch 66/399\n",
      "240.5766246318817\n",
      "Epoch 67/399\n",
      "240.9733853340149\n",
      "Epoch 68/399\n",
      "240.5598165988922\n",
      "Epoch 69/399\n",
      "240.94860863685608\n",
      "Epoch 70/399\n",
      "240.90986609458923\n",
      "Epoch 71/399\n",
      "240.41285276412964\n",
      "Epoch 72/399\n",
      "240.44279074668884\n",
      "Epoch 73/399\n",
      "240.622816324234\n",
      "Epoch 74/399\n",
      "240.20537447929382\n",
      "Epoch 75/399\n",
      "240.4477870464325\n",
      "Epoch 76/399\n",
      "240.68577766418457\n",
      "Epoch 77/399\n",
      "240.62044501304626\n",
      "Epoch 78/399\n",
      "240.47297883033752\n",
      "Epoch 79/399\n",
      "240.43525385856628\n",
      "Epoch 80/399\n",
      "240.40630888938904\n",
      "Epoch 81/399\n",
      "240.15097665786743\n",
      "Epoch 82/399\n",
      "240.79837799072266\n",
      "Epoch 83/399\n",
      "240.53735041618347\n",
      "Epoch 84/399\n",
      "240.88706374168396\n",
      "Epoch 85/399\n",
      "240.4450101852417\n",
      "Epoch 86/399\n",
      "240.5724024772644\n",
      "Epoch 87/399\n",
      "240.3764455318451\n",
      "Epoch 88/399\n",
      "240.3042266368866\n",
      "Epoch 89/399\n",
      "240.7167947292328\n",
      "Epoch 90/399\n",
      "240.84231114387512\n",
      "Epoch 91/399\n",
      "240.41145849227905\n",
      "Epoch 92/399\n",
      "240.1429567337036\n",
      "Epoch 93/399\n",
      "240.31564283370972\n",
      "Epoch 94/399\n",
      "240.17366647720337\n",
      "Epoch 95/399\n",
      "240.50362730026245\n",
      "Epoch 96/399\n",
      "240.48043394088745\n",
      "Epoch 97/399\n",
      "240.58725309371948\n",
      "Epoch 98/399\n",
      "240.3874306678772\n",
      "Epoch 99/399\n",
      "240.70765376091003\n",
      "Epoch 100/399\n",
      "240.74922800064087\n",
      "Epoch 101/399\n",
      "240.874125957489\n",
      "Epoch 102/399\n",
      "240.68559861183167\n",
      "Epoch 103/399\n",
      "240.56765913963318\n",
      "Epoch 104/399\n",
      "240.4437379837036\n",
      "Epoch 105/399\n",
      "240.55752778053284\n",
      "Epoch 106/399\n",
      "240.4004373550415\n",
      "Epoch 107/399\n",
      "239.99639630317688\n",
      "Epoch 108/399\n",
      "240.59265208244324\n",
      "Epoch 109/399\n",
      "241.04303884506226\n",
      "Epoch 110/399\n",
      "240.55161261558533\n",
      "Epoch 111/399\n",
      "240.4412806034088\n",
      "Epoch 112/399\n",
      "240.70665073394775\n",
      "Epoch 113/399\n",
      "240.49289894104004\n",
      "Epoch 114/399\n",
      "240.72290563583374\n",
      "Epoch 115/399\n",
      "240.5575032234192\n",
      "Epoch 116/399\n",
      "240.65449023246765\n",
      "Epoch 117/399\n",
      "240.45341515541077\n",
      "Epoch 118/399\n",
      "240.14957427978516\n",
      "Epoch 119/399\n",
      "240.48791599273682\n",
      "Epoch 120/399\n",
      "240.61939764022827\n",
      "Epoch 121/399\n",
      "240.51197957992554\n",
      "Epoch 122/399\n",
      "240.33673787117004\n",
      "Epoch 123/399\n",
      "240.48746180534363\n",
      "Epoch 124/399\n",
      "240.5600175857544\n",
      "Epoch 125/399\n",
      "240.54159450531006\n",
      "Epoch 126/399\n",
      "240.75688862800598\n",
      "Epoch 127/399\n",
      "240.47965335845947\n",
      "Epoch 128/399\n",
      "240.71186447143555\n",
      "Epoch 129/399\n",
      "240.7552511692047\n",
      "Epoch 130/399\n",
      "240.3885133266449\n",
      "Epoch 131/399\n",
      "240.64170289039612\n",
      "Epoch 132/399\n",
      "240.73841500282288\n",
      "Epoch 133/399\n",
      "240.50943613052368\n",
      "Epoch 134/399\n",
      "240.59490847587585\n",
      "Epoch 135/399\n",
      "240.5012526512146\n",
      "Epoch 136/399\n",
      "240.48265933990479\n",
      "Epoch 137/399\n",
      "240.65170431137085\n",
      "Epoch 138/399\n",
      "240.73649716377258\n",
      "Epoch 139/399\n",
      "240.79977941513062\n",
      "Epoch 140/399\n",
      "240.589581489563\n",
      "Epoch 141/399\n",
      "240.50912237167358\n",
      "Epoch 142/399\n",
      "240.68126797676086\n",
      "Epoch 143/399\n",
      "240.7334098815918\n",
      "Epoch 144/399\n",
      "240.6343367099762\n",
      "Epoch 145/399\n",
      "240.77391600608826\n",
      "Epoch 146/399\n",
      "240.57101774215698\n",
      "Epoch 147/399\n",
      "240.411447763443\n",
      "Epoch 148/399\n",
      "240.56750059127808\n",
      "Epoch 149/399\n",
      "240.81443667411804\n",
      "Epoch 150/399\n",
      "240.2893762588501\n",
      "Epoch 151/399\n",
      "240.2492356300354\n",
      "Epoch 152/399\n",
      "240.12089800834656\n",
      "Epoch 153/399\n",
      "240.759685754776\n",
      "Epoch 154/399\n",
      "240.58330917358398\n",
      "Epoch 155/399\n",
      "240.8821415901184\n",
      "Epoch 156/399\n",
      "240.6175262928009\n",
      "Epoch 157/399\n",
      "240.63670754432678\n",
      "Epoch 158/399\n",
      "240.6246201992035\n",
      "Epoch 159/399\n",
      "240.58856511116028\n",
      "Epoch 160/399\n",
      "240.51650214195251\n",
      "Epoch 161/399\n",
      "240.54746866226196\n",
      "Epoch 162/399\n",
      "240.81571698188782\n",
      "Epoch 163/399\n",
      "240.66321635246277\n",
      "Epoch 164/399\n",
      "240.80004930496216\n",
      "Epoch 165/399\n",
      "240.50494718551636\n",
      "Epoch 166/399\n",
      "240.7868194580078\n",
      "Epoch 167/399\n",
      "240.56053519248962\n",
      "Epoch 168/399\n",
      "240.89235639572144\n",
      "Epoch 169/399\n",
      "240.90285301208496\n",
      "Epoch 170/399\n",
      "240.53549885749817\n",
      "Epoch 171/399\n",
      "240.86857986450195\n",
      "Epoch 172/399\n",
      "240.68709874153137\n",
      "Epoch 173/399\n",
      "240.9657859802246\n",
      "Epoch 174/399\n",
      "240.8382487297058\n",
      "Epoch 175/399\n",
      "240.97045230865479\n",
      "Epoch 176/399\n",
      "240.62371230125427\n",
      "Epoch 177/399\n",
      "240.98740458488464\n",
      "Epoch 178/399\n",
      "240.8361132144928\n",
      "Epoch 179/399\n",
      "240.8438596725464\n",
      "Epoch 180/399\n",
      "240.97177243232727\n",
      "Epoch 181/399\n",
      "240.9463815689087\n",
      "Epoch 182/399\n",
      "241.12529611587524\n",
      "Epoch 183/399\n",
      "240.49781370162964\n",
      "Epoch 184/399\n",
      "241.07842755317688\n",
      "Epoch 185/399\n",
      "240.7451593875885\n",
      "Epoch 186/399\n",
      "240.75332188606262\n",
      "Epoch 187/399\n",
      "240.69205498695374\n",
      "Epoch 188/399\n",
      "240.80787634849548\n",
      "Epoch 189/399\n",
      "241.2557954788208\n",
      "Epoch 190/399\n",
      "246.36666584014893\n",
      "Epoch 191/399\n",
      "247.29419779777527\n",
      "Epoch 192/399\n",
      "240.29676032066345\n",
      "Epoch 193/399\n",
      "240.82871341705322\n",
      "Epoch 194/399\n",
      "241.33256578445435\n",
      "Epoch 195/399\n",
      "239.46477460861206\n",
      "Epoch 196/399\n",
      "239.4394233226776\n",
      "Epoch 197/399\n",
      "239.69429564476013\n",
      "Epoch 198/399\n",
      "239.6140534877777\n",
      "Epoch 199/399\n",
      "239.0186779499054\n",
      "Epoch 200/399\n",
      "237.90299654006958\n",
      "Epoch 201/399\n",
      "238.21850538253784\n",
      "Epoch 202/399\n",
      "238.16836214065552\n",
      "Epoch 203/399\n",
      "237.55480813980103\n",
      "Epoch 204/399\n",
      "238.09600567817688\n",
      "Epoch 205/399\n",
      "237.52013325691223\n",
      "Epoch 206/399\n",
      "237.82152724266052\n",
      "Epoch 207/399\n",
      "237.7417130470276\n",
      "Epoch 208/399\n",
      "237.97507524490356\n",
      "Epoch 209/399\n",
      "240.2655735015869\n",
      "Epoch 210/399\n",
      "241.1624972820282\n",
      "Epoch 211/399\n",
      "240.41460919380188\n",
      "Epoch 212/399\n",
      "239.4069366455078\n",
      "Epoch 213/399\n",
      "239.6727273464203\n",
      "Epoch 214/399\n",
      "241.38256359100342\n",
      "Epoch 215/399\n",
      "239.4189064502716\n",
      "Epoch 216/399\n",
      "239.12744569778442\n",
      "Epoch 217/399\n",
      "240.4947488307953\n",
      "Epoch 218/399\n",
      "238.79493951797485\n",
      "Epoch 219/399\n",
      "238.39168453216553\n",
      "Epoch 220/399\n",
      "238.27683401107788\n",
      "Epoch 221/399\n",
      "238.79416060447693\n",
      "Epoch 222/399\n",
      "238.71802020072937\n",
      "Epoch 223/399\n",
      "236.82365202903748\n",
      "Epoch 224/399\n",
      "236.86586260795593\n",
      "Epoch 225/399\n",
      "237.3800139427185\n",
      "Epoch 226/399\n",
      "237.27193212509155\n",
      "Epoch 227/399\n",
      "237.36922693252563\n",
      "Epoch 228/399\n",
      "238.02697443962097\n",
      "Epoch 229/399\n",
      "237.50486516952515\n",
      "Epoch 230/399\n",
      "236.80630016326904\n",
      "Epoch 231/399\n",
      "237.3340620994568\n",
      "Epoch 232/399\n",
      "237.25982427597046\n",
      "Epoch 233/399\n",
      "237.29102277755737\n",
      "Epoch 234/399\n",
      "236.99089169502258\n",
      "Epoch 235/399\n",
      "237.46614027023315\n",
      "Epoch 236/399\n",
      "238.52113461494446\n",
      "Epoch 237/399\n",
      "240.93360948562622\n",
      "Epoch 238/399\n",
      "240.08164978027344\n",
      "Epoch 239/399\n",
      "240.17259168624878\n",
      "Epoch 240/399\n",
      "240.38424587249756\n",
      "Epoch 241/399\n",
      "241.2825255393982\n",
      "Epoch 242/399\n",
      "242.01853251457214\n",
      "Epoch 243/399\n",
      "241.3517870903015\n",
      "Epoch 244/399\n",
      "241.29066967964172\n",
      "Epoch 245/399\n",
      "241.32417392730713\n",
      "Epoch 246/399\n",
      "240.13547086715698\n",
      "Epoch 247/399\n",
      "239.92804718017578\n",
      "Epoch 248/399\n",
      "240.45025610923767\n",
      "Epoch 249/399\n",
      "242.42254185676575\n",
      "Epoch 250/399\n",
      "241.69304728507996\n",
      "Epoch 251/399\n",
      "240.09913730621338\n",
      "Epoch 252/399\n",
      "240.31563425064087\n",
      "Epoch 253/399\n",
      "239.979553937912\n",
      "Epoch 254/399\n",
      "241.582781791687\n",
      "Epoch 255/399\n",
      "241.24836921691895\n",
      "Epoch 256/399\n",
      "240.45086860656738\n",
      "Epoch 257/399\n",
      "246.45981907844543\n",
      "Epoch 258/399\n",
      "248.22677159309387\n",
      "Epoch 259/399\n",
      "249.61731481552124\n",
      "Epoch 260/399\n",
      "249.58407545089722\n",
      "Epoch 261/399\n",
      "249.11578726768494\n",
      "Epoch 262/399\n",
      "245.6433093547821\n",
      "Epoch 263/399\n",
      "243.62822723388672\n",
      "Epoch 264/399\n",
      "243.0486466884613\n",
      "Epoch 265/399\n",
      "243.11488890647888\n",
      "Epoch 266/399\n",
      "243.60093879699707\n",
      "Epoch 267/399\n",
      "243.09856271743774\n",
      "Epoch 268/399\n",
      "243.21745204925537\n",
      "Epoch 269/399\n",
      "243.33492493629456\n",
      "Epoch 270/399\n",
      "243.37664556503296\n",
      "Epoch 271/399\n",
      "243.095454454422\n",
      "Epoch 272/399\n",
      "242.8922896385193\n",
      "Epoch 273/399\n",
      "242.80819058418274\n",
      "Epoch 274/399\n",
      "242.88195538520813\n",
      "Epoch 275/399\n",
      "243.33725833892822\n",
      "Epoch 276/399\n",
      "242.92485857009888\n",
      "Epoch 277/399\n",
      "243.180184841156\n",
      "Epoch 278/399\n",
      "243.0351448059082\n",
      "Epoch 279/399\n",
      "243.60870814323425\n",
      "Epoch 280/399\n",
      "243.04406189918518\n",
      "Epoch 281/399\n",
      "243.13117814064026\n",
      "Epoch 282/399\n",
      "243.11645412445068\n",
      "Epoch 283/399\n",
      "243.32450699806213\n",
      "Epoch 284/399\n",
      "242.80661487579346\n",
      "Epoch 285/399\n",
      "243.53943943977356\n",
      "Epoch 286/399\n",
      "243.02736020088196\n",
      "Epoch 287/399\n",
      "242.8911406993866\n",
      "Epoch 288/399\n",
      "243.1078917980194\n",
      "Epoch 289/399\n",
      "242.90326738357544\n",
      "Epoch 290/399\n",
      "243.19562077522278\n",
      "Epoch 291/399\n",
      "242.87035393714905\n",
      "Epoch 292/399\n",
      "243.22457361221313\n",
      "Epoch 293/399\n",
      "243.2369408607483\n",
      "Epoch 294/399\n",
      "242.8353500366211\n",
      "Epoch 295/399\n",
      "243.06348085403442\n",
      "Epoch 296/399\n",
      "243.5630383491516\n",
      "Epoch 297/399\n",
      "243.36705040931702\n",
      "Epoch 298/399\n",
      "242.81381821632385\n",
      "Epoch 299/399\n",
      "242.76837825775146\n",
      "Epoch 300/399\n",
      "243.02266192436218\n",
      "Epoch 301/399\n",
      "243.44436407089233\n",
      "Epoch 302/399\n",
      "242.97173976898193\n",
      "Epoch 303/399\n",
      "242.94162249565125\n",
      "Epoch 304/399\n",
      "242.9520263671875\n",
      "Epoch 305/399\n",
      "242.73105764389038\n",
      "Epoch 306/399\n",
      "242.7373652458191\n",
      "Epoch 307/399\n",
      "242.8421790599823\n",
      "Epoch 308/399\n",
      "242.98939990997314\n",
      "Epoch 309/399\n",
      "243.05418372154236\n",
      "Epoch 310/399\n",
      "242.95481371879578\n",
      "Epoch 311/399\n",
      "242.66712188720703\n",
      "Epoch 312/399\n",
      "243.06557822227478\n",
      "Epoch 313/399\n",
      "243.02261900901794\n",
      "Epoch 314/399\n",
      "242.55714058876038\n",
      "Epoch 315/399\n",
      "243.01047468185425\n",
      "Epoch 316/399\n",
      "242.75836038589478\n",
      "Epoch 317/399\n",
      "242.68473148345947\n",
      "Epoch 318/399\n",
      "242.41236329078674\n",
      "Epoch 319/399\n",
      "242.4610698223114\n",
      "Epoch 320/399\n",
      "242.72749519348145\n",
      "Epoch 321/399\n",
      "242.44480562210083\n",
      "Epoch 322/399\n",
      "242.90272569656372\n",
      "Epoch 323/399\n",
      "242.90660095214844\n",
      "Epoch 324/399\n",
      "242.60537576675415\n",
      "Epoch 325/399\n",
      "242.8159704208374\n",
      "Epoch 326/399\n",
      "242.31952166557312\n",
      "Epoch 327/399\n",
      "243.96716284751892\n",
      "Epoch 328/399\n",
      "242.53706526756287\n",
      "Epoch 329/399\n",
      "242.37808775901794\n",
      "Epoch 330/399\n",
      "242.13709211349487\n",
      "Epoch 331/399\n",
      "241.99499034881592\n",
      "Epoch 332/399\n",
      "241.96920323371887\n",
      "Epoch 333/399\n",
      "241.59037113189697\n",
      "Epoch 334/399\n",
      "242.57715225219727\n",
      "Epoch 335/399\n",
      "255.01076531410217\n",
      "Epoch 336/399\n",
      "304.264365196228\n",
      "Epoch 337/399\n",
      "306.2315790653229\n",
      "Epoch 338/399\n",
      "303.76858258247375\n",
      "Epoch 339/399\n",
      "315.06360483169556\n",
      "Epoch 340/399\n",
      "309.9606399536133\n",
      "Epoch 341/399\n",
      "311.7773313522339\n",
      "Epoch 342/399\n",
      "309.0352909564972\n",
      "Epoch 343/399\n",
      "308.3099699020386\n",
      "Epoch 344/399\n",
      "277.3512887954712\n",
      "Epoch 345/399\n",
      "250.91870713233948\n",
      "Epoch 346/399\n",
      "249.86859107017517\n",
      "Epoch 347/399\n",
      "250.83145380020142\n",
      "Epoch 348/399\n",
      "250.56474208831787\n",
      "Epoch 349/399\n",
      "251.38400554656982\n",
      "Epoch 350/399\n",
      "251.3956537246704\n",
      "Epoch 351/399\n",
      "251.12156057357788\n",
      "Epoch 352/399\n",
      "251.39501237869263\n",
      "Epoch 353/399\n",
      "251.27460765838623\n",
      "Epoch 354/399\n",
      "251.24856543540955\n",
      "Epoch 355/399\n",
      "251.78259229660034\n",
      "Epoch 356/399\n",
      "251.13388442993164\n",
      "Epoch 357/399\n",
      "250.96859407424927\n",
      "Epoch 358/399\n",
      "245.38285040855408\n",
      "Epoch 359/399\n",
      "245.03573775291443\n",
      "Epoch 360/399\n",
      "245.02791810035706\n",
      "Epoch 361/399\n",
      "244.96108412742615\n",
      "Epoch 362/399\n",
      "244.48838877677917\n",
      "Epoch 363/399\n",
      "245.15268731117249\n",
      "Epoch 364/399\n",
      "244.56349229812622\n",
      "Epoch 365/399\n",
      "244.88028287887573\n",
      "Epoch 366/399\n",
      "244.71780681610107\n",
      "Epoch 367/399\n",
      "245.00256061553955\n",
      "Epoch 368/399\n",
      "245.16876602172852\n",
      "Epoch 369/399\n",
      "244.95468091964722\n",
      "Epoch 370/399\n",
      "245.16619491577148\n",
      "Epoch 371/399\n",
      "248.40828132629395\n",
      "Epoch 372/399\n",
      "250.36262726783752\n",
      "Epoch 373/399\n",
      "251.1989448070526\n",
      "Epoch 374/399\n",
      "251.5300633907318\n",
      "Epoch 375/399\n",
      "251.48387026786804\n",
      "Epoch 376/399\n",
      "250.97468614578247\n",
      "Epoch 377/399\n",
      "250.57082080841064\n",
      "Epoch 378/399\n",
      "250.88683700561523\n",
      "Epoch 379/399\n",
      "250.97103428840637\n",
      "Epoch 380/399\n",
      "251.20495772361755\n",
      "Epoch 381/399\n",
      "251.13691973686218\n",
      "Epoch 382/399\n",
      "252.48249435424805\n",
      "Epoch 383/399\n",
      "251.25011706352234\n",
      "Epoch 384/399\n",
      "251.14716744422913\n",
      "Epoch 385/399\n",
      "250.6449110507965\n",
      "Epoch 386/399\n",
      "250.81924319267273\n",
      "Epoch 387/399\n",
      "251.61042618751526\n",
      "Epoch 388/399\n",
      "252.51989650726318\n",
      "Epoch 389/399\n",
      "253.32101154327393\n",
      "Epoch 390/399\n",
      "252.1455054283142\n",
      "Epoch 391/399\n",
      "251.49753785133362\n",
      "Epoch 392/399\n",
      "251.89119482040405\n",
      "Epoch 393/399\n",
      "251.07854533195496\n",
      "Epoch 394/399\n",
      "251.33185505867004\n",
      "Epoch 395/399\n",
      "251.12644147872925\n",
      "Epoch 396/399\n",
      "251.0692777633667\n",
      "Epoch 397/399\n",
      "251.21078896522522\n",
      "Epoch 398/399\n",
      "255.23755383491516\n",
      "Epoch 399/399\n",
      "250.569890499115\n",
      "Training complete in 1623m 36s\n",
      "Best val Acc: 0.937200\n"
     ]
    }
   ],
   "source": [
    "net_pugds_cos = UPANets(args.filters, Num_class, args.blocks, img_size)  \n",
    "net_pugds_cos.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "net_pugds_cos.to(device)\n",
    "\n",
    "if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "    net_pugds_cos = torch.nn.DataParallel(net_pugds_cos)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "base_optimizer = optim.SGD\n",
    "optimizer = PUGDXS(net_pugds_cos.parameters(),\n",
    "                base_optimizer,\n",
    "                lr=args.lr,\n",
    "                max_epochs= args.epochs,\n",
    "                momentum=args.momentum,\n",
    "                weight_decay=args.wd,\n",
    "                min_beta = 0.0, \n",
    "                max_beta = 2,\n",
    "                method = 'cos',\n",
    "                dampening=0,   # 必须设置为0才能完全固定 \n",
    "                nesterov=False # 禁用Nesterov动量 \n",
    "                 )\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "# exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "net_pugds_cos, metricss_cos = train_model_alpha(net_pugds_cos, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "model_path = \"./model/\"+args.datasets+\"/pugds_cos\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".pth\"\n",
    "torch.save({\n",
    "    'model_state_dict': net_pugds_cos.state_dict(), \n",
    "    'optimizer_state_dict': optimizer.state_dict()\n",
    "}, model_path) \n",
    "\n",
    "name = \"./results/\"+args.datasets+\"/pugds_cos_\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".json\"\n",
    "with open(name,  'w', encoding='utf-8') as f:\n",
    "    json.dump(metricss_cos,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e79fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/399\n",
      "251.90189909934998\n",
      "Epoch 1/399\n",
      "253.27992296218872\n",
      "Epoch 2/399\n",
      "251.57479238510132\n",
      "Epoch 3/399\n",
      "252.4341766834259\n",
      "Epoch 4/399\n",
      "251.78467512130737\n",
      "Epoch 5/399\n",
      "252.3520267009735\n",
      "Epoch 6/399\n",
      "252.04265713691711\n",
      "Epoch 7/399\n",
      "252.14621591567993\n",
      "Epoch 8/399\n",
      "249.8141360282898\n",
      "Epoch 9/399\n",
      "247.50203728675842\n",
      "Epoch 10/399\n",
      "247.2816755771637\n",
      "Epoch 11/399\n",
      "247.45690631866455\n",
      "Epoch 12/399\n",
      "247.37869334220886\n",
      "Epoch 13/399\n",
      "243.77710628509521\n",
      "Epoch 14/399\n",
      "241.73074197769165\n",
      "Epoch 15/399\n",
      "241.62355661392212\n",
      "Epoch 16/399\n",
      "241.61669993400574\n",
      "Epoch 17/399\n",
      "241.768079996109\n",
      "Epoch 18/399\n",
      "241.4867868423462\n",
      "Epoch 19/399\n",
      "241.7054159641266\n",
      "Epoch 20/399\n",
      "241.35499095916748\n",
      "Epoch 21/399\n",
      "241.7161512374878\n",
      "Epoch 22/399\n",
      "241.84691762924194\n",
      "Epoch 23/399\n",
      "241.63340592384338\n",
      "Epoch 24/399\n",
      "241.83843111991882\n",
      "Epoch 25/399\n",
      "241.51668000221252\n",
      "Epoch 26/399\n",
      "241.35537314414978\n",
      "Epoch 27/399\n",
      "241.43341660499573\n",
      "Epoch 28/399\n",
      "241.72174096107483\n",
      "Epoch 29/399\n",
      "241.43412017822266\n",
      "Epoch 30/399\n",
      "241.78598475456238\n",
      "Epoch 31/399\n",
      "241.57923364639282\n",
      "Epoch 32/399\n",
      "241.43768310546875\n",
      "Epoch 33/399\n",
      "241.46326804161072\n",
      "Epoch 34/399\n",
      "241.48065567016602\n",
      "Epoch 35/399\n",
      "241.51833367347717\n",
      "Epoch 36/399\n",
      "241.43829488754272\n",
      "Epoch 37/399\n",
      "241.75749158859253\n",
      "Epoch 38/399\n",
      "241.38849520683289\n",
      "Epoch 39/399\n",
      "241.3541874885559\n",
      "Epoch 40/399\n",
      "241.44623064994812\n",
      "Epoch 41/399\n",
      "241.45639729499817\n",
      "Epoch 42/399\n",
      "241.25410318374634\n",
      "Epoch 43/399\n",
      "241.4835283756256\n",
      "Epoch 44/399\n",
      "241.52832198143005\n",
      "Epoch 45/399\n",
      "241.34147763252258\n",
      "Epoch 46/399\n",
      "241.56473898887634\n",
      "Epoch 47/399\n",
      "241.24239134788513\n",
      "Epoch 48/399\n",
      "241.5183720588684\n",
      "Epoch 49/399\n",
      "241.74506616592407\n",
      "Epoch 50/399\n",
      "241.6579728126526\n",
      "Epoch 51/399\n",
      "241.67325115203857\n",
      "Epoch 52/399\n",
      "241.78184986114502\n",
      "Epoch 53/399\n",
      "241.32449650764465\n",
      "Epoch 54/399\n",
      "241.29385375976562\n",
      "Epoch 55/399\n",
      "241.41196298599243\n",
      "Epoch 56/399\n",
      "241.2021632194519\n",
      "Epoch 57/399\n",
      "241.53396892547607\n",
      "Epoch 58/399\n",
      "241.63536286354065\n",
      "Epoch 59/399\n",
      "241.47818851470947\n",
      "Epoch 60/399\n",
      "241.6057801246643\n",
      "Epoch 61/399\n",
      "241.55131697654724\n",
      "Epoch 62/399\n",
      "241.42667865753174\n",
      "Epoch 63/399\n",
      "241.68630480766296\n",
      "Epoch 64/399\n",
      "241.9268205165863\n",
      "Epoch 65/399\n",
      "241.47215700149536\n",
      "Epoch 66/399\n",
      "241.43130445480347\n",
      "Epoch 67/399\n",
      "241.67243337631226\n",
      "Epoch 68/399\n",
      "241.432288646698\n",
      "Epoch 69/399\n",
      "241.61338138580322\n",
      "Epoch 70/399\n",
      "241.68601417541504\n",
      "Epoch 71/399\n",
      "241.8327465057373\n",
      "Epoch 72/399\n",
      "241.40668368339539\n",
      "Epoch 73/399\n",
      "241.58772134780884\n",
      "Epoch 74/399\n",
      "241.91358637809753\n",
      "Epoch 75/399\n",
      "241.54634833335876\n",
      "Epoch 76/399\n",
      "241.29747986793518\n",
      "Epoch 77/399\n",
      "241.41134905815125\n",
      "Epoch 78/399\n",
      "241.69167757034302\n",
      "Epoch 79/399\n",
      "241.12953329086304\n",
      "Epoch 80/399\n",
      "241.30149936676025\n",
      "Epoch 81/399\n",
      "241.5063009262085\n",
      "Epoch 82/399\n",
      "241.62717247009277\n",
      "Epoch 83/399\n",
      "241.53833317756653\n",
      "Epoch 84/399\n",
      "241.28943300247192\n",
      "Epoch 85/399\n",
      "241.35300588607788\n",
      "Epoch 86/399\n",
      "241.75556826591492\n",
      "Epoch 87/399\n",
      "241.43615460395813\n",
      "Epoch 88/399\n",
      "241.50087594985962\n",
      "Epoch 89/399\n",
      "241.5161316394806\n",
      "Epoch 90/399\n",
      "241.76387405395508\n",
      "Epoch 91/399\n",
      "241.4644651412964\n",
      "Epoch 92/399\n",
      "241.66483998298645\n",
      "Epoch 93/399\n",
      "241.63263273239136\n",
      "Epoch 94/399\n",
      "241.3888874053955\n",
      "Epoch 95/399\n",
      "241.4833061695099\n",
      "Epoch 96/399\n",
      "241.55099296569824\n",
      "Epoch 97/399\n",
      "241.48167610168457\n",
      "Epoch 98/399\n",
      "241.41507577896118\n",
      "Epoch 99/399\n",
      "241.42684292793274\n",
      "Epoch 100/399\n",
      "241.4881784915924\n",
      "Epoch 101/399\n",
      "241.6404151916504\n",
      "Epoch 102/399\n",
      "241.37291860580444\n",
      "Epoch 103/399\n",
      "241.52038621902466\n",
      "Epoch 104/399\n",
      "241.58027458190918\n",
      "Epoch 105/399\n",
      "241.54742693901062\n",
      "Epoch 106/399\n",
      "241.31674313545227\n",
      "Epoch 107/399\n",
      "241.62658429145813\n",
      "Epoch 108/399\n",
      "241.38923382759094\n",
      "Epoch 109/399\n",
      "241.68126702308655\n",
      "Epoch 110/399\n",
      "241.6466829776764\n",
      "Epoch 111/399\n",
      "241.67777752876282\n",
      "Epoch 112/399\n",
      "241.47621536254883\n",
      "Epoch 113/399\n",
      "241.57942652702332\n",
      "Epoch 114/399\n",
      "241.5527663230896\n",
      "Epoch 115/399\n",
      "241.78812766075134\n",
      "Epoch 116/399\n",
      "241.42636704444885\n",
      "Epoch 117/399\n",
      "241.76768708229065\n",
      "Epoch 118/399\n",
      "241.582213640213\n",
      "Epoch 119/399\n",
      "241.6398618221283\n",
      "Epoch 120/399\n",
      "241.70749926567078\n",
      "Epoch 121/399\n",
      "241.84023308753967\n",
      "Epoch 122/399\n",
      "241.76720476150513\n",
      "Epoch 123/399\n",
      "241.5412061214447\n",
      "Epoch 124/399\n",
      "241.62781977653503\n",
      "Epoch 125/399\n",
      "241.6410949230194\n",
      "Epoch 126/399\n",
      "241.6017518043518\n",
      "Epoch 127/399\n",
      "241.66526079177856\n",
      "Epoch 128/399\n",
      "241.66988611221313\n",
      "Epoch 129/399\n",
      "241.81084847450256\n",
      "Epoch 130/399\n",
      "242.18755435943604\n",
      "Epoch 131/399\n",
      "241.3888418674469\n",
      "Epoch 132/399\n",
      "241.5468635559082\n",
      "Epoch 133/399\n",
      "241.20336866378784\n",
      "Epoch 134/399\n",
      "241.59857535362244\n",
      "Epoch 135/399\n",
      "241.5202555656433\n",
      "Epoch 136/399\n",
      "241.4585599899292\n",
      "Epoch 137/399\n",
      "241.6282455921173\n",
      "Epoch 138/399\n",
      "241.6326584815979\n",
      "Epoch 139/399\n",
      "241.60699462890625\n",
      "Epoch 140/399\n",
      "241.69519329071045\n",
      "Epoch 141/399\n",
      "241.7367000579834\n",
      "Epoch 142/399\n",
      "241.87896513938904\n",
      "Epoch 143/399\n",
      "241.89465308189392\n",
      "Epoch 144/399\n",
      "241.4985818862915\n",
      "Epoch 145/399\n",
      "241.44525146484375\n",
      "Epoch 146/399\n",
      "241.40566778182983\n",
      "Epoch 147/399\n",
      "241.50750303268433\n",
      "Epoch 148/399\n",
      "241.64819359779358\n",
      "Epoch 149/399\n",
      "241.7468981742859\n",
      "Epoch 150/399\n",
      "241.9454424381256\n",
      "Epoch 151/399\n",
      "241.5686230659485\n",
      "Epoch 152/399\n",
      "241.04301404953003\n",
      "Epoch 153/399\n",
      "241.10707354545593\n",
      "Epoch 154/399\n",
      "241.7880425453186\n",
      "Epoch 155/399\n",
      "241.75540733337402\n",
      "Epoch 156/399\n",
      "241.5291302204132\n",
      "Epoch 157/399\n",
      "241.81022262573242\n",
      "Epoch 158/399\n",
      "241.5362994670868\n",
      "Epoch 159/399\n",
      "241.67221689224243\n",
      "Epoch 160/399\n",
      "241.78342247009277\n",
      "Epoch 161/399\n",
      "241.75319147109985\n",
      "Epoch 162/399\n",
      "241.64225220680237\n",
      "Epoch 163/399\n",
      "241.66456961631775\n",
      "Epoch 164/399\n",
      "241.72739481925964\n",
      "Epoch 165/399\n",
      "241.90605998039246\n",
      "Epoch 166/399\n",
      "241.70495629310608\n",
      "Epoch 167/399\n",
      "241.96303176879883\n",
      "Epoch 168/399\n",
      "241.803284406662\n",
      "Epoch 169/399\n",
      "241.9469349384308\n",
      "Epoch 170/399\n",
      "241.84496307373047\n",
      "Epoch 171/399\n",
      "241.9383487701416\n",
      "Epoch 172/399\n",
      "241.84107899665833\n",
      "Epoch 173/399\n",
      "241.61076498031616\n",
      "Epoch 174/399\n",
      "242.01634168624878\n",
      "Epoch 175/399\n",
      "241.75183248519897\n",
      "Epoch 176/399\n",
      "241.958594083786\n",
      "Epoch 177/399\n",
      "241.72561836242676\n",
      "Epoch 178/399\n",
      "241.8382637500763\n",
      "Epoch 179/399\n",
      "241.77624249458313\n",
      "Epoch 180/399\n",
      "241.73584508895874\n",
      "Epoch 181/399\n",
      "241.93414092063904\n",
      "Epoch 182/399\n",
      "241.77601504325867\n",
      "Epoch 183/399\n",
      "241.98335194587708\n",
      "Epoch 184/399\n",
      "241.79744124412537\n",
      "Epoch 185/399\n",
      "242.14176630973816\n",
      "Epoch 186/399\n",
      "240.14578080177307\n",
      "Epoch 187/399\n",
      "239.90273904800415\n",
      "Epoch 188/399\n",
      "240.1516478061676\n",
      "Epoch 189/399\n",
      "240.21877264976501\n",
      "Epoch 190/399\n",
      "240.059641122818\n",
      "Epoch 191/399\n",
      "240.1078963279724\n",
      "Epoch 192/399\n",
      "240.96650218963623\n",
      "Epoch 193/399\n",
      "241.595294713974\n",
      "Epoch 194/399\n",
      "240.04274225234985\n",
      "Epoch 195/399\n",
      "240.26376605033875\n",
      "Epoch 196/399\n",
      "243.24784398078918\n",
      "Epoch 197/399\n",
      "241.35272669792175\n",
      "Epoch 198/399\n",
      "240.05989527702332\n",
      "Epoch 199/399\n",
      "240.1127233505249\n",
      "Epoch 200/399\n",
      "240.8788161277771\n",
      "Epoch 201/399\n",
      "240.82824301719666\n",
      "Epoch 202/399\n",
      "243.32380771636963\n",
      "Epoch 203/399\n",
      "245.06838512420654\n",
      "Epoch 204/399\n",
      "244.4945707321167\n",
      "Epoch 205/399\n",
      "244.9181089401245\n",
      "Epoch 206/399\n",
      "246.6654109954834\n",
      "Epoch 207/399\n",
      "245.42322397232056\n",
      "Epoch 208/399\n",
      "247.11691308021545\n",
      "Epoch 209/399\n",
      "248.9505980014801\n",
      "Epoch 210/399\n",
      "248.5007574558258\n",
      "Epoch 211/399\n",
      "247.98281836509705\n",
      "Epoch 212/399\n",
      "248.28541469573975\n",
      "Epoch 213/399\n",
      "245.58415603637695\n",
      "Epoch 214/399\n",
      "242.38628363609314\n",
      "Epoch 215/399\n",
      "242.0881266593933\n",
      "Epoch 216/399\n",
      "242.05349111557007\n",
      "Epoch 217/399\n",
      "242.2905490398407\n",
      "Epoch 218/399\n",
      "242.33783960342407\n",
      "Epoch 219/399\n",
      "242.27678394317627\n",
      "Epoch 220/399\n",
      "242.37774801254272\n",
      "Epoch 221/399\n",
      "242.21559166908264\n",
      "Epoch 222/399\n",
      "242.2650625705719\n",
      "Epoch 223/399\n",
      "242.45533061027527\n",
      "Epoch 224/399\n",
      "242.04296493530273\n",
      "Epoch 225/399\n",
      "242.21352338790894\n",
      "Epoch 226/399\n",
      "242.1616427898407\n",
      "Epoch 227/399\n",
      "242.02306866645813\n",
      "Epoch 228/399\n",
      "242.05494809150696\n",
      "Epoch 229/399\n",
      "242.32703638076782\n",
      "Epoch 230/399\n",
      "242.13212895393372\n",
      "Epoch 231/399\n",
      "242.4557135105133\n",
      "Epoch 232/399\n",
      "241.68887615203857\n",
      "Epoch 233/399\n",
      "242.08280444145203\n",
      "Epoch 234/399\n",
      "242.07815074920654\n",
      "Epoch 235/399\n",
      "242.26445198059082\n",
      "Epoch 236/399\n",
      "242.17036032676697\n",
      "Epoch 237/399\n",
      "242.189679145813\n",
      "Epoch 238/399\n",
      "242.02697372436523\n",
      "Epoch 239/399\n",
      "242.16181874275208\n",
      "Epoch 240/399\n",
      "242.36613297462463\n",
      "Epoch 241/399\n",
      "241.8947958946228\n",
      "Epoch 242/399\n",
      "242.0677478313446\n",
      "Epoch 243/399\n",
      "242.23040461540222\n",
      "Epoch 244/399\n",
      "242.0431764125824\n",
      "Epoch 245/399\n",
      "242.0309624671936\n",
      "Epoch 246/399\n",
      "241.8550524711609\n",
      "Epoch 247/399\n",
      "241.87726712226868\n",
      "Epoch 248/399\n",
      "242.19568586349487\n",
      "Epoch 249/399\n",
      "241.99117851257324\n",
      "Epoch 250/399\n",
      "241.97480511665344\n",
      "Epoch 251/399\n",
      "242.1074423789978\n",
      "Epoch 252/399\n",
      "242.0885980129242\n",
      "Epoch 253/399\n",
      "242.01562428474426\n",
      "Epoch 254/399\n",
      "241.93651914596558\n",
      "Epoch 255/399\n",
      "241.92948532104492\n",
      "Epoch 256/399\n",
      "242.13274431228638\n",
      "Epoch 257/399\n",
      "242.43379521369934\n",
      "Epoch 258/399\n",
      "242.02580976486206\n",
      "Epoch 259/399\n",
      "242.08932518959045\n",
      "Epoch 260/399\n",
      "242.1596176624298\n",
      "Epoch 261/399\n",
      "242.05148816108704\n",
      "Epoch 262/399\n",
      "242.31178379058838\n",
      "Epoch 263/399\n",
      "242.17543768882751\n",
      "Epoch 264/399\n",
      "242.20602202415466\n",
      "Epoch 265/399\n",
      "241.75623631477356\n",
      "Epoch 266/399\n",
      "241.60050773620605\n",
      "Epoch 267/399\n",
      "241.39939713478088\n",
      "Epoch 268/399\n",
      "242.16876649856567\n",
      "Epoch 269/399\n",
      "242.02509450912476\n",
      "Epoch 270/399\n",
      "245.59030628204346\n",
      "Epoch 271/399\n",
      "246.93012738227844\n",
      "Epoch 272/399\n",
      "247.53077912330627\n",
      "Epoch 273/399\n",
      "248.02044486999512\n",
      "Epoch 274/399\n",
      "277.3942937850952\n",
      "Epoch 275/399\n",
      "301.9033787250519\n",
      "Epoch 276/399\n",
      "304.9631977081299\n",
      "Epoch 277/399\n",
      "309.1954517364502\n",
      "Epoch 278/399\n",
      "313.8394753932953\n",
      "Epoch 279/399\n",
      "315.634441614151\n",
      "Epoch 280/399\n",
      "321.78587532043457\n",
      "Epoch 281/399\n",
      "295.90074253082275\n",
      "Epoch 282/399\n",
      "330.4001588821411\n",
      "Epoch 283/399\n",
      "329.8317799568176\n",
      "Epoch 284/399\n",
      "310.6003532409668\n",
      "Epoch 285/399\n",
      "321.3282585144043\n",
      "Epoch 286/399\n",
      "337.0085599422455\n",
      "Epoch 287/399\n",
      "350.5336127281189\n",
      "Epoch 288/399\n",
      "338.69550919532776\n",
      "Epoch 289/399\n",
      "330.3862223625183\n",
      "Epoch 290/399\n",
      "301.69213819503784\n",
      "Epoch 291/399\n",
      "305.09754252433777\n",
      "Epoch 292/399\n",
      "285.97612714767456\n",
      "Epoch 293/399\n",
      "261.24898886680603\n",
      "Epoch 294/399\n",
      "249.3712067604065\n",
      "Epoch 295/399\n",
      "250.01167249679565\n",
      "Epoch 296/399\n",
      "250.31295442581177\n",
      "Epoch 297/399\n",
      "249.55286622047424\n",
      "Epoch 298/399\n",
      "249.3948528766632\n",
      "Epoch 299/399\n",
      "249.05985116958618\n",
      "Epoch 300/399\n",
      "249.79414916038513\n",
      "Epoch 301/399\n",
      "250.51508498191833\n",
      "Epoch 302/399\n",
      "249.67692017555237\n",
      "Epoch 303/399\n",
      "249.94163417816162\n",
      "Epoch 304/399\n",
      "249.77253770828247\n",
      "Epoch 305/399\n",
      "249.30684971809387\n",
      "Epoch 306/399\n",
      "248.78121256828308\n",
      "Epoch 307/399\n",
      "248.6986439228058\n",
      "Epoch 308/399\n",
      "249.10334753990173\n",
      "Epoch 309/399\n",
      "250.18287539482117\n",
      "Epoch 310/399\n",
      "250.93843150138855\n",
      "Epoch 311/399\n",
      "248.54506015777588\n",
      "Epoch 312/399\n",
      "249.21911311149597\n",
      "Epoch 313/399\n",
      "248.71771621704102\n",
      "Epoch 314/399\n",
      "248.19581270217896\n",
      "Epoch 315/399\n",
      "248.10831141471863\n",
      "Epoch 316/399\n",
      "248.10964179039001\n",
      "Epoch 317/399\n",
      "247.9921691417694\n",
      "Epoch 318/399\n",
      "247.83331203460693\n",
      "Epoch 319/399\n",
      "249.05918788909912\n",
      "Epoch 320/399\n",
      "249.2972068786621\n",
      "Epoch 321/399\n",
      "249.46244978904724\n",
      "Epoch 322/399\n",
      "248.131840467453\n",
      "Epoch 323/399\n",
      "248.31337428092957\n",
      "Epoch 324/399\n",
      "248.06223917007446\n",
      "Epoch 325/399\n",
      "247.2498254776001\n",
      "Epoch 326/399\n",
      "247.67051362991333\n",
      "Epoch 327/399\n",
      "247.62036442756653\n",
      "Epoch 328/399\n",
      "248.25762844085693\n",
      "Epoch 329/399\n",
      "249.05515789985657\n",
      "Epoch 330/399\n",
      "262.52271485328674\n",
      "Epoch 331/399\n",
      "253.33945298194885\n",
      "Epoch 332/399\n",
      "253.2008285522461\n",
      "Epoch 333/399\n",
      "253.01172280311584\n",
      "Epoch 334/399\n",
      "253.43732571601868\n",
      "Epoch 335/399\n",
      "254.08696269989014\n",
      "Epoch 336/399\n",
      "254.67533206939697\n",
      "Epoch 337/399\n",
      "255.40286326408386\n",
      "Epoch 338/399\n",
      "255.15157747268677\n",
      "Epoch 339/399\n",
      "255.49554991722107\n",
      "Epoch 340/399\n",
      "250.50487756729126\n",
      "Epoch 341/399\n",
      "246.59148383140564\n",
      "Epoch 342/399\n",
      "247.34614253044128\n",
      "Epoch 343/399\n",
      "246.5587899684906\n",
      "Epoch 344/399\n",
      "247.46369051933289\n",
      "Epoch 345/399\n",
      "248.15734601020813\n",
      "Epoch 346/399\n",
      "248.42640376091003\n",
      "Epoch 347/399\n",
      "248.13445472717285\n",
      "Epoch 348/399\n",
      "246.79723024368286\n",
      "Epoch 349/399\n",
      "247.04058408737183\n",
      "Epoch 350/399\n",
      "259.2730202674866\n",
      "Epoch 351/399\n",
      "250.82561016082764\n",
      "Epoch 352/399\n",
      "250.82157468795776\n",
      "Epoch 353/399\n",
      "251.12960410118103\n",
      "Epoch 354/399\n",
      "251.45479249954224\n",
      "Epoch 355/399\n",
      "250.17960596084595\n",
      "Epoch 356/399\n",
      "250.56406164169312\n",
      "Epoch 357/399\n",
      "250.94774293899536\n",
      "Epoch 358/399\n",
      "251.11356830596924\n",
      "Epoch 359/399\n",
      "251.0460546016693\n",
      "Epoch 360/399\n",
      "251.06616163253784\n",
      "Epoch 361/399\n",
      "250.38660311698914\n",
      "Epoch 362/399\n",
      "250.66838717460632\n",
      "Epoch 363/399\n",
      "250.75943088531494\n",
      "Epoch 364/399\n",
      "251.15154147148132\n",
      "Epoch 365/399\n",
      "251.4141387939453\n",
      "Epoch 366/399\n",
      "251.27729535102844\n",
      "Epoch 367/399\n",
      "251.45731687545776\n",
      "Epoch 368/399\n",
      "251.5735161304474\n",
      "Epoch 369/399\n",
      "249.1376349925995\n",
      "Epoch 370/399\n",
      "244.58400344848633\n",
      "Epoch 371/399\n",
      "246.08426880836487\n",
      "Epoch 372/399\n",
      "245.91743302345276\n",
      "Epoch 373/399\n",
      "245.63627219200134\n",
      "Epoch 374/399\n",
      "244.9404857158661\n",
      "Epoch 375/399\n",
      "239.66640996932983\n",
      "Epoch 376/399\n",
      "239.39674925804138\n",
      "Epoch 377/399\n",
      "239.51311779022217\n",
      "Epoch 378/399\n",
      "239.55200004577637\n",
      "Epoch 379/399\n",
      "239.55391883850098\n",
      "Epoch 380/399\n",
      "239.37086153030396\n",
      "Epoch 381/399\n",
      "239.34192299842834\n",
      "Epoch 382/399\n",
      "239.42554020881653\n",
      "Epoch 383/399\n",
      "239.23228883743286\n",
      "Epoch 384/399\n",
      "239.43268823623657\n",
      "Epoch 385/399\n",
      "239.2031660079956\n",
      "Epoch 386/399\n",
      "239.59849309921265\n",
      "Epoch 387/399\n",
      "239.29429531097412\n",
      "Epoch 388/399\n",
      "239.48634696006775\n",
      "Epoch 389/399\n",
      "239.45869064331055\n",
      "Epoch 390/399\n",
      "239.3757348060608\n",
      "Epoch 391/399\n",
      "239.20817041397095\n",
      "Epoch 392/399\n",
      "239.41208267211914\n",
      "Epoch 393/399\n",
      "239.48329257965088\n",
      "Epoch 394/399\n",
      "239.40603518486023\n",
      "Epoch 395/399\n",
      "239.41334867477417\n",
      "Epoch 396/399\n",
      "239.2141308784485\n",
      "Epoch 397/399\n",
      "239.16016149520874\n",
      "Epoch 398/399\n",
      "239.0945131778717\n",
      "Epoch 399/399\n",
      "239.53800630569458\n",
      "Training complete in 1648m 1s\n",
      "Best val Acc: 0.100000\n"
     ]
    }
   ],
   "source": [
    "net_pugds_sin = UPANets(args.filters, Num_class, args.blocks, img_size)  \n",
    "net_pugds_sin.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "net_pugds_sin.to(device)\n",
    "\n",
    "if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "    net_pugds_sin = torch.nn.DataParallel(net_pugds_sin)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "base_optimizer = optim.SGD\n",
    "optimizer = PUGDXS(net_pugds_sin.parameters(),\n",
    "                base_optimizer,\n",
    "                lr=args.lr,\n",
    "                max_epochs= args.epochs,\n",
    "                momentum=args.momentum,\n",
    "                weight_decay=args.wd,\n",
    "                min_beta = 0.0, \n",
    "                max_beta = 2,\n",
    "                method = 'sin',\n",
    "                dampening=0,   # 必须设置为0才能完全固定 \n",
    "                nesterov=False # 禁用Nesterov动量 \n",
    "                 )\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "# exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "net_pugds_sin, metricss_sin = train_model_alpha(net_pugds_sin, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "model_path = \"./model/\"+args.datasets+\"/pugds_sin\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".pth\"\n",
    "torch.save({\n",
    "    'model_state_dict': net_pugds_sin.state_dict(), \n",
    "    'optimizer_state_dict': optimizer.state_dict()\n",
    "}, model_path) \n",
    "\n",
    "name = \"./results/\"+args.datasets+\"/pugds_sin_\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".json\"\n",
    "with open(name,  'w', encoding='utf-8') as f:\n",
    "    json.dump(metricss_sin,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d2ef1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pugd = UPANets(args.filters, Num_class, args.blocks, img_size)  \n",
    "# net_pugd.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net_pugd.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     model_ft_org = torch.nn.DataParallel(net_pugd)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDX(net_pugd.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=args.lr,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                  )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "# # exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# net_pugd, metrics0 = train_model(net_pugd, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "# model_path = \"./model/\"+args.datasets+\"/pugd\" + str(args.epochs) + \".pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net_pugd.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/pugd_\" + str(args.epochs) + \".json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metrics0,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c195537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pugdr_cos = UPANets(args.filters, Num_class, args.blocks, img_size)  \n",
    "# net_pugdr_cos.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net_pugdr_cos.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     model_ft_org = torch.nn.DataParallel(net_pugdr_cos)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDXR(net_pugdr_cos.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=args.lr,\n",
    "#                 max_epochs= args.epochs,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 min_beta = 0.01, \n",
    "#                 max_beta = 2, \n",
    "#                 method = 'icos',\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                 )\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "\n",
    "# net_pugdr_cos, metricsr_cos = train_model_alpha(net_pugdr_cos, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "# model_path = \"./model/\"+args.datasets+\"/pugdr_icos\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net_pugdr_cos.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/pugdr_icos_\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metricsr_cos,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cf6955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pugdr_sin = UPANets(args.filters, Num_class, args.blocks, img_size)\n",
    "# net_pugdr_sin.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net_pugdr_sin.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     model_ft_org = torch.nn.DataParallel(net_pugdr_sin)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDXR(net_pugdr_sin.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=args.lr,\n",
    "#                 max_epochs= args.epochs,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 min_beta = 0.01, \n",
    "#                 max_beta = 2, \n",
    "#                 method = 'isin',\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                 )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "# # exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# net_pugdr_sin, metricsr_sin = train_model_alpha(net_pugdr_sin, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "# model_path = \"./model/\"+args.datasets+\"/pugdr_isin\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net_pugdr_sin.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/pugdr_isin_\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metricsr_sin,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b645d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pugds_icos = UPANets(args.filters, Num_class, args.blocks, img_size)  \n",
    "# net_pugds_icos.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net_pugds_icos.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     net_pugds_icos = torch.nn.DataParallel(net_pugds_icos)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDXS(net_pugds_icos.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=args.lr,\n",
    "#                 max_epochs= args.epochs,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 min_beta = 0.8, \n",
    "#                 max_beta = 3, \n",
    "#                 method = 'icos',\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                  )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "# # exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# net_pugds_icos, metricss_icos = train_model_alpha(net_pugds_icos, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "# model_path = \"./model/\"+args.datasets+\"/pugds_icos\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net_pugds_icos.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/pugds_icos_\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metricss_icos,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214741d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pugds_isin = UPANets(args.filters, Num_class, args.blocks, img_size)  \n",
    "# net_pugds_isin.load_state_dict(copy.deepcopy(benckmark_state_dict))\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# net_pugds_isin.to(device)\n",
    "\n",
    "# if device == 'cuda' and torch.cuda.device_count() > 1:\n",
    "#     net_pugds_isin = torch.nn.DataParallel(net_pugds_isin)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# base_optimizer = optim.SGD\n",
    "# optimizer = PUGDXS(net_pugds_isin.parameters(),\n",
    "#                 base_optimizer,\n",
    "#                 lr=args.lr,\n",
    "#                 max_epochs= args.epochs,\n",
    "#                 momentum=args.momentum,\n",
    "#                 weight_decay=args.wd,\n",
    "#                 min_beta = 0.8, \n",
    "#                 max_beta = 3, \n",
    "#                 method = 'isin',\n",
    "#                 dampening=0,   # 必须设置为0才能完全固定 \n",
    "#                 nesterov=False # 禁用Nesterov动量 \n",
    "#                  )\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "# # exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# net_pugds_isin, metricss_isin = train_model_alpha(net_pugds_isin, criterion, optimizer, scheduler, args.epochs, trainloader, device, dataset_sizes) \n",
    "\n",
    "# model_path = \"./model/\"+args.datasets+\"/pugds_isin\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".pth\"\n",
    "# torch.save({\n",
    "#     'model_state_dict': net_pugds_isin.state_dict(), \n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, model_path) \n",
    "\n",
    "# name = \"./results/\"+args.datasets+\"/pugds_isin_\" + str(optimizer.max_beta) + \"_\" + str(optimizer.min_beta) + \"_\" + str(args.epochs) + \".json\"\n",
    "# with open(name,  'w', encoding='utf-8') as f:\n",
    "#     json.dump(metricss_isin,  f, default=tensor_to_serializable, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672b77e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8923cee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(new_head.__dict__)\n",
    "# print(vars(new_head))\n",
    "# import optimizers\n",
    "# import importlib \n",
    "# importlib.reload(optimizers)   \n",
    "# from optimizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c21966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_ft2 = timm.create_model('mobilenetv3_small_100', pretrained=True, num_classes=Num_class)\n",
    "# original_head = model_ft2.classifier   # MobileNetV3的分类头名为classifier \n",
    "# new_head = nn.Linear(original_head.in_features,  Num_class)\n",
    "# model_ft2 = model_ft2.to(device)\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# base_optimizer2 = optim.SGD\n",
    "# optimizer2 = PUGD2(model_ft2.parameters(),\n",
    "#                  base_optimizer2,\n",
    "#                  lr=args.lr,\n",
    "#                  momentum=args.momentum,\n",
    "#                  weight_decay=args.wd,\n",
    "#                  )\n",
    "\n",
    "\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "# exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer2, step_size=7, gamma=0.1)\n",
    "\n",
    "# model_ft2 = train_model2(model_ft2, criterion, optimizer2, exp_lr_scheduler, num_epochs=20) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
